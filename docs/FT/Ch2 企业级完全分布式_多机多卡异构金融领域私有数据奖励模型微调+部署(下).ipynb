{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe98a9e5-4646-47d0-9445-19bf22ef3a54",
   "metadata": {},
   "source": [
    "# <center>Ch2 ä¼ä¸šçº§å®Œå…¨åˆ†å¸ƒå¼_å¤šæœºå¤šå¡å¼‚æ„é‡‘èé¢†åŸŸç§æœ‰æ•°æ®å¥–åŠ±æ¨¡å‹å¾®è°ƒ+éƒ¨ç½²(ä¸‹)</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62520f00",
   "metadata": {},
   "source": [
    "# 1. æœ¬åœ°å¼€å‘è¿æ¥æœåŠ¡å™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28616f3e",
   "metadata": {},
   "source": [
    "## æ–¹å¼1ï¼šä½¿ç”¨Remote - SSH  \n",
    "\n",
    "ç›´æ¥è¿æ¥æœåŠ¡å™¨æ–¹ä¾¿ä»£ç æ›´æ”¹ï¼Œå¯ä»¥ç›´æ¥ä¿å­˜"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67cdbe9",
   "metadata": {},
   "source": [
    "æœ¬æ¬¡è¿é€šæ–¹å¼ä½¿ç”¨ä¸º visual Studio Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545e5095",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250623155250822.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "643f1856",
   "metadata": {},
   "source": [
    "ç›´æ¥è¿›å…¥æ‰©å±•ä¸­è¿›è¡Œåç§°æœç´¢åå®‰è£…"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4284f456",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153107297.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc29fa30",
   "metadata": {},
   "source": [
    "é€‰æ‹©æœç´¢æ æ‰¾åˆ°æ˜¾ç¤ºå¹¶è¿è¡Œå‘½ä»¤ï¼Œæˆ–è€…ç›´æ¥æŒ‰å¿«æ·é”®(å½“å‰ç”µè„‘ç¯å¢ƒä¸ºmacç¯å¢ƒ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc61234",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153347272.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a7f491",
   "metadata": {},
   "source": [
    "ä½¿ç”¨å½“å‰å‘½ä»¤  å¢åŠ ç›®æ ‡IPçš„å½•å…¥  Remote-SSH: Add New SSH Host\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe007c6",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153425819.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d62b889e",
   "metadata": {},
   "source": [
    "è¿™é‡Œä¼šè¦æ±‚è¾“å…¥ç›®æ ‡çš„sshå‘½ä»¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fdaecd7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153450588.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab472a5",
   "metadata": {},
   "source": [
    "è¾“å…¥ç›®æ ‡æœåŠ¡å™¨sshå‘½ä»¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257eea73",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153513184.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88122d89",
   "metadata": {},
   "source": [
    " ä¼šå¼¹å‡ºé€‰æ‹©ä¿¡æ¯ä¿å­˜è·¯å¾„  é€‰æ‹© `~/.ssh/config` ä½œä¸ºé…ç½®æ–‡ä»¶ä¿å­˜ä½ç½®ã€‚\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "488eb0cb",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153647334.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8baf74d3",
   "metadata": {},
   "source": [
    "**ä½¿ç”¨ç§˜é’¥å½¢å¼è¿›è¡Œé“¾æ¥**\n",
    "\n",
    "IdentityFile ~/.ssh/id_rsa   \n",
    "  ServerAliveInterval 60   \n",
    "  ServerAliveCountMax 5   \n",
    "\n",
    "  æ¯ 60 ç§’å‘æœåŠ¡å™¨å‘é€ä¸€æ¬¡ä¿æ´»ä¿¡å·ï¼ˆç©ºæ•°æ®åŒ…ï¼‰ï¼Œæ£€æµ‹è¿æ¥æ˜¯å¦å­˜æ´»ã€‚    \n",
    "  å¦‚æœè¿ç»­ 5 æ¬¡ä¿æ´»ä¿¡å·ï¼ˆæ€»è®¡ 5 Ã— 60 = 300 ç§’ï¼‰æœªæ”¶åˆ°æœåŠ¡å™¨å“åº”æ–­å¼€è¿æ¥      \n",
    "\n",
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605162300856.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fe57fc",
   "metadata": {},
   "source": [
    "æ˜¾ç¤ºæ·»åŠ å®Œæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f597480",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153606598.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b71b8893",
   "metadata": {},
   "source": [
    "\n",
    "è¾“å…¥é€‰æ‹©æƒ³è¦è¿æ¥åº¦æœåŠ¡å™¨IP   Remote-SSH: Connect to Host\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc253c5",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153721394.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4537747",
   "metadata": {},
   "source": [
    "é€‰æ‹©æƒ³è¦è¿æ¥çš„æœåŠ¡å™¨åœ°å€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb274ac",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153748177.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6245ddc2",
   "metadata": {},
   "source": [
    "è¾“å…¥è¿æ¥å¯†ç  ç¡®è®¤ åè¿æ¥"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7303bd8",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605153838180.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83752650",
   "metadata": {},
   "source": [
    "é€‰æ‹©æ‰“å¼€ æ‰¾åˆ°é¡¹ç›®ç›®æ ‡è·¯å¾„ ç‚¹å‡»ç¡®å®š å¯ä»¥è¿›è¡Œé¡¹ç›®ç¼–è¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f24db4",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605154811870.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6acc3d73",
   "metadata": {},
   "source": [
    "## æ–¹å¼äºŒï¼š rsync"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d17be8b",
   "metadata": {},
   "source": [
    "**windowç³»ç»Ÿå®‰è£… åœ¨WSLä¸­åŒæ­¥Windowsæ–‡ä»¶åˆ°è¿œç¨‹æœåŠ¡å™¨**    \n",
    "rsync -avz --progress /mnt/c/Users/YourName/Documents/project/ username@server:/remote/path/\n",
    "\n",
    "**ä»è¿œç¨‹æœåŠ¡å™¨åŒæ­¥åˆ°Windows**    \n",
    "rsync -avz --progress username@server:/remote/path/ /mnt/c/Users/YourName/Documents/project/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571480c5",
   "metadata": {},
   "source": [
    "macç”µè„‘æœ¬èº«è‡ªå¸¦ rsync è½¯ä»¶ \n",
    "\n",
    "å¦‚æœæƒ³è¦æ›´æ–°æˆ–è€…å®‰è£… éœ€è¦ä½¿ç”¨ /bin/bash -c \"$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install.sh)\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95f2fbc",
   "metadata": {},
   "source": [
    "\n",
    "è¿›å…¥é¡¹ç›®æ–‡ä»¶å¤¹ä¸‹ cd \"/financial_reward_model\" åˆ›å»ºdeploy.sh è„šæœ¬\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e9ee80",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605160358114.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68af7878",
   "metadata": {},
   "source": [
    " åˆ›å»ºæ–‡ä»¶ touch deploy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2d4263",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "# å†…å®¹å¦‚ä¸‹\n",
    "echo \"ğŸš€ å¼€å§‹åŒæ­¥é¡¹ç›®åˆ°æœåŠ¡å™¨...\"\n",
    "\n",
    "rsync -avz \\\n",
    "  --exclude '.git' \\\n",
    "  --exclude '__pycache__' \\\n",
    "  --exclude '.DS_Store' \\\n",
    "  ./ \\\n",
    "  ubuntu@117.50.34.28:/shared/financial_reward_model/\n",
    "\n",
    "echo \"âœ… æ–‡ä»¶åŒæ­¥å®Œæˆï¼Œæ‰§è¡Œè¿œç¨‹æ“ä½œ...\"\n",
    "\n",
    "ssh ubuntu@117.50.34.28 << 'EOF'\n",
    "cd /shared/financial_reward_model\n",
    "# å¦‚æœæœ‰éœ€è¦é‡å¯çš„æœåŠ¡æˆ–è¿è¡Œå‘½ä»¤ï¼Œè¯·åœ¨ä¸‹é¢åŠ \n",
    "# ç¤ºä¾‹: pkill -f app.py && nohup python3 app.py > out.log 2>&1 &\n",
    "echo \"ğŸš€ å·²è¿›å…¥è¿œç¨‹é¡¹ç›®ç›®å½•ï¼Œå¯æ ¹æ®éœ€è¦æ·»åŠ æ‰§è¡Œå‘½ä»¤\"\n",
    "EOF\n",
    "\n",
    "echo \"ğŸ‰ éƒ¨ç½²å®Œæ¯•ï¼\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c817dd",
   "metadata": {},
   "source": [
    "æ·»åŠ å¯æ‰§è¡Œæƒé™ï¼šchmod +x deploy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3d0ad0",
   "metadata": {},
   "source": [
    "ç›®æ ‡æ–‡ä»¶å¤¹è¦ä¼˜åŠ¿ç”¨æˆ·æˆæƒ sudo chown -R ubuntu:ubuntu /shared  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6601df8f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605160507639.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e967e7",
   "metadata": {},
   "source": [
    "æ‰§è¡Œæ–‡ä»¶ å°±ä¼šå°†æœ¬åœ°ä»£ç å†…å®¹åŒæ­¥åˆ°æœåŠ¡å™¨ä¸­"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0e0ae1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605160601767.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "050414ee",
   "metadata": {},
   "source": [
    "æ‰§è¡Œä¼šè¦æ±‚è¾“å…¥æœåŠ¡å™¨è¿æ¥å¯†ç  ä¸sshè¿æ¥æ–¹å¼ç›¸åŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ebc1432",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605160727146.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc6acf",
   "metadata": {},
   "source": [
    "å¦‚æœå«Œéº»çƒ¦å¯ä»¥é€‰æ‹©å°†æœ¬åœ°ç§˜é’¥ä¸Šä¼ åˆ°æœåŠ¡å™¨ä¸­ï¼Œä¹‹åå°±ä¸ç”¨æ¯æ¬¡ä¸Šä¼ é‡æ–°è¾“å…¥å¯†ç \n",
    "\n",
    "**æœ¬åœ°ç”Ÿæˆå¯†é’¥**æ ¹æ®å½“å‰ç”¨æˆ·åˆ›å»ºç§˜é’¥\n",
    "\n",
    "ssh-keygen -t rsa -C \"ä¸ªäººç”µè„‘ç”¨æˆ·\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400dc4ea",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605160953565.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c007fef",
   "metadata": {},
   "source": [
    "**å°†å…¬é’¥å‘é€åˆ°æœåŠ¡å™¨** \n",
    "\n",
    "ssh-copy-id ubuntu@106.75.127.84\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d696c54",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605161138954.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b9e4c7",
   "metadata": {},
   "source": [
    "ç›´æ¥æ‰§è¡Œè„šæœ¬ï¼Œä¸ç”¨äºŒæ¬¡è¾“å…¥å¯†ç   ./deploy.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87944a8d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605161203070.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fc40747",
   "metadata": {},
   "source": [
    "## åŸºç¡€ç¯å¢ƒæ ¡éªŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a86a27",
   "metadata": {},
   "source": [
    "åˆ›å»ºæ£€æŸ¥æ–‡ä»¶ï¼š\n",
    "\n",
    "check_data.py(å¯é€‰)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ca5516",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import os\n",
    "import json\n",
    "import sys\n",
    "\n",
    "def find_data_files(data_base_path):\n",
    "    \"\"\"æŸ¥æ‰¾æ•°æ®æ–‡ä»¶\"\"\"\n",
    "    train_dir = os.path.join(data_base_path, \"train\")\n",
    "    eval_dir = os.path.join(data_base_path, \"eval\")\n",
    "    \n",
    "    print(f\"æŸ¥æ‰¾æ•°æ®æ–‡ä»¶...\")\n",
    "    print(f\"è®­ç»ƒæ•°æ®ç›®å½•: {train_dir}\")\n",
    "    print(f\"è¯„ä¼°æ•°æ®ç›®å½•: {eval_dir}\")\n",
    "    \n",
    "    # æŸ¥æ‰¾è®­ç»ƒæ•°æ®æ–‡ä»¶\n",
    "    train_files = []\n",
    "    if os.path.exists(train_dir):\n",
    "        train_files = [f for f in os.listdir(train_dir) if f.endswith('.jsonl')]\n",
    "        print(f\"è®­ç»ƒç›®å½•ä¸­çš„jsonlæ–‡ä»¶: {train_files}\")\n",
    "    \n",
    "    # æŸ¥æ‰¾è¯„ä¼°æ•°æ®æ–‡ä»¶\n",
    "    eval_files = []\n",
    "    if os.path.exists(eval_dir):\n",
    "        eval_files = [f for f in os.listdir(eval_dir) if f.endswith('.jsonl')]\n",
    "        print(f\"è¯„ä¼°ç›®å½•ä¸­çš„jsonlæ–‡ä»¶: {eval_files}\")\n",
    "    \n",
    "    return train_files, eval_files\n",
    "\n",
    "# ============================================================================\n",
    "#  åå¥½æ•°æ®æ£€æŸ¥å‡½æ•°ï¼šéªŒè¯preferenceæ•°æ®çš„ç»“æ„å’Œå†…å®¹\n",
    "# \n",
    "#  è¿™ä¸ªå‡½æ•°åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š\n",
    "# 1. ã€æ•°æ®éªŒè¯ã€‘ï¼šç¡®ä¿è®­ç»ƒæ•°æ®å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®\n",
    "# 2. ã€é—®é¢˜é¢„é˜²ã€‘ï¼šåœ¨è®­ç»ƒå¼€å§‹å‰å‘ç°æ•°æ®é—®é¢˜\n",
    "# 3. ã€æ ¼å¼æ£€æŸ¥ã€‘ï¼šéªŒè¯JSONç»“æ„æ˜¯å¦ç¬¦åˆæœŸæœ›\n",
    "# 4. ã€ç»Ÿè®¡æŠ¥å‘Šã€‘ï¼šæä¾›æ•°æ®é›†çš„åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯\n",
    "# \n",
    "#  æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°åœ¨é¡¹ç›®ä¸­ã€å¾ˆå°‘è¢«è°ƒç”¨ã€‘\n",
    "# - ä¸»è¦ç”¨äºè°ƒè¯•å’Œé—®é¢˜æ’æŸ¥\n",
    "# - ä¸æ˜¯è®­ç»ƒæµç¨‹çš„å¿…éœ€éƒ¨åˆ†\n",
    "# ============================================================================\n",
    "def check_preference_data_structure():\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥preferenceæ•°æ®ç»“æ„å’Œå†…å®¹çš„ä¸»è¦å‡½æ•°\n",
    "    \n",
    "    è¿™ä¸ªå‡½æ•°ä¼šæ£€æŸ¥ä»¥ä¸‹å†…å®¹ï¼š\n",
    "    1. æ•°æ®ç›®å½•ç»“æ„æ˜¯å¦æ­£ç¡®\n",
    "    2. æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "    3. JSONæ ¼å¼æ˜¯å¦æ­£ç¡®\n",
    "    4. å¿…éœ€å­—æ®µæ˜¯å¦å®Œæ•´\n",
    "    5. æ•°æ®å†…å®¹æ˜¯å¦åˆç†\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - å¦‚æœæ£€æŸ¥é€šè¿‡ï¼š(True, train_file, eval_file)\n",
    "    - å¦‚æœæ£€æŸ¥å¤±è´¥ï¼š(False, None, None)\n",
    "    \"\"\"\n",
    "    \n",
    "    # ç¬¬1æ­¥ï¼šè®¾ç½®æ•°æ®è·¯å¾„ï¼ˆç¡¬ç¼–ç è·¯å¾„ï¼‰\n",
    "    data_base_path = \"../reward_model_data/reward_data\"\n",
    "    \n",
    "    print(\"=== æ•°æ®ç»“æ„æ£€æŸ¥ ===\")\n",
    "    print(f\"æ•°æ®åŸºç¡€è·¯å¾„: {data_base_path}\")\n",
    "    \n",
    "    # ç¬¬2æ­¥ï¼šæ£€æŸ¥åŸºç¡€è·¯å¾„æ˜¯å¦å­˜åœ¨\n",
    "    if not os.path.exists(data_base_path):\n",
    "        print(f\" æ•°æ®åŸºç¡€è·¯å¾„ä¸å­˜åœ¨: {data_base_path}\")\n",
    "        return False\n",
    "    \n",
    "    # ç¬¬3æ­¥ï¼šæŸ¥æ‰¾æ•°æ®æ–‡ä»¶\n",
    "    train_files, eval_files = find_data_files(data_base_path)\n",
    "    \n",
    "    # ç¬¬4æ­¥ï¼šé€‰æ‹©æ•°æ®æ–‡ä»¶ï¼ˆä¼˜å…ˆä½¿ç”¨preference_dataset.jsonlï¼‰\n",
    "    train_file = \"preference_dataset.jsonl\" if \"preference_dataset.jsonl\" in train_files else (train_files[0] if train_files else None)\n",
    "    eval_file = \"preference_dataset.jsonl\" if \"preference_dataset.jsonl\" in eval_files else (eval_files[0] if eval_files else None)\n",
    "    \n",
    "    # ç¬¬5æ­¥ï¼šéªŒè¯æ•°æ®æ–‡ä»¶å­˜åœ¨æ€§\n",
    "    if not train_file:\n",
    "        print(f\" è®­ç»ƒç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°jsonlæ–‡ä»¶\")\n",
    "        return False\n",
    "    \n",
    "    if not eval_file:\n",
    "        print(f\" è¯„ä¼°ç›®å½•ä¸­æ²¡æœ‰æ‰¾åˆ°jsonlæ–‡ä»¶\")\n",
    "        return False\n",
    "    \n",
    "    # ç¬¬6æ­¥ï¼šæ„å»ºå®Œæ•´æ–‡ä»¶è·¯å¾„\n",
    "    train_path = os.path.join(data_base_path, \"train\", train_file)\n",
    "    eval_path = os.path.join(data_base_path, \"eval\", eval_file)\n",
    "    \n",
    "    print(f\" ä½¿ç”¨è®­ç»ƒæ–‡ä»¶: {train_file}\")\n",
    "    print(f\" ä½¿ç”¨è¯„ä¼°æ–‡ä»¶: {eval_file}\")\n",
    "    \n",
    "    # ========================================================================\n",
    "    #  æ•°æ®å†…å®¹æ£€æŸ¥å­å‡½æ•°ï¼šéªŒè¯å•ä¸ªæ•°æ®æ–‡ä»¶çš„å†…å®¹\n",
    "    # \n",
    "    #  è¿™ä¸ªå†…éƒ¨å‡½æ•°çš„ä½œç”¨ï¼š\n",
    "    # 1. ã€æ ¼å¼éªŒè¯ã€‘ï¼šæ£€æŸ¥æ¯è¡Œæ˜¯å¦æ˜¯æœ‰æ•ˆçš„JSON\n",
    "    # 2. ã€å­—æ®µæ£€æŸ¥ã€‘ï¼šéªŒè¯å¿…éœ€å­—æ®µæ˜¯å¦å­˜åœ¨\n",
    "    # 3. ã€å†…å®¹åˆ†æã€‘ï¼šåˆ†ææ•°æ®å†…å®¹çš„åˆç†æ€§\n",
    "    # 4. ã€ç»Ÿè®¡æŠ¥å‘Šã€‘ï¼šæä¾›æ•°æ®é›†çš„è¯¦ç»†ç»Ÿè®¡\n",
    "    # ========================================================================\n",
    "    def check_file_content(file_path, split_name):\n",
    "        \"\"\"\n",
    "        æ£€æŸ¥å•ä¸ªæ•°æ®æ–‡ä»¶çš„å†…å®¹\n",
    "        \n",
    "        å‚æ•°è¯´æ˜ï¼š\n",
    "        - file_path: è¦æ£€æŸ¥çš„æ–‡ä»¶è·¯å¾„\n",
    "        - split_name: æ•°æ®é›†åç§°ï¼ˆ\"è®­ç»ƒ\" æˆ– \"è¯„ä¼°\"ï¼‰\n",
    "        \n",
    "        è¿”å›ï¼š\n",
    "        - True: æ£€æŸ¥é€šè¿‡\n",
    "        - False: æ£€æŸ¥å¤±è´¥\n",
    "        \"\"\"\n",
    "        print(f\"\\n--- {split_name} æ•°æ®æ£€æŸ¥ ---\")\n",
    "        try:\n",
    "            # è¯»å–æ‰€æœ‰è¡Œ\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "            \n",
    "            print(f\"æ•°æ®è¡Œæ•°: {len(lines)}\")\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦ä¸ºç©º\n",
    "            if len(lines) == 0:\n",
    "                print(f\" {split_name} æ•°æ®ä¸ºç©º\")\n",
    "                return False\n",
    "            \n",
    "            # æ£€æŸ¥å‰å‡ è¡Œæ•°æ®æ ¼å¼ï¼ˆé¿å…æ£€æŸ¥æ‰€æœ‰æ•°æ®ï¼ŒèŠ‚çœæ—¶é—´ï¼‰\n",
    "            for i, line in enumerate(lines[:2]):  # åªæ£€æŸ¥å‰2è¡Œä½œä¸ºæ ·æœ¬\n",
    "                try:\n",
    "                    data = json.loads(line.strip())  # è§£æJSON\n",
    "                    \n",
    "                    print(f\"æ ·æœ¬ {i+1}:\")\n",
    "                    print(f\"  å­—æ®µ: {list(data.keys())}\")\n",
    "                    \n",
    "                    # æ£€æŸ¥questionå­—æ®µ\n",
    "                    if \"question\" in data:\n",
    "                        print(f\"   åŒ…å«questionå­—æ®µ\")\n",
    "                        print(f\"  é—®é¢˜é•¿åº¦: {len(data['question'])}\")\n",
    "                    else:\n",
    "                        print(f\"  ç¼ºå°‘questionå­—æ®µ\")\n",
    "                        return False\n",
    "                    \n",
    "                    # æ£€æŸ¥answerså­—æ®µï¼ˆç”¨äºpreferenceè®­ç»ƒï¼‰\n",
    "                    if \"answers\" in data:\n",
    "                        print(f\"   åŒ…å«answerså­—æ®µ\")\n",
    "                        if isinstance(data[\"answers\"], list):\n",
    "                            print(f\"  ç­”æ¡ˆæ•°é‡: {len(data['answers'])}\")\n",
    "                            if len(data[\"answers\"]) >= 2:\n",
    "                                print(f\"   è‡³å°‘æœ‰2ä¸ªç­”æ¡ˆï¼Œå¯ç”¨äºpreferenceè®­ç»ƒ\")\n",
    "                            else:\n",
    "                                print(f\"    åªæœ‰{len(data['answers'])}ä¸ªç­”æ¡ˆï¼Œå¯èƒ½ä¸è¶³ä»¥è¿›è¡Œpreferenceè®­ç»ƒ\")\n",
    "                        else:\n",
    "                            print(f\"    answersä¸æ˜¯åˆ—è¡¨æ ¼å¼\")\n",
    "                    \n",
    "                    # æ£€æŸ¥å…¶ä»–å­—æ®µå¹¶ç»Ÿè®¡ä¿¡æ¯\n",
    "                    for key, value in data.items():\n",
    "                        if key not in [\"question\", \"answers\"]:\n",
    "                            if isinstance(value, str):\n",
    "                                print(f\"  {key}: {len(value)} å­—ç¬¦\")\n",
    "                            else:\n",
    "                                print(f\"  {key}: {type(value).__name__}\")\n",
    "                    \n",
    "                except json.JSONDecodeError as e:\n",
    "                    print(f\" ç¬¬{i+1}è¡ŒJSONæ ¼å¼é”™è¯¯: {e}\")\n",
    "                    return False\n",
    "            \n",
    "            print(f\" {split_name} æ•°æ®æ ¼å¼åŸºæœ¬æ­£ç¡®\")\n",
    "            return True\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\" è¯»å–{split_name}æ•°æ®æ—¶å‡ºé”™: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # ç¬¬7æ­¥ï¼šæ£€æŸ¥è®­ç»ƒå’Œè¯„ä¼°æ•°æ®\n",
    "    train_ok = check_file_content(train_path, \"è®­ç»ƒ\")\n",
    "    eval_ok = check_file_content(eval_path, \"è¯„ä¼°\")\n",
    "    \n",
    "    # ç¬¬8æ­¥ï¼šæ±‡æ€»æ£€æŸ¥ç»“æœ\n",
    "    if train_ok and eval_ok:\n",
    "        print(\"\\n æ•°æ®æ£€æŸ¥é€šè¿‡ï¼\")\n",
    "        print(f\" æ•°æ®æ–‡ä»¶ä¿¡æ¯:\")\n",
    "        print(f\"  è®­ç»ƒæ–‡ä»¶: {train_file}\")\n",
    "        print(f\"  è¯„ä¼°æ–‡ä»¶: {eval_file}\")\n",
    "        print(f\"\\n  æ³¨æ„: éœ€è¦æ ¹æ®å®é™…æ•°æ®æ ¼å¼ä¿®æ”¹æ•°æ®é›†ç±»\")\n",
    "        return True, train_file, eval_file\n",
    "    else:\n",
    "        print(\"\\n æ•°æ®æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤æ•°æ®é—®é¢˜åå†è¯•ã€‚\")\n",
    "        return False, None, None\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#  æ¨¡å‹è·¯å¾„æ£€æŸ¥å‡½æ•°ï¼šéªŒè¯é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶æ˜¯å¦å®Œæ•´\n",
    "# \n",
    "#  è¿™ä¸ªå‡½æ•°åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š\n",
    "# 1. ã€æ¨¡å‹éªŒè¯ã€‘ï¼šç¡®ä¿é¢„è®­ç»ƒæ¨¡å‹æ–‡ä»¶å­˜åœ¨ä¸”å®Œæ•´\n",
    "# 2. ã€è·¯å¾„æ£€æŸ¥ã€‘ï¼šéªŒè¯æ¨¡å‹è·¯å¾„é…ç½®æ˜¯å¦æ­£ç¡®\n",
    "# 3. ã€æ–‡ä»¶å®Œæ•´æ€§ã€‘ï¼šæ£€æŸ¥å…³é”®æ¨¡å‹æ–‡ä»¶æ˜¯å¦é½å…¨\n",
    "# 4. ã€æ ¼å¼æ”¯æŒã€‘ï¼šæ£€æŸ¥æ¨¡å‹æ ¼å¼ï¼ˆsafetensors/pytorchï¼‰\n",
    "# \n",
    "#  æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°åœ¨é¡¹ç›®ä¸­ã€å¾ˆå°‘è¢«è°ƒç”¨ã€‘\n",
    "# - ä¸»è¦ç”¨äºç¯å¢ƒé…ç½®éªŒè¯\n",
    "# - ç¡¬ç¼–ç äº†æ¨¡å‹è·¯å¾„ï¼Œå¯èƒ½éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´\n",
    "# ============================================================================\n",
    "def check_model_path():\n",
    "    \"\"\"\n",
    "    æ£€æŸ¥é¢„è®­ç»ƒæ¨¡å‹è·¯å¾„å’Œæ–‡ä»¶å®Œæ•´æ€§\n",
    "    \n",
    "    è¿™ä¸ªå‡½æ•°ä¼šæ£€æŸ¥ä»¥ä¸‹å†…å®¹ï¼š\n",
    "    1. æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨\n",
    "    2. å…³é”®é…ç½®æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆconfig.json, tokenizer.jsonï¼‰\n",
    "    3. æ¨¡å‹æƒé‡æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼ˆsafetensorsæˆ–pytorchæ ¼å¼ï¼‰\n",
    "    4. æ–‡ä»¶æ ¼å¼æ˜¯å¦æ”¯æŒ\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - True: æ¨¡å‹æ£€æŸ¥é€šè¿‡\n",
    "    - False: æ¨¡å‹æ£€æŸ¥å¤±è´¥\n",
    "    \"\"\"\n",
    "    # ç¡¬ç¼–ç çš„æ¨¡å‹è·¯å¾„ï¼ˆ å¯èƒ½éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´ï¼‰\n",
    "    model_path = \"/shared/QRM-Llama3.1-8B-v2\"\n",
    "    \n",
    "    print(f\"\\n=== æ¨¡å‹è·¯å¾„æ£€æŸ¥ ===\")\n",
    "    print(f\"æ¨¡å‹è·¯å¾„: {model_path}\")\n",
    "    \n",
    "    # ç¬¬1æ­¥ï¼šæ£€æŸ¥æ¨¡å‹ç›®å½•æ˜¯å¦å­˜åœ¨\n",
    "    if not os.path.exists(model_path):\n",
    "        print(f\" æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}\")\n",
    "        return False\n",
    "    \n",
    "    # ç¬¬2æ­¥ï¼šæ£€æŸ¥å…³é”®é…ç½®æ–‡ä»¶\n",
    "    required_files = [\"config.json\", \"tokenizer.json\"]  # å¿…éœ€çš„é…ç½®æ–‡ä»¶\n",
    "    missing_files = []\n",
    "    \n",
    "    for file_name in required_files:\n",
    "        file_path = os.path.join(model_path, file_name)\n",
    "        if os.path.exists(file_path):\n",
    "            print(f\" {file_name} å­˜åœ¨\")\n",
    "        else:\n",
    "            missing_files.append(file_name)\n",
    "    \n",
    "    # ç¬¬3æ­¥ï¼šæ£€æŸ¥æ¨¡å‹æƒé‡æ–‡ä»¶\n",
    "    model_files_found = False\n",
    "    \n",
    "    # è·å–ç›®å½•ä¸­çš„æ‰€æœ‰æ–‡ä»¶\n",
    "    all_files = os.listdir(model_path)\n",
    "    \n",
    "    # æ£€æŸ¥safetensorsæ ¼å¼ï¼ˆæ¨èæ ¼å¼ï¼‰\n",
    "    safetensors_files = [f for f in all_files if f.endswith(\".safetensors\")]\n",
    "    if safetensors_files:\n",
    "        print(f\" æ‰¾åˆ°safetensorsæ¨¡å‹æ–‡ä»¶: {len(safetensors_files)} ä¸ª\")\n",
    "        model_files_found = True\n",
    "    \n",
    "    # æ£€æŸ¥pytorchæ ¼å¼ï¼ˆä¼ ç»Ÿæ ¼å¼ï¼‰\n",
    "    pytorch_files = [f for f in all_files if f.endswith(\".bin\") and \"pytorch_model\" in f]\n",
    "    if pytorch_files:\n",
    "        print(f\" æ‰¾åˆ°pytorchæ¨¡å‹æ–‡ä»¶: {len(pytorch_files)} ä¸ª\")\n",
    "        model_files_found = True\n",
    "    \n",
    "    # ç¬¬4æ­¥ï¼šæ£€æŸ¥æ˜¯å¦æ‰¾åˆ°æ¨¡å‹æƒé‡æ–‡ä»¶\n",
    "    if not model_files_found:\n",
    "        print(f\"æœªæ‰¾åˆ°æ¨¡å‹æƒé‡æ–‡ä»¶\")\n",
    "        missing_files.append(\"model_weights\")\n",
    "    \n",
    "    # ç¬¬5æ­¥ï¼šæ±‡æ€»æ£€æŸ¥ç»“æœ\n",
    "    if missing_files:\n",
    "        print(f\" ç¼ºå°‘å…³é”®æ–‡ä»¶: {missing_files}\")\n",
    "        return False\n",
    "    \n",
    "    print(\" æ¨¡å‹æ–‡ä»¶æ£€æŸ¥é€šè¿‡\")\n",
    "    return True\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#  ä¸»æ‰§è¡Œå‡½æ•°ï¼šè„šæœ¬çš„å…¥å£ç‚¹ï¼Œåè°ƒæ‰€æœ‰æ£€æŸ¥æµç¨‹\n",
    "# \n",
    "#  è¿™ä¸ªéƒ¨åˆ†åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š\n",
    "# 1. ã€æµç¨‹åè°ƒã€‘ï¼šåè°ƒæ•°æ®æ£€æŸ¥å’Œæ¨¡å‹æ£€æŸ¥\n",
    "# 2. ã€ç»“æœæ±‡æ€»ã€‘ï¼šæ±‡æ€»æ‰€æœ‰æ£€æŸ¥ç»“æœ\n",
    "# 3. ã€çŠ¶æ€è¿”å›ã€‘ï¼šé€šè¿‡é€€å‡ºç å‘ŠçŸ¥è°ƒç”¨è€…æ£€æŸ¥ç»“æœ\n",
    "# 4. ã€ç”¨æˆ·å‹å¥½ã€‘ï¼šæä¾›æ¸…æ™°çš„æˆåŠŸ/å¤±è´¥ä¿¡æ¯\n",
    "# \n",
    "#  æ³¨æ„ï¼šè¿™ä¸ªè„šæœ¬åœ¨é¡¹ç›®ä¸­ã€å¾ˆå°‘è¢«å®é™…ä½¿ç”¨ã€‘\n",
    "# - è¢«run_training.shå¼•ç”¨ï¼Œä½†run_training.shæœ¬èº«ä¹Ÿæœªè¢«ä½¿ç”¨\n",
    "# - ä¸»è¦ç”¨äºæ‰‹åŠ¨è°ƒè¯•å’Œç¯å¢ƒéªŒè¯\n",
    "# ============================================================================\n",
    "if __name__ == \"__main__\":\n",
    "    \"\"\"\n",
    "    è„šæœ¬ä¸»å…¥å£ï¼šå½“ç›´æ¥è¿è¡Œæ­¤è„šæœ¬æ—¶æ‰§è¡Œ\n",
    "    \n",
    "    æ‰§è¡Œæµç¨‹ï¼š\n",
    "    1. æ‰§è¡Œæ•°æ®ç»“æ„å’Œå†…å®¹æ£€æŸ¥\n",
    "    2. æ‰§è¡Œæ¨¡å‹è·¯å¾„å’Œæ–‡ä»¶æ£€æŸ¥\n",
    "    3. æ±‡æ€»æ‰€æœ‰æ£€æŸ¥ç»“æœ\n",
    "    4. æ ¹æ®æ£€æŸ¥ç»“æœè®¾ç½®é€€å‡ºç \n",
    "    \n",
    "    é€€å‡ºç è¯´æ˜ï¼š\n",
    "    - 0: æ‰€æœ‰æ£€æŸ¥é€šè¿‡\n",
    "    - 1: æ£€æŸ¥å¤±è´¥\n",
    "    \"\"\"\n",
    "    print(\"å¼€å§‹ç¯å¢ƒå’Œæ•°æ®æ£€æŸ¥...\\n\")\n",
    "    \n",
    "    # ç¬¬1æ­¥ï¼šæ‰§è¡Œæ•°æ®æ£€æŸ¥\n",
    "    data_result = check_preference_data_structure()\n",
    "    if isinstance(data_result, tuple):\n",
    "        data_ok, train_file, eval_file = data_result  # è§£åŒ…è¿”å›å€¼\n",
    "    else:\n",
    "        data_ok = data_result\n",
    "        train_file = eval_file = None\n",
    "    \n",
    "    # ç¬¬2æ­¥ï¼šæ‰§è¡Œæ¨¡å‹æ£€æŸ¥\n",
    "    model_ok = check_model_path()\n",
    "    \n",
    "    # ç¬¬3æ­¥ï¼šæ±‡æ€»æ£€æŸ¥ç»“æœ\n",
    "    print(f\"\\n=== æ£€æŸ¥ç»“æœæ±‡æ€» ===\")\n",
    "    print(f\"æ•°æ®æ£€æŸ¥: {' é€šè¿‡' if data_ok else 'å¤±è´¥'}\")\n",
    "    print(f\"æ¨¡å‹æ£€æŸ¥: {' é€šè¿‡' if model_ok else 'å¤±è´¥'}\")\n",
    "    \n",
    "    # ç¬¬4æ­¥ï¼šæ ¹æ®æ£€æŸ¥ç»“æœæä¾›ç›¸åº”çš„ä¿¡æ¯å’Œé€€å‡ºç \n",
    "    if data_ok and model_ok:\n",
    "        print(\"\\n æ‰€æœ‰æ£€æŸ¥é€šè¿‡ï¼ç¯å¢ƒå‡†å¤‡å°±ç»ªã€‚\")\n",
    "        if train_file and eval_file:\n",
    "            print(f\"\\n å»ºè®®ä½¿ç”¨çš„æ•°æ®æ–‡ä»¶:\")\n",
    "            print(f\"   è®­ç»ƒæ–‡ä»¶: {train_file}\")\n",
    "            print(f\"   è¯„ä¼°æ–‡ä»¶: {eval_file}\")\n",
    "        sys.exit(0)  # æˆåŠŸé€€å‡º\n",
    "    else:\n",
    "        print(\"\\n æ£€æŸ¥å¤±è´¥ï¼Œè¯·ä¿®å¤é—®é¢˜åå†è¯•ã€‚\")\n",
    "        sys.exit(1)  # å¤±è´¥é€€å‡º\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a90fd64",
   "metadata": {},
   "source": [
    "python scripts/setup/check_data.py (æ³¨æ„æ‰§è¡Œè·¯å¾„ä»¥åŠæ–‡ä»¶å¯¹åº”çš„ç›¸å¯¹è·¯å¾„)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18446059",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605163307140.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9790b2",
   "metadata": {},
   "source": [
    "åˆ›å»ºdeepspeed ç¯å¢ƒæ£€æŸ¥è·¯å¾„   test_deepspeed.py(å¯é€‰)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46b549",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "DeepSpeed Stage 3æµ‹è¯•è„šæœ¬ - æœ€å¤§å†…å­˜ä¼˜åŒ–\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import deepspeed\n",
    "from transformers import AutoTokenizer, AutoConfig, LlamaForSequenceClassification\n",
    "import gc\n",
    "\n",
    "def main():\n",
    "    \"\"\"DeepSpeed Stage 3æµ‹è¯• - å‚æ•°åˆ†ç‰‡\"\"\"\n",
    "    \n",
    "    local_rank = int(os.environ.get('LOCAL_RANK', 0))\n",
    "    world_size = int(os.environ.get('WORLD_SIZE', 1))\n",
    "    rank = int(os.environ.get('RANK', 0))\n",
    "    \n",
    "    print(f\"è¿›ç¨‹ {rank}/{world_size} åœ¨GPU {local_rank}ä¸Šå¯åŠ¨ (Stage 3)\")\n",
    "    \n",
    "    # è®¾ç½®ç¯å¢ƒå˜é‡\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    \n",
    "    # è®¾ç½®GPUå’Œå†…å­˜ä¼˜åŒ–\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "    \n",
    "    model_path = \"/home/ubuntu/QRM-Llama3.1-8B-v2\"\n",
    "    \n",
    "    try:\n",
    "        # 1. åŠ è½½tokenizer\n",
    "        if rank == 0:\n",
    "            print(\" åŠ è½½tokenizer...\")\n",
    "        \n",
    "        tokenizer = AutoTokenizer.from_pretrained(\n",
    "            model_path, \n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        if tokenizer.pad_token is None:\n",
    "            tokenizer.pad_token = tokenizer.eos_token\n",
    "        \n",
    "        # 2. åŠ è½½æ¨¡å‹é…ç½®\n",
    "        if rank == 0:\n",
    "            print(\"ğŸ¤– åŠ è½½æ¨¡å‹é…ç½®...\")\n",
    "        \n",
    "        config = AutoConfig.from_pretrained(\n",
    "            model_path,\n",
    "            trust_remote_code=True\n",
    "        )\n",
    "        config.num_labels = 1\n",
    "        \n",
    "        # 3. Stage 3éœ€è¦åœ¨CPUä¸Šåˆå§‹åŒ–æ¨¡å‹\n",
    "        if rank == 0:\n",
    "            print(\"ğŸ”§ åœ¨CPUä¸Šåˆå§‹åŒ–æ¨¡å‹ï¼ˆStage 3æ¨¡å¼ï¼‰...\")\n",
    "        \n",
    "        with torch.device('cpu'):\n",
    "            model = LlamaForSequenceClassification.from_pretrained(\n",
    "                model_path,\n",
    "                config=config,\n",
    "                torch_dtype=torch.bfloat16,\n",
    "                trust_remote_code=True,\n",
    "                low_cpu_mem_usage=True,\n",
    "                device_map=None\n",
    "            )\n",
    "        \n",
    "        total_params = sum(p.numel() for p in model.parameters())\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f\" æ¨¡å‹åˆå§‹åŒ–æˆåŠŸï¼ˆCPUï¼‰\")\n",
    "            print(f\"   æ€»å‚æ•°é‡: {total_params:,}\")\n",
    "            print(f\"   æ¨¡å‹å¤§å°: {total_params * 2 / 1024**3:.2f}GB (bf16)\")\n",
    "        \n",
    "        # 4. DeepSpeed Stage 3é…ç½®\n",
    "        if rank == 0:\n",
    "            print(\" é…ç½®DeepSpeed Stage 3...\")\n",
    "        \n",
    "        ds_config = {\n",
    "            \"train_batch_size\": 4,\n",
    "            \"train_micro_batch_size_per_gpu\": 2,\n",
    "            \"gradient_accumulation_steps\": 1,\n",
    "            \"gradient_clipping\": 1.0,\n",
    "            \n",
    "            \"zero_allow_untested_optimizer\": True,\n",
    "            \"zero_optimization\": {\n",
    "                \"stage\": 3,                            # Stage 3 - å‚æ•°åˆ†ç‰‡\n",
    "                \"offload_optimizer\": {\n",
    "                    \"device\": \"cpu\",                   # ä¼˜åŒ–å™¨çŠ¶æ€å¸è½½åˆ°CPU\n",
    "                    \"pin_memory\": True\n",
    "                },\n",
    "                \"offload_param\": {\n",
    "                    \"device\": \"cpu\",                   # å‚æ•°å¸è½½åˆ°CPU\n",
    "                    \"pin_memory\": True\n",
    "                },\n",
    "                \"overlap_comm\": True,\n",
    "                \"contiguous_gradients\": True,\n",
    "                \"sub_group_size\": 1e9,\n",
    "                \"reduce_bucket_size\": 1e8,\n",
    "                \"stage3_prefetch_bucket_size\": 1e8,\n",
    "                \"stage3_param_persistence_threshold\": 1e6,\n",
    "                \"stage3_max_live_parameters\": 1e9,\n",
    "                \"stage3_max_reuse_distance\": 1e9\n",
    "            },\n",
    "            \n",
    "            \"optimizer\": {\n",
    "                \"type\": \"SGD\",\n",
    "                \"params\": {\n",
    "                    \"lr\": 1e-3,\n",
    "                    \"momentum\": 0.9,\n",
    "                    \"weight_decay\": 0.01\n",
    "                }\n",
    "            },\n",
    "            \n",
    "            \"bf16\": {\"enabled\": True},\n",
    "            \"wall_clock_breakdown\": False,\n",
    "            \"steps_per_print\": 10\n",
    "        }\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(\" DeepSpeed Stage 3é…ç½®å®Œæˆ\")\n",
    "            print(\"   - å‚æ•°åˆ†ç‰‡: å¯ç”¨\")\n",
    "            print(\"   - ä¼˜åŒ–å™¨CPUå¸è½½: å¯ç”¨\") \n",
    "            print(\"   - å‚æ•°CPUå¸è½½: å¯ç”¨\")\n",
    "        \n",
    "        # 5. åˆå§‹åŒ–DeepSpeedå¼•æ“\n",
    "        if rank == 0:\n",
    "            print(\" åˆå§‹åŒ–DeepSpeed Stage 3å¼•æ“...\")\n",
    "        \n",
    "        engine, optimizer, _, _ = deepspeed.initialize(\n",
    "            model=model,\n",
    "            config=ds_config\n",
    "        )\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(\" DeepSpeed Stage 3å¼•æ“åˆå§‹åŒ–æˆåŠŸ\")\n",
    "            print(f\"   å¼•æ“ç±»å‹: {type(engine).__name__}\")\n",
    "        \n",
    "        # 6. æµ‹è¯•å‰å‘ä¼ æ’­\n",
    "        if rank == 0:\n",
    "            print(\" æµ‹è¯•å‰å‘ä¼ æ’­ï¼ˆStage 3ï¼‰...\")\n",
    "        \n",
    "        batch_size = 1\n",
    "        seq_length = 128\n",
    "        vocab_size = tokenizer.vocab_size\n",
    "        \n",
    "        input_ids = torch.randint(\n",
    "            0, vocab_size, \n",
    "            (batch_size, seq_length), \n",
    "            device=f\"cuda:{local_rank}\"\n",
    "        )\n",
    "        attention_mask = torch.ones(\n",
    "            (batch_size, seq_length), \n",
    "            device=f\"cuda:{local_rank}\"\n",
    "        )\n",
    "        \n",
    "        outputs = engine(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f\" å‰å‘ä¼ æ’­æˆåŠŸ\")\n",
    "            print(f\"   è¾“å…¥å½¢çŠ¶: {input_ids.shape}\")\n",
    "            print(f\"   è¾“å‡ºå½¢çŠ¶: {logits.shape}\")\n",
    "        \n",
    "        # 7. æµ‹è¯•åå‘ä¼ æ’­\n",
    "        if rank == 0:\n",
    "            print(\" æµ‹è¯•åå‘ä¼ æ’­ï¼ˆStage 3ï¼‰...\")\n",
    "        \n",
    "        loss = logits.mean()\n",
    "        engine.backward(loss)\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(f\" åå‘ä¼ æ’­æˆåŠŸï¼ŒæŸå¤±å€¼: {loss.item():.6f}\")\n",
    "        \n",
    "        # 8. æµ‹è¯•ä¼˜åŒ–å™¨æ­¥éª¤\n",
    "        if rank == 0:\n",
    "            print(\"âš¡ æµ‹è¯•ä¼˜åŒ–å™¨æ­¥éª¤ï¼ˆStage 3ï¼‰...\")\n",
    "        \n",
    "        engine.step()\n",
    "        \n",
    "        if rank == 0:\n",
    "            print(\" ä¼˜åŒ–å™¨æ­¥éª¤æˆåŠŸ\")\n",
    "        \n",
    "        # 9. å†…å­˜ç»Ÿè®¡\n",
    "        if rank == 0:\n",
    "            print(\" Stage 3å†…å­˜ä½¿ç”¨ç»Ÿè®¡:\")\n",
    "            for i in range(world_size):\n",
    "                memory_allocated = torch.cuda.memory_allocated(i) / 1024**3\n",
    "                memory_reserved = torch.cuda.memory_reserved(i) / 1024**3\n",
    "                print(f\"   GPU {i}: åˆ†é… {memory_allocated:.2f}GB, ä¿ç•™ {memory_reserved:.2f}GB\")\n",
    "        \n",
    "        # 10. æˆåŠŸæ€»ç»“\n",
    "        if rank == 0:\n",
    "            print(\"\\n DeepSpeed Stage 3æµ‹è¯•æˆåŠŸï¼\")\n",
    "            print(\" éªŒè¯ç»“æœ:\")\n",
    "            print(\"   - Stage 3å‚æ•°åˆ†ç‰‡æ­£å¸¸ \")\n",
    "            print(\"   - CPUå¸è½½åŠŸèƒ½æ­£å¸¸ \")\n",
    "            print(\"   - å†…å­˜ä½¿ç”¨å¤§å¹…é™ä½ \")\n",
    "            print(\"   - 8Bæ¨¡å‹å¯åœ¨åŒ4090ä¸Šè¿è¡Œ \")\n",
    "            print(f\"\\n Stage 3å¯ä»¥å¤„ç†æ›´å¤§çš„æ¨¡å‹å’Œæ‰¹æ¬¡å¤§å°\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\" è¿›ç¨‹ {rank} Stage 3æµ‹è¯•å¤±è´¥: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "        return False\n",
    "    \n",
    "    return True\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if 'LOCAL_RANK' not in os.environ:\n",
    "        print(\" é”™è¯¯ï¼šæ­¤è„šæœ¬å¿…é¡»é€šè¿‡torchrunå¯åŠ¨\")\n",
    "        print(\"æ­£ç¡®å¯åŠ¨å‘½ä»¤:\")\n",
    "        print(\"   torchrun --nproc_per_node=2 scripts/setup/test_deepspeed.py\")\n",
    "        exit(1)\n",
    "    \n",
    "    success = main()\n",
    "    \n",
    "    if int(os.environ.get('RANK', 0)) == 0:\n",
    "        if success:\n",
    "            print(\"\\n DeepSpeed Stage 3æµ‹è¯•å®Œå…¨é€šè¿‡ï¼\")\n",
    "            print(\" ç»“è®ºï¼šStage 3å¯ä»¥åœ¨åŒ4090ä¸Šè®­ç»ƒ8Bæ¨¡å‹\")\n",
    "        else:\n",
    "            print(\"\\n Stage 3æµ‹è¯•å¤±è´¥ï¼\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c898893",
   "metadata": {},
   "source": [
    "torchrun --nproc_per_node=2 scripts/setup/test_deepspeed.py\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50524fdc",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605211645562.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5461a36a",
   "metadata": {},
   "source": [
    "ç¯å¢ƒæ ¡éªŒæŸ¥çœ‹GPUå˜åŒ–æƒ…å†µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2994d7a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605211722414.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5165f9",
   "metadata": {},
   "source": [
    "æœ€ç»ˆè¾“å‡º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d2663d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250605211744988.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde62dd5",
   "metadata": {},
   "source": [
    "# 2. æ­å»ºå¾®è°ƒé›†ç¾¤ç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdff4575",
   "metadata": {},
   "source": [
    "## 1.åŸºç¡€æ­å»º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af365cf",
   "metadata": {},
   "source": [
    "å½“å‰ç§ŸèµæœåŠ¡å™¨ä¸ºä¸‰å°ï¼Œå¯¹åº”ä¼šå› ç½‘ç»œä¼ é€’é€Ÿåº¦ä¸åŒè°ƒæ•´ä½¿ç”¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe48755b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624105248164.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41e6c530",
   "metadata": {},
   "source": [
    "é¦–å…ˆä½¿ç”¨pingå‘½ä»¤è®¿é—®ç›®æ ‡æœºå™¨ä¿è¯ç½‘ç»œè¿é€šæ€§"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f430f092",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616151248339.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde12c60",
   "metadata": {},
   "source": [
    "```bash   \n",
    "# æœåŠ¡å™¨ä¹‹é—´ç›¸äº’å…å¯†ç™»å½•\n",
    "\n",
    "#åœ¨host0ä¸Šæ‰§è¡Œ \n",
    "ssh-keygen -t rsa -b 4096 -f ~/.ssh/id_rsa -N \"\" \n",
    "```\n",
    "\n",
    "```bash   #æŸ¥çœ‹ç”Ÿæˆçš„å…¬é’¥\n",
    "cat ~/.ssh/id_rsa.pub\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2fdd0a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616151132830.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9f2121a",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#æ–¹æ³•1ï¼šä½¿ç”¨ssh-copy-idï¼ˆæ¨èï¼‰\n",
    "ssh-copy-id -o StrictHostKeyChecking=no ubuntu@10.60.240.249\n",
    "   #æ–¹æ³•2ï¼šå¦‚æœssh-copy-idä¸å¯ç”¨ï¼Œæ‰‹åŠ¨å¤åˆ¶\n",
    "   #å…ˆå¤åˆ¶å…¬é’¥å†…å®¹ï¼Œç„¶ååœ¨host1ä¸Šæ‰§è¡Œï¼š\n",
    "   #mkdir -p ~/.ssh\n",
    "   #echo \"ä½ çš„å…¬é’¥å†…å®¹\" >> ~/.ssh/authorized_keys\n",
    "   #chmod 600 ~/.ssh/authorized_keys\n",
    "   #chmod 700 ~/.ssh\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f651b90",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616151909597.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a521d9d",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#åœ¨host0ä¸Šæµ‹è¯•\n",
    "ssh ubuntu@10.60.240.249 \"hostname && whoami\"\n",
    "  #å¦‚æœæˆåŠŸï¼Œåº”è¯¥æ˜¾ç¤ºhost1çš„ä¸»æœºåå’Œç”¨æˆ·\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d105acbf",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616152026233.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d676d46",
   "metadata": {},
   "source": [
    "host1 ä¹ŸåšåŒæ ·å…å¯†ç™»å½•ï¼Œä»¥åŠåç»­å¦‚æœæœ‰æ›´å¤šæœåŠ¡å™¨å¢åŠ éƒ½è¦å¢åŠ å…å¯†ç™»å½•æ‰“é€šèŠ‚ç‚¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9d2508",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616152322086.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac5f3e1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616152344974.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e65046",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒåŒæ­¥æ–¹å¼ä¸€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fba0022",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#  åšç¯å¢ƒåŒæ­¥(ä¼˜å…ˆåœ¨æœ¬åœ°éªŒè¯ç¯å¢ƒæ²¡é—®é¢˜å†è¿›è¡Œç¯å¢ƒåŒæ­¥)\n",
    "# æ–¹å¼ä¸€ ï¼šå¯¼å‡ºå½“å‰ç¯å¢ƒä¾èµ–åŒ…ç‰ˆæœ¬\n",
    "#åœ¨host0ä¸Šæ‰§è¡Œ\n",
    "conda activate reward\n",
    "  #å¯¼å‡ºå®Œæ•´ç¯å¢ƒ\n",
    "conda env export > /tmp/reward_environment.yml\n",
    "  #å¯¼å‡ºpipåŒ…åˆ—è¡¨ï¼ˆå¤‡ç”¨ï¼‰\n",
    "pip freeze > /tmp/requirements.txt\n",
    "   #æŸ¥çœ‹å…³é”®åŒ…ç‰ˆæœ¬\n",
    "python -c \"\n",
    "import torch, deepspeed, transformers\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'DeepSpeed: {deepspeed.__version__}')  \n",
    "print(f'Transformers: {transformers.__version__}')\n",
    "print(f'CUDA: {torch.version.cuda}')\n",
    "\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2426025a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616152513408.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850bfeea",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#åœ¨host0ä¸Šæ‰§è¡Œ  å½“å‰ç¯å¢ƒç‰ˆæœ¬å‘é€åˆ°ç›®æ ‡æœåŠ¡å™¨ä¸­\n",
    "scp /tmp/reward_environment.yml ubuntu@10.60.240.249:/tmp/\n",
    "scp /tmp/requirements.txt ubuntu@10.60.240.249:/tmp/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7af5da9",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616152600121.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c646a8d2",
   "metadata": {},
   "source": [
    "Host1 è¿›è¡ŒæŸ¥çœ‹ æ ¡éªŒæ˜¯å¦æ”¶åˆ°\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d933e8c1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616152650884.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a734c12",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#æ£€æŸ¥ç›®æ ‡æœåŠ¡å™¨æ˜¯å¦å·²å®‰è£…conda  æ²¡æœ‰çš„è¯è¿›è¡Œå®‰è£…\n",
    "which conda\n",
    "â€‹    wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
    "â€‹    bash Miniconda3-latest-Linux-x86_64.sh -b -p $HOME/miniconda3\n",
    "â€‹    echo 'export PATH=\"$HOME/miniconda3/bin:$PATH\"' >> ~/.bashrc\n",
    "â€‹    source ~/.bashrc\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd47da",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616153759089.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee241ede",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616153843648.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e14ec6b9",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#æ ¹æ®ä¼ è¾“è¿‡æ¥çš„condaå†…å®¹åˆ›å»ºrewardç¯å¢ƒ\n",
    "conda env create -f /tmp/reward_environment.yml\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d852c93a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616154042672.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880b9f1",
   "metadata": {},
   "source": [
    "```bash   \n",
    "\n",
    "#å®‰è£…å®Œæˆæ¿€æ´»ç¯å¢ƒå¹¶éªŒè¯\n",
    "conda activate reward\n",
    "python -c \"\n",
    "import torch, deepspeed, transformers\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'DeepSpeed: {deepspeed.__version__}')\n",
    "print(f'Transformers: {transformers.__version__}')\n",
    "print(f'CUDA Available: {torch.cuda.is_available()}')\n",
    "print(f'GPU Count: {torch.cuda.device_count()}')\n",
    "\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5820a1e9",
   "metadata": {},
   "source": [
    "```bash\n",
    "# é…ç½®condaç¯å¢ƒé•œåƒæº\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free\n",
    "conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forge\n",
    "conda config --add channels defaults\n",
    "conda config --set show_channel_urls true\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea45015",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616155641076.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecc9f86",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616155605679.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9e0c1",
   "metadata": {},
   "source": [
    "é‡åˆ°è¿™ç§æ— æ³•åˆ‡æ¢ä»¥åŠä½¿ç”¨çš„çŠ¶å†µï¼Œå»ºè®®é‡æ–°è¿æ¥æœåŠ¡å™¨"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce6a3e3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616160135411.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f2657b",
   "metadata": {},
   "source": [
    "source ~/.bashrc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691500ac",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616160155467.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd2db9c",
   "metadata": {},
   "source": [
    "## ç¯å¢ƒåŒæ­¥æ–¹å¼äºŒ(æ¨è)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d22080",
   "metadata": {},
   "source": [
    "\n",
    "```bash   \n",
    "# ç¯å¢ƒåŒæ­¥ æ–¹å¼äºŒ ä¸»è¦æƒ³æ³•æ˜¯å°†å½“å‰ç¯å¢ƒè¿›è¡Œæ‰“åŒ…ï¼Œå‘é€åˆ°ç›®æ ‡æœåŠ¡å™¨è§£å‹åå®‰è£…\n",
    "#åœ¨host0ä¸Šæ‰§è¡Œ\n",
    "conda activate reward\n",
    " #æ–¹æ³•1ï¼šä½¿ç”¨conda-packï¼ˆæ¨èï¼‰\n",
    " #å…ˆå®‰è£…conda-pack\n",
    "conda install conda-pack -y\n",
    "  # æ‰“åŒ…ç¯å¢ƒ\n",
    "conda pack -n reward -o reward_env.tar.gz\n",
    "  #ä¼ è¾“åˆ°host1\n",
    "scp reward_env.tar.gz ubuntu@10.60.240.249:/tmp/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e190a60",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616162210429.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedf30dc",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616163038898.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6e46cf",
   "metadata": {},
   "source": [
    "åœ¨host1 ä¸­ç¯å¢ƒæŸ¥çœ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f8bbce",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616163107428.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7158e752",
   "metadata": {},
   "source": [
    "```bash   \n",
    "\n",
    "#åœ¨host1ä¸Šæ‰§è¡Œ\n",
    "#åˆ›å»ºç¯å¢ƒç›®å½•\n",
    "mkdir -p ~/miniconda3/envs/reward\n",
    "\n",
    " #è§£å‹ç¯å¢ƒ\n",
    "cd ~/miniconda3/envs/reward\n",
    "tar -xzf /tmp/reward_env.tar.gz\n",
    "\n",
    "#æ¿€æ´»ç¯å¢ƒ\n",
    "source ~/miniconda3/envs/reward/bin/activate\n",
    "#ä¿®å¤è·¯å¾„\n",
    "conda-unpack\n",
    " #æµ‹è¯•ç¯å¢ƒ\n",
    "python -c \"import torch, deepspeed, transformers; print('Environment OK')\"\n",
    "\n",
    "python -c \"\n",
    "import torch, deepspeed, transformers\n",
    "print(f'PyTorch: {torch.__version__}')\n",
    "print(f'DeepSpeed: {deepspeed.__version__}')\n",
    "print(f'Transformers: {transformers.__version__}')\n",
    "print(f'CUDA Available: {torch.cuda.is_available()}')\n",
    "print(f'GPU Count: {torch.cuda.device_count()}')\n",
    "\"\n",
    "åŒæ­¥å®Œæˆ\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5360ae9",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616172814809.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd441167",
   "metadata": {},
   "source": [
    "## æ•°æ®æŒ‚è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d418f04",
   "metadata": {},
   "source": [
    "### å®‰è£…NFS(å¿…é¡»)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01fd7ab9",
   "metadata": {},
   "source": [
    "```bash   \n",
    "# å½“å‰æ“ä½œä¹Ÿå¯ä»¥ä½¿ç”¨ç›¸äº’åŒæ­¥çš„æ–¹å¼åªè¦ä¿è¯æ¯å°æœåŠ¡å™¨èŠ‚ç‚¹å¯¹åº”æ•°æ®ä»¥åŠç¨‹åºæ–‡ä»¶ç›¸åŒå³å¯\n",
    "#é€€å‡ºcondaç¯å¢ƒï¼Œå›åˆ°ç³»ç»Ÿçº§æ“ä½œ  \n",
    "conda deactivate\n",
    "#å®‰è£…NFSå®¢æˆ·ç«¯\n",
    "sudo apt update\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13459bc0",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616174057336.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "236a4e7c",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#åœ¨host0ä¸Šæ‰§è¡Œ å½“å‰ä½¿ç”¨host0 ä¸ºä¸»èŠ‚ç‚¹\n",
    "sudo apt update\n",
    "sudo apt install nfs-kernel-server -y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea971303",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616174303816.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90457b73",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#åˆ›å»ºå…±äº«ç›®å½•\n",
    "sudo mkdir -p /shared/\n",
    "#è®¾ç½®æƒé™\n",
    "sudo chown -R ubuntu:ubuntu /shared/\n",
    "chmod -R 755 /shared/\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a11ca97",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616174627165.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4d749",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616174652212.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13173b25",
   "metadata": {},
   "source": [
    "å¦‚æœåœ¨åˆ«å¤„å­˜å‚¨æ–‡ä»¶å»ºè®®ç›´æ¥æ”¾åˆ°å…±äº«ç›®å½•ä¸­"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18723f00",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616175224916.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e17d510b",
   "metadata": {},
   "source": [
    "```bash   \n",
    "\n",
    "#é…ç½®NFSå¯¼å‡ºï¼ˆä½¿ç”¨å†…ç½‘ç½‘æ®µï¼‰\n",
    "sudo tee /etc/exports << EOF\n",
    "/shared 10.60.0.0/16(rw,sync,no_subtree_check,no_root_squash,insecure)\n",
    "EOF\n",
    "#å¯åŠ¨NFSæœåŠ¡\n",
    "sudo systemctl enable nfs-kernel-server\n",
    "sudo systemctl start nfs-kernel-server\n",
    "sudo exportfs -ra\n",
    " #éªŒè¯NFSé…ç½®\n",
    "sudo exportfs -v\n",
    "showmount -e localhost\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a42ff84",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616180631692.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc173cab",
   "metadata": {},
   "source": [
    "```bash  \n",
    " #SSHåˆ°host1\n",
    "ssh ubuntu@10.60.240.249\n",
    "#å®‰è£…NFSå®¢æˆ·ç«¯\n",
    "sudo apt update\n",
    "sudo apt install nfs-common -y\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f5c6b44",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616181449090.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e39e634",
   "metadata": {},
   "source": [
    "\n",
    "```bash   \n",
    "#åˆ›å»ºæŒ‚è½½ç‚¹\n",
    "sudo mkdir -p /shared\n",
    "#æµ‹è¯•æŒ‚è½½\n",
    "sudo mount -t nfs 10.60.11.131:/shared /shared\n",
    " #éªŒè¯æŒ‚è½½\n",
    "ls -la /shared/\n",
    "df -h | grep shared \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b4dc91",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616181553612.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95e1db0",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#è®¾ç½®å¼€æœºè‡ªåŠ¨æŒ‚è½½\n",
    "echo \"10.60.11.131:/shared /shared nfs defaults,_netdev 0 0\" | sudo tee -a /etc/fstab\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81132546",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616181635576.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a777926b",
   "metadata": {},
   "source": [
    "```bash\n",
    "# åˆ›å»ºè½¯è¿æ¥(å¯é€‰ çœ‹ä¸ªäººä¹ æƒ¯)\n",
    "ln -s /shared/financial_reward_model /home/ubuntu/financial_reward_model\n",
    "ln -s /shared/QRM-Llama3.1-8B-v2 /home/ubuntu/QRM-Llama3.1-8B-v2\n",
    "ln -s /shared/reward_model_data /home/ubuntu/reward_model_data\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4a68f9",
   "metadata": {},
   "source": [
    "\n",
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616181933571.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a3bff3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616181959724.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a3a94c",
   "metadata": {},
   "source": [
    "### å®‰è£…pdsh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e650683",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#åœ¨host0ä¸Šæ‰§è¡Œ  åªæ˜¯ä¸ºäº†åœ¨å•èŠ‚ç‚¹æ–¹ä¾¿æ§åˆ¶å…¶ä»–æœåŠ¡å™¨\n",
    "sudo apt install pdsh -y\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baed175",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616190355492.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ee4d96",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#åˆ›å»ºPDSHé…ç½®ç›®å½•\n",
    "mkdir -p ~/.pdsh\n",
    "\n",
    " #åˆ›å»ºæœºå™¨åˆ—è¡¨\n",
    "cat > ~/.pdsh/machines << EOF\n",
    "\n",
    " #è®­ç»ƒé›†ç¾¤èŠ‚ç‚¹\n",
    "10.60.11.131   # host0 - ä¸»èŠ‚ç‚¹\n",
    "10.60.240.249  # host1 - ä»èŠ‚ç‚¹\n",
    "EOF\n",
    "\n",
    "#åˆ›å»ºç»„é…ç½®\n",
    "cat > ~/.pdsh/groups << EOF\n",
    "all: 10.60.11.131,10.60.240.249\n",
    "workers: 10.60.240.249\n",
    "master: 10.60.11.131\n",
    "EOF\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ee76473",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616191950570.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0f87e",
   "metadata": {},
   "source": [
    "```bash   \n",
    "# æ·»åŠ è‡ªå·±çš„ä¸»æœºå¯†é’¥åˆ°known_hosts ä¸ªäººä¸»æœºIP\n",
    "ssh-keyscan -H 10.60.240.249 >> ~/.ssh/known_hosts\n",
    "ssh-keyscan -H $(hostname) >> ~/.ssh/known_hosts\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2fc6475",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616205030372.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ea3193",
   "metadata": {},
   "source": [
    "```bash\n",
    "# host0\n",
    "echo 'export PDSH_RCMD_TYPE=ssh' >> ~/.bashrc\n",
    "source ~/.bashrc\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a465343",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616204249403.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a18caf5e",
   "metadata": {},
   "source": [
    "```bash\n",
    "# host0\n",
    "cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys\n",
    "chmod 600 ~/.ssh/authorized_keys\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "586c9d4a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616192205559.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45600e60",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#æµ‹è¯•PDSHè¿æ¥\n",
    "pdsh -w 10.60.11.131,10.60.240.249 \"nvidia-smi --query-gpu=count --format=csv,noheader,nounits\"\n",
    "pdsh -w 10.60.11.131,10.60.240.249 'echo \"$(hostname): $(whoami) - $(date)\"'\n",
    "pdsh -w 10.60.11.131,10.60.240.249 \"hostname\"\n",
    "pdsh -w 10.60.11.131,10.60.240.249 'echo \"PDSH test from $(hostname)\"'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c67d4d39",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616192253895.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801edb44",
   "metadata": {},
   "source": [
    "```bash   \n",
    "#å®‰è£…å®Œæˆåé…ç½®é˜²ç«å¢™ å½“å‰åªæ˜¯é˜²ç«å¢™é…ç½® ä¹Ÿå¯ä»¥ä¸ä½¿ç”¨pdshå•ç‹¬æ‰§è¡Œ\n",
    "\n",
    "pdsh -w 10.60.11.131,10.60.240.249 \"\n",
    "â€‹    echo '=== \\$(hostname) é…ç½®é˜²ç«å¢™ ===' && \\\n",
    "â€‹    sudo ufw --force enable && \\\n",
    "â€‹    sudo ufw allow 22 && \\\n",
    "â€‹    sudo ufw allow 29500 && \\\n",
    "â€‹    sudo ufw allow 29501 && \\Â·\n",
    "â€‹    sudo ufw allow 2049 && \\\n",
    "â€‹    sudo ufw allow from 10.60.0.0/16 && \\\n",
    "â€‹    sudo ufw status numbered\n",
    "\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49712034",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250616205304441.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e541f2",
   "metadata": {},
   "source": [
    "```bash \n",
    "# ä¸¤ä¸ªèŠ‚ç‚¹éƒ½éœ€è¦\n",
    "sudo apt update\n",
    "sudo apt install -y ninja-build\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2448bdff",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250617191918965.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbb78ca",
   "metadata": {},
   "source": [
    "# 3. å¾®è°ƒé¡¹ç›®æ„å»º  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc66308e",
   "metadata": {},
   "source": [
    "é›†ç¾¤æ­å»º"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6283c279",
   "metadata": {},
   "source": [
    "ä»¥ä¸Šä¸»è¦ä¸»è¦ä¾èµ–ç‰ˆæœ¬é€‚ç”¨äºQRM-Llama3.1-8B-v2æ¨¡å‹å¾®è°ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3fc544",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Skywork/Skywork-Reward-Llama-3.1-8Bç‰ˆæœ¬ç¯å¢ƒ\n",
    "conda create -n reward2 python=3.11 -y\n",
    "pip install torch==2.5.1 torchvision==0.20.1 torchaudio==2.5.1  -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "pip install accelerate==0.29.3 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "pip install transformers==4.51.3 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "pip install deepspeed==0.15.4 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "pip install datasets==2.14.0 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe123142",
   "metadata": {},
   "source": [
    "## é¡¹ç›®æ•´ä½“ç»“æ„åˆ†æ\n",
    "\n",
    "è¿™æ˜¯ä¸€ä¸ªåŸºäºLLaMA-3.1-8Bçš„å¥–åŠ±æ¨¡å‹è®­ç»ƒå’Œéƒ¨ç½²é¡¹ç›®ï¼Œç”¨äºè¯„ä¼°AIå›ç­”çš„è´¨é‡ï¼Œé€šè¿‡å¯¹æ¯”å­¦ä¹ è®­ç»ƒæ¨¡å‹åˆ¤æ–­å“ªä¸ªå›ç­”æ›´å¥½ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6046d4",
   "metadata": {},
   "source": [
    "\n",
    "### æ ¸å¿ƒç›®å½•ç»“æ„\n",
    "\n",
    "```json\n",
    "financial_reward_model/\n",
    "â”œâ”€â”€ configs/           # é…ç½®æ–‡ä»¶ç›®å½•\n",
    "â”œâ”€â”€ src/              # æºä»£ç ç›®å½•  \n",
    "â”œâ”€â”€ scripts/          # è„šæœ¬å·¥å…·ç›®å½•\n",
    "â”œâ”€â”€ inference/        # æ¨ç†éƒ¨ç½²ç›®å½•\n",
    "â””â”€â”€ deploy.sh         # éƒ¨ç½²è„šæœ¬\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f87ce18",
   "metadata": {},
   "source": [
    "### 1. **`configs/` - é…ç½®ç®¡ç†ä¸­å¿ƒ**\n",
    "```json\n",
    "configs/\n",
    "â”œâ”€â”€ training/\n",
    "    â”œâ”€â”€ config.json           # è®­ç»ƒä¸»é…ç½®æ–‡ä»¶\n",
    "    â””â”€â”€ deepspeed_only.json   # DeepSpeedä¼˜åŒ–é…ç½®\n",
    "```\n",
    "\n",
    "**ä½œç”¨**ï¼š\n",
    "- `config.json`ï¼šæ ¸å¿ƒè®­ç»ƒå‚æ•°ï¼ˆå­¦ä¹ ç‡ã€æ‰¹æ¬¡å¤§å°ã€æ¨¡å‹è·¯å¾„ã€freeze tuningé…ç½®ç­‰ï¼‰\n",
    "- `deepspeed_only.json`ï¼šDeepSpeed Stage 2é…ç½®ï¼Œå®ç°å†…å­˜ä¼˜åŒ–å’Œåˆ†å¸ƒå¼è®­ç»ƒ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd2fd8b4",
   "metadata": {},
   "source": [
    "\n",
    "### 2. **`src/` - æ ¸å¿ƒä»£ç æ¨¡å—**\n",
    "```json\n",
    "src/\n",
    "â”œâ”€â”€ train_reward_model.py     # ä¸»è®­ç»ƒè„šæœ¬ \n",
    "â””â”€â”€ data/\n",
    "    â””â”€â”€ dataset.py           # æ•°æ®å¤„ç†æ¨¡å—\n",
    "```\n",
    "\n",
    "**æ ¸å¿ƒåŠŸèƒ½**ï¼š\n",
    "- **`train_reward_model.py`**ï¼šæ•´ä¸ªé¡¹ç›®çš„è®­ç»ƒæ ¸å¿ƒ\n",
    "  - DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒ\n",
    "  - Freeze tuningï¼ˆåªè®­ç»ƒæœ€å4å±‚ï¼‰\n",
    "  - è‡ªå®šä¹‰RewardTrainerç±»\n",
    "  \n",
    "- **`dataset.py`**ï¼šæ•°æ®å¤„ç†å¼•æ“\n",
    "  - åŠ è½½preferenceæ•°æ®ï¼ˆquestion/chosen/rejectedæ ¼å¼ï¼‰\n",
    "  - LLaMA-3å¯¹è¯æ ¼å¼è½¬æ¢\n",
    "  - è‡ªå®šä¹‰PairwiseDataCollator\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3add30d2",
   "metadata": {},
   "source": [
    "\n",
    "### 3. **`scripts/` - å·¥å…·è„šæœ¬é›†åˆ**\n",
    "```json\n",
    "scripts/\n",
    "â”œâ”€â”€ setup/                    # ç¯å¢ƒé…ç½®å·¥å…·\n",
    "â”‚   â”œâ”€â”€ check_data.py        # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥\n",
    "â”‚   â””â”€â”€ test_deepspeed.py    # DeepSpeedåŠŸèƒ½æµ‹è¯•\n",
    "â””â”€â”€ training/                # è®­ç»ƒå¯åŠ¨å·¥å…·\n",
    "    â”œâ”€â”€ deepspeed_cluster_launcher.sh  # å¤šæœºåˆ†å¸ƒå¼å¯åŠ¨è„šæœ¬ \n",
    "    â””â”€â”€ run_training.sh              # å•æœºè®­ç»ƒè„šæœ¬\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c1f5c3",
   "metadata": {},
   "source": [
    "\n",
    "**å…³é”®è„šæœ¬**ï¼š\n",
    "- **`deepspeed_cluster_launcher.sh`**ï¼šå®é™…ä½¿ç”¨çš„åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨å™¨\n",
    "  - ç®¡ç†10.60.11.131(4GPU) + 10.60.240.249(2GPU)é›†ç¾¤\n",
    "  - è‡ªåŠ¨åˆ›å»ºhostfileé…ç½®\n",
    "  - æ”¯æŒstart/stop/logs/resumeæ“ä½œ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f271f8",
   "metadata": {},
   "source": [
    "\n",
    "### 4. **`inference/` - æ¨ç†éƒ¨ç½²æ¨¡å—**\n",
    "```json\n",
    "inference/\n",
    "â”œâ”€â”€ ray_reward_service.py     # Rayåˆ†å¸ƒå¼æ¨ç†æœåŠ¡ \n",
    "â”œâ”€â”€ test_ray_service.py       # æ¨¡å‹éªŒè¯æµ‹è¯•å·¥å…·\n",
    "â”œâ”€â”€ start_ray_cluster.sh      # Rayé›†ç¾¤å¯åŠ¨è„šæœ¬\n",
    "â””â”€â”€ debug_response.py         # è°ƒè¯•å·¥å…·\n",
    "```\n",
    "\n",
    "**éƒ¨ç½²æ¶æ„**ï¼š\n",
    "- **Ray Serve**ï¼šåˆ†å¸ƒå¼æ¨ç†æ¡†æ¶ï¼Œæ”¯æŒå¤šGPUè´Ÿè½½å‡è¡¡\n",
    "- **éªŒè¯æµç¨‹**ï¼šåŠ è½½æµ‹è¯•æ•°æ® â†’ å¹¶å‘æ¨ç† â†’ è®¡ç®—å‡†ç¡®ç‡\n",
    "- **å¥åº·æ£€æŸ¥**ï¼šæä¾›æœåŠ¡çŠ¶æ€ç›‘æ§\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3670616e",
   "metadata": {},
   "source": [
    "\n",
    "##  **å®Œæ•´å·¥ä½œæµç¨‹**\n",
    "\n",
    "### **è®­ç»ƒé˜¶æ®µ**\n",
    "```bash\n",
    "# 1. å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ\n",
    "bash scripts/training/deepspeed_cluster_launcher.sh start\n",
    "\n",
    "# 2. ç›‘æ§è®­ç»ƒæ—¥å¿—  \n",
    "bash scripts/training/deepspeed_cluster_launcher.sh logs\n",
    "\n",
    "# 3. ä»checkpointæ¢å¤\n",
    "bash scripts/training/deepspeed_cluster_launcher.sh resume output/checkpoint-700\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3327e3",
   "metadata": {},
   "source": [
    "æ•°æ®ç»“æ„\n",
    "```json\n",
    "output_dir/\n",
    "â”œâ”€â”€ train/\n",
    "â”‚   â”œâ”€â”€ qa_dataset.jsonl          # é—®é¢˜-ç­”æ¡ˆæ ¼å¼\n",
    "â”‚   â””â”€â”€ preference_dataset.jsonl  # åå¥½å¯¹æ ¼å¼\n",
    "â”œâ”€â”€ eval/\n",
    "â”‚   â”œâ”€â”€ qa_dataset.jsonl\n",
    "â”‚   â””â”€â”€ preference_dataset.jsonl\n",
    "â””â”€â”€ test/\n",
    "    â”œâ”€â”€ qa_dataset.jsonl\n",
    "    â””â”€â”€ preference_dataset.jsonl\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731d68c",
   "metadata": {},
   "source": [
    "dataset.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50a4b10c",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "================================================================================\n",
    " æ–‡ä»¶ä½œç”¨è¯´æ˜ï¼š\n",
    "è¿™æ˜¯å¥–åŠ±æ¨¡å‹çš„æ•°æ®å¤„ç†æ ¸å¿ƒæ¨¡å—ï¼Œè´Ÿè´£preferenceæ•°æ®çš„åŠ è½½å’Œå¤„ç†\n",
    "\n",
    " é¡¹ç›®ä¸­çš„æ•´ä½“ä½œç”¨ï¼š\n",
    "1. ã€æ•°æ®åŠ è½½ã€‘ï¼šåŠ è½½åŒ…å«chosen/rejectedå›ç­”å¯¹çš„preferenceæ•°æ®\n",
    "2. ã€æ ¼å¼è½¬æ¢ã€‘ï¼šå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ ¼å¼\n",
    "3. ã€åˆ†è¯å¤„ç†ã€‘ï¼šä½¿ç”¨tokenizerå°†æ–‡æœ¬è½¬æ¢ä¸ºtokenåºåˆ—\n",
    "4. ã€æ‰¹æ¬¡æ•´ç†ã€‘ï¼šæä¾›æ•°æ®æ•´ç†å™¨ï¼Œå°†å¤šä¸ªæ ·æœ¬ç»„ç»‡æˆè®­ç»ƒæ‰¹æ¬¡\n",
    "5. ã€LLaMAæ ¼å¼ã€‘ï¼šæŒ‰ç…§LLaMA-3çš„å¯¹è¯æ ¼å¼å¤„ç†æ•°æ®\n",
    "\n",
    " æ•°æ®æµç¨‹ï¼š\n",
    "åŸå§‹JSON â†’ åŠ è½½æ•°æ® â†’ æ ¼å¼åŒ–å¯¹è¯ â†’ åˆ†è¯ â†’ åˆ›å»ºæ•°æ®é›† â†’ æ‰¹æ¬¡æ•´ç† â†’ è®­ç»ƒ\n",
    "================================================================================\n",
    "\"\"\"\n",
    "\n",
    "import json\n",
    "import os\n",
    "from collections import defaultdict\n",
    "from typing import Dict, List, Optional, Any\n",
    "from transformers import PreTrainedTokenizer\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#  é‡‘èå¥–åŠ±æ•°æ®é›†ç±»ï¼šæ ¸å¿ƒçš„æ•°æ®å¤„ç†ç±»\n",
    "# \n",
    "#  è¿™ä¸ªç±»åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š\n",
    "# 1. ã€æ•°æ®æ ¸å¿ƒã€‘ï¼šæ•´ä¸ªå¥–åŠ±æ¨¡å‹è®­ç»ƒçš„æ•°æ®å¤„ç†æ ¸å¿ƒ\n",
    "# 2. ã€æ ¼å¼ç»Ÿä¸€ã€‘ï¼šå°†ä¸åŒæ ¼å¼çš„preferenceæ•°æ®ç»Ÿä¸€å¤„ç†\n",
    "# 3. ã€LLaMAé€‚é…ã€‘ï¼šä¸“é—¨é€‚é…LLaMA-3æ¨¡å‹çš„å¯¹è¯æ ¼å¼\n",
    "# 4. ã€å†…å­˜é«˜æ•ˆã€‘ï¼šé‡‡ç”¨æ‡’åŠ è½½æ–¹å¼ï¼ŒèŠ‚çœå†…å­˜ä½¿ç”¨\n",
    "# ============================================================================\n",
    "class FinancialRewardDataset:\n",
    "    \"\"\"\n",
    "    é‡‘èå¥–åŠ±æ•°æ®é›†å¤„ç†ç±»\n",
    "    \n",
    "    è¿™ä¸ªç±»è´Ÿè´£å¤„ç†åŒ…å«chosen/rejectedå›ç­”å¯¹çš„æ•°æ®ï¼š\n",
    "    - åŠ è½½JSONLæ ¼å¼çš„preferenceæ•°æ®\n",
    "    - è½¬æ¢ä¸ºLLaMA-3çš„å¯¹è¯æ ¼å¼\n",
    "    - æä¾›ç»™è®­ç»ƒå™¨ä½¿ç”¨çš„æ ‡å‡†æ•°æ®é›†\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,                    # æ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "        tokenizer: PreTrainedTokenizer,    # åˆ†è¯å™¨\n",
    "        max_length: int = 2048,            # æœ€å¤§åºåˆ—é•¿åº¦\n",
    "        split: str = \"train\"               # æ•°æ®é›†åˆ†å‰²ï¼ˆtrain/evalï¼‰\n",
    "    ):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ•°æ®é›†\n",
    "        \n",
    "        åˆå§‹åŒ–è¿‡ç¨‹ï¼š\n",
    "        1. ä¿å­˜é…ç½®å‚æ•°\n",
    "        2. ç¡®å®šæ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "        3. åŠ è½½åŸå§‹æ•°æ®åˆ°å†…å­˜\n",
    "        4. æ‰“å°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer      # ä¿å­˜åˆ†è¯å™¨å¼•ç”¨\n",
    "        self.max_length = max_length    # ä¿å­˜æœ€å¤§é•¿åº¦è®¾ç½®\n",
    "        self.split = split             # ä¿å­˜æ•°æ®é›†ç±»å‹\n",
    "        \n",
    "        # æ ¹æ®splitå‚æ•°ç¡®å®šæ•°æ®æ–‡ä»¶è·¯å¾„\n",
    "        if split == \"train\":\n",
    "            data_file = os.path.join(data_path, \"train\", \"preference_dataset.jsonl\")\n",
    "        else:\n",
    "            data_file = os.path.join(data_path, \"eval\", \"preference_dataset.jsonl\")\n",
    "        \n",
    "        # åŠ è½½åŸå§‹æ•°æ®ï¼šè¯»å–JSONLæ–‡ä»¶ï¼Œæ¯è¡Œæ˜¯ä¸€ä¸ªJSONå¯¹è±¡\n",
    "        with open(data_file, 'r', encoding='utf-8') as f:\n",
    "            self.raw_data = [json.loads(line) for line in f]\n",
    "        \n",
    "        print(f\"{split.upper()} æ•°æ®é›†å¤§å°: {len(self.raw_data)}\")\n",
    "    \n",
    "    def preprocess_dataset(self) -> Dict[str, List[Any]]:\n",
    "        \"\"\"\n",
    "        é¢„å¤„ç†æ•°æ®é›†ï¼šå°†åŸå§‹æ•°æ®è½¬æ¢ä¸ºæ¨¡å‹è®­ç»ƒæ ¼å¼\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•çš„ä½œç”¨ï¼š\n",
    "        1. ã€æ ¼å¼è½¬æ¢ã€‘ï¼šå°†question+chosen/rejectedè½¬æ¢ä¸ºå®Œæ•´å¯¹è¯\n",
    "        2. ã€LLaMAæ ¼å¼ã€‘ï¼šä½¿ç”¨LLaMA-3çš„ç‰¹æ®Štokenæ ¼å¼åŒ–å¯¹è¯\n",
    "        3. ã€åˆ†è¯å¤„ç†ã€‘ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºtoken IDåºåˆ—\n",
    "        4. ã€æ•°æ®ç»„ç»‡ã€‘ï¼šç»„ç»‡æˆchosen/rejectedå¯¹çš„å½¢å¼ä¾›è®­ç»ƒä½¿ç”¨\n",
    "        \n",
    "        æ•°æ®æ ¼å¼è½¬æ¢ï¼š\n",
    "        è¾“å…¥ï¼š{\"question\": \"...\", \"chosen\": \"...\", \"rejected\": \"...\"}\n",
    "        è¾“å‡ºï¼š{\"chosen_input_ids\": [...], \"rejected_input_ids\": [...], ...}\n",
    "        \"\"\"\n",
    "        model_inputs = defaultdict(list)  # ç”¨äºæ”¶é›†å¤„ç†åçš„æ•°æ®\n",
    "        \n",
    "        # éå†æ‰€æœ‰åŸå§‹æ•°æ®é¡¹\n",
    "        for item in self.raw_data:\n",
    "            # æå–æ•°æ®çš„ä¸‰ä¸ªæ ¸å¿ƒéƒ¨åˆ†\n",
    "            question = item[\"question\"]    # ç”¨æˆ·é—®é¢˜\n",
    "            chosen = item[\"chosen\"]        # äººç±»åå¥½çš„å›ç­”ï¼ˆå¥½å›ç­”ï¼‰\n",
    "            rejected = item[\"rejected\"]    # äººç±»ä¸åå¥½çš„å›ç­”ï¼ˆå·®å›ç­”ï¼‰\n",
    "            \n",
    "            # æ„å»ºLLaMA-3æ ¼å¼çš„å¯¹è¯prompt\n",
    "            # è¿™ä¸ªæ ¼å¼åŒ…å«ç‰¹æ®Šçš„å¯¹è¯æ§åˆ¶token\n",
    "            prompt_text = f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
    "            \n",
    "            # å¤„ç†chosenå›ç­”ï¼šprompt + chosenå›ç­” + ç»“æŸtoken\n",
    "            chosen_full = prompt_text + chosen + \"<|eot_id|>\"\n",
    "            chosen_inputs = self.tokenizer(\n",
    "                chosen_full,\n",
    "                truncation=True,              # å¦‚æœè¶…é•¿åˆ™æˆªæ–­\n",
    "                max_length=self.max_length,   # æœ€å¤§é•¿åº¦é™åˆ¶\n",
    "                return_tensors=None           # è¿”å›Python listè€Œä¸æ˜¯tensor\n",
    "            )\n",
    "            \n",
    "            # å¤„ç†rejectedå›ç­”ï¼šprompt + rejectedå›ç­” + ç»“æŸtoken\n",
    "            rejected_full = prompt_text + rejected + \"<|eot_id|>\"\n",
    "            rejected_inputs = self.tokenizer(\n",
    "                rejected_full,\n",
    "                truncation=True,              # å¦‚æœè¶…é•¿åˆ™æˆªæ–­\n",
    "                max_length=self.max_length,   # æœ€å¤§é•¿åº¦é™åˆ¶\n",
    "                return_tensors=None           # è¿”å›Python listè€Œä¸æ˜¯tensor\n",
    "            )\n",
    "            \n",
    "            # å°†å¤„ç†åçš„æ•°æ®æ·»åŠ åˆ°ç»“æœä¸­\n",
    "            model_inputs[\"chosen_input_ids\"].append(chosen_inputs[\"input_ids\"])\n",
    "            model_inputs[\"chosen_attention_mask\"].append(chosen_inputs[\"attention_mask\"])\n",
    "            model_inputs[\"rejected_input_ids\"].append(rejected_inputs[\"input_ids\"])\n",
    "            model_inputs[\"rejected_attention_mask\"].append(rejected_inputs[\"attention_mask\"])\n",
    "        \n",
    "        return model_inputs\n",
    "    \n",
    "    def to_dataset(self) -> Dataset:\n",
    "        \"\"\"\n",
    "        è½¬æ¢ä¸ºHuggingFace Datasetæ ¼å¼\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•çš„ä½œç”¨ï¼š\n",
    "        1. ã€æ ‡å‡†åŒ–ã€‘ï¼šè½¬æ¢ä¸ºHuggingFaceç”Ÿæ€ç³»ç»Ÿçš„æ ‡å‡†æ•°æ®æ ¼å¼\n",
    "        2. ã€å…¼å®¹æ€§ã€‘ï¼šç¡®ä¿ä¸Transformersåº“çš„Trainerå®Œå…¨å…¼å®¹\n",
    "        3. ã€æ€§èƒ½ä¼˜åŒ–ã€‘ï¼šåˆ©ç”¨HuggingFace Datasetçš„ä¼˜åŒ–åŠŸèƒ½\n",
    "        \n",
    "        æ³¨æ„ï¼šè¿™ä¸ªæ–¹æ³•åœ¨é¡¹ç›®ä¸­è¢«train_reward_model.pyè°ƒç”¨\n",
    "        \"\"\"\n",
    "        processed_data = self.preprocess_dataset()  # è·å–é¢„å¤„ç†åçš„æ•°æ®\n",
    "        return Dataset.from_dict(processed_data)    # è½¬æ¢ä¸ºHuggingFace Dataset\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#  åˆ›å»ºæ•°æ®é›†çš„ä¾¿æ·å‡½æ•°ï¼šé¡¹ç›®çš„å¯¹å¤–æ¥å£\n",
    "# \n",
    "#  è¿™ä¸ªå‡½æ•°åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š\n",
    "# 1. ã€å¯¹å¤–æ¥å£ã€‘ï¼šè¿™æ˜¯train_reward_model.pyå®é™…è°ƒç”¨çš„å‡½æ•°\n",
    "# 2. ã€åŒæ—¶åˆ›å»ºã€‘ï¼šä¸€æ¬¡æ€§åˆ›å»ºè®­ç»ƒé›†å’ŒéªŒè¯é›†\n",
    "# 3. ã€ç®€åŒ–è°ƒç”¨ã€‘ï¼šç®€åŒ–æ•°æ®é›†åˆ›å»ºçš„å¤æ‚åº¦\n",
    "# 4. ã€è¿”å›æ ‡å‡†ã€‘ï¼šè¿”å›æ ‡å‡†çš„HuggingFace Datasetå¯¹è±¡\n",
    "# ============================================================================\n",
    "def create_reward_dataset(data_path: str, tokenizer: PreTrainedTokenizer, max_length: int = 2048):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºè®­ç»ƒå’Œè¯„ä¼°æ•°æ®é›†çš„ä¸»è¦æ¥å£\n",
    "    \n",
    "    è¿™ä¸ªå‡½æ•°æ˜¯é¡¹ç›®ä¸­train_reward_model.pyè°ƒç”¨çš„ä¸»è¦æ•°æ®æ¥å£ï¼š\n",
    "    1. åˆ›å»ºè®­ç»ƒæ•°æ®é›†\n",
    "    2. åˆ›å»ºéªŒè¯æ•°æ®é›†\n",
    "    3. è¿”å›ä¸¤ä¸ªæ•°æ®é›†ä¾›è®­ç»ƒä½¿ç”¨\n",
    "    \n",
    "    å‚æ•°è¯´æ˜ï¼š\n",
    "    - data_path: æ•°æ®æ ¹ç›®å½•è·¯å¾„\n",
    "    - tokenizer: ç”¨äºåˆ†è¯çš„tokenizer\n",
    "    - max_length: åºåˆ—çš„æœ€å¤§é•¿åº¦\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - train_dataset: è®­ç»ƒæ•°æ®é›†\n",
    "    - eval_dataset: éªŒè¯æ•°æ®é›†\n",
    "    \"\"\"\n",
    "    # åˆ›å»ºè®­ç»ƒæ•°æ®é›†\n",
    "    train_data = FinancialRewardDataset(data_path, tokenizer, max_length, \"train\")\n",
    "    \n",
    "    # åˆ›å»ºéªŒè¯æ•°æ®é›†\n",
    "    eval_data = FinancialRewardDataset(data_path, tokenizer, max_length, \"eval\")\n",
    "    \n",
    "    # è½¬æ¢ä¸ºHuggingFace Datasetæ ¼å¼å¹¶è¿”å›\n",
    "    return train_data.to_dataset(), eval_data.to_dataset()\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#  Pairwiseæ•°æ®æ•´ç†å™¨ï¼šä¸“é—¨å¤„ç†chosen/rejectedæ•°æ®å¯¹çš„æ‰¹æ¬¡æ•´ç†\n",
    "# \n",
    "#  è¿™ä¸ªç±»åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š\n",
    "# 1. ã€æ‰¹æ¬¡å¤„ç†ã€‘ï¼šå°†å¤šä¸ªæ•°æ®æ ·æœ¬ç»„ç»‡æˆè®­ç»ƒæ‰¹æ¬¡\n",
    "# 2. ã€é•¿åº¦å¯¹é½ã€‘ï¼šé€šè¿‡paddingå°†ä¸åŒé•¿åº¦çš„åºåˆ—å¯¹é½\n",
    "# 3. ã€å†…å­˜ä¼˜åŒ–ã€‘ï¼šé«˜æ•ˆåœ°ç»„ç»‡æ•°æ®ï¼Œå‡å°‘å†…å­˜æµªè´¹\n",
    "# 4. ã€è®­ç»ƒé…åˆã€‘ï¼šä¸SafeRewardTrainerçš„compute_lossæ–¹æ³•å®Œç¾é…åˆ\n",
    "# ============================================================================\n",
    "class PairwiseDataCollator:\n",
    "    \"\"\"\n",
    "    Pairwiseæ•°æ®æ•´ç†å™¨ - ä¸“é—¨å¤„ç†å¥–åŠ±æ¨¡å‹çš„chosen/rejectedæ•°æ®\n",
    "    \n",
    "    è¿™ä¸ªç±»çš„æ ¸å¿ƒåŠŸèƒ½ï¼š\n",
    "    - å°†ä¸€ä¸ªbatchä¸­çš„æ‰€æœ‰chosenå›ç­”paddingåˆ°ç›¸åŒé•¿åº¦\n",
    "    - å°†ä¸€ä¸ªbatchä¸­çš„æ‰€æœ‰rejectedå›ç­”paddingåˆ°ç›¸åŒé•¿åº¦\n",
    "    - ç»„ç»‡æ•°æ®æ ¼å¼ä¾›SafeRewardTrainerä½¿ç”¨\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer, padding: str = \"longest\"):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–æ•°æ®æ•´ç†å™¨\n",
    "        \n",
    "        å‚æ•°è¯´æ˜ï¼š\n",
    "        - tokenizer: ç”¨äºpaddingçš„åˆ†è¯å™¨\n",
    "        - padding: paddingç­–ç•¥ï¼Œ\"longest\"è¡¨ç¤ºpaddingåˆ°batchä¸­æœ€é•¿çš„åºåˆ—\n",
    "        \"\"\"\n",
    "        self.tokenizer = tokenizer    # ä¿å­˜åˆ†è¯å™¨å¼•ç”¨\n",
    "        self.padding = padding        # ä¿å­˜paddingç­–ç•¥\n",
    "\n",
    "    def __call__(self, features: List[Dict[str, Any]]) -> Dict[str, Any]:\n",
    "        \"\"\"\n",
    "        æ•´ç†ä¸€ä¸ªbatchçš„pairwiseæ•°æ®\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•çš„ä½œç”¨ï¼š\n",
    "        1. ã€æ•°æ®åˆ†ç¦»ã€‘ï¼šå°†chosenå’Œrejectedæ•°æ®åˆ†åˆ«å¤„ç†\n",
    "        2. ã€æ‰¹æ¬¡paddingã€‘ï¼šå¯¹æ¯ç»„æ•°æ®åˆ†åˆ«è¿›è¡Œpadding\n",
    "        3. ã€æ ¼å¼ç»„ç»‡ã€‘ï¼šç»„ç»‡æˆè®­ç»ƒå™¨æœŸæœ›çš„æ ¼å¼\n",
    "        \n",
    "        å¤„ç†æµç¨‹ï¼š\n",
    "        è¾“å…¥ï¼š[{chosen_input_ids: [...], rejected_input_ids: [...]}, ...]\n",
    "        è¾“å‡ºï¼š{chosen_input_ids: tensor, rejected_input_ids: tensor, ...}\n",
    "        \"\"\"\n",
    "        import torch\n",
    "        \n",
    "        # ç¬¬1æ­¥ï¼šåˆ†ç¦»chosenå’Œrejectedæ•°æ®\n",
    "        chosen_features = []    # æ”¶é›†æ‰€æœ‰chosenå›ç­”çš„æ•°æ®\n",
    "        rejected_features = []  # æ”¶é›†æ‰€æœ‰rejectedå›ç­”çš„æ•°æ®\n",
    "        \n",
    "        for feature in features:\n",
    "            # æå–chosenå›ç­”çš„æ•°æ®\n",
    "            chosen_features.append({\n",
    "                \"input_ids\": feature[\"chosen_input_ids\"],\n",
    "                \"attention_mask\": feature[\"chosen_attention_mask\"]\n",
    "            })\n",
    "            # æå–rejectedå›ç­”çš„æ•°æ®\n",
    "            rejected_features.append({\n",
    "                \"input_ids\": feature[\"rejected_input_ids\"], \n",
    "                \"attention_mask\": feature[\"rejected_attention_mask\"]\n",
    "            })\n",
    "        \n",
    "        # ç¬¬2æ­¥ï¼šåˆ†åˆ«å¯¹chosenå’Œrejectedæ•°æ®è¿›è¡Œpadding\n",
    "        chosen_batch = self.tokenizer.pad(\n",
    "            chosen_features,\n",
    "            padding=self.padding,     # ä½¿ç”¨æŒ‡å®šçš„paddingç­–ç•¥\n",
    "            return_tensors=\"pt\"       # è¿”å›PyTorch tensor\n",
    "        )\n",
    "        \n",
    "        rejected_batch = self.tokenizer.pad(\n",
    "            rejected_features,\n",
    "            padding=self.padding,     # ä½¿ç”¨æŒ‡å®šçš„paddingç­–ç•¥\n",
    "            return_tensors=\"pt\"       # è¿”å›PyTorch tensor\n",
    "        )\n",
    "        \n",
    "        # ç¬¬3æ­¥ï¼šç»„åˆä¸ºæœ€ç»ˆçš„batchæ ¼å¼\n",
    "        # è¿™ä¸ªæ ¼å¼æ­£å¥½æ˜¯SafeRewardTrainer.compute_lossæ–¹æ³•æœŸæœ›çš„è¾“å…¥\n",
    "        return {\n",
    "            \"chosen_input_ids\": chosen_batch[\"input_ids\"],           # chosenå›ç­”çš„token IDs\n",
    "            \"chosen_attention_mask\": chosen_batch[\"attention_mask\"], # chosenå›ç­”çš„æ³¨æ„åŠ›æ©ç \n",
    "            \"rejected_input_ids\": rejected_batch[\"input_ids\"],       # rejectedå›ç­”çš„token IDs\n",
    "            \"rejected_attention_mask\": rejected_batch[\"attention_mask\"], # rejectedå›ç­”çš„æ³¨æ„åŠ›æ©ç \n",
    "        }\n",
    "\n",
    "\n",
    "# ============================================================================\n",
    "#  åˆ›å»ºæ•°æ®æ•´ç†å™¨çš„ä¾¿æ·å‡½æ•°ï¼šé¡¹ç›®çš„æ ‡å‡†æ¥å£\n",
    "# \n",
    "#  è¿™ä¸ªå‡½æ•°åœ¨é¡¹ç›®ä¸­çš„ä½œç”¨ï¼š\n",
    "# 1. ã€æ ‡å‡†æ¥å£ã€‘ï¼šè¿™æ˜¯train_reward_model.pyè°ƒç”¨çš„æ ‡å‡†æ¥å£\n",
    "# 2. ã€ç®€åŒ–åˆ›å»ºã€‘ï¼šç®€åŒ–PairwiseDataCollatorçš„åˆ›å»ºè¿‡ç¨‹\n",
    "# 3. ã€é…ç½®ç»Ÿä¸€ã€‘ï¼šä½¿ç”¨ç»Ÿä¸€çš„é»˜è®¤é…ç½®\n",
    "# \n",
    "# âš ï¸ æ³¨æ„ï¼šè¿™ä¸ªå‡½æ•°åœ¨train_reward_model.pyä¸­è¢«è°ƒç”¨\n",
    "# ============================================================================\n",
    "def create_data_collator(tokenizer: PreTrainedTokenizer):\n",
    "    \"\"\"\n",
    "    åˆ›å»ºpairwiseæ•°æ®æ•´ç†å™¨çš„ä¾¿æ·å‡½æ•°\n",
    "    \n",
    "    è¿™ä¸ªå‡½æ•°æ˜¯train_reward_model.pyä¸­è°ƒç”¨çš„æ ‡å‡†æ¥å£ï¼š\n",
    "    - åˆ›å»ºå¹¶è¿”å›é…ç½®å¥½çš„PairwiseDataCollator\n",
    "    - ä½¿ç”¨\"longest\"paddingç­–ç•¥ï¼ˆpaddingåˆ°batchä¸­æœ€é•¿åºåˆ—çš„é•¿åº¦ï¼‰\n",
    "    \n",
    "    å‚æ•°è¯´æ˜ï¼š\n",
    "    - tokenizer: ç”¨äºpaddingçš„åˆ†è¯å™¨\n",
    "    \n",
    "    è¿”å›ï¼š\n",
    "    - PairwiseDataCollatorå®ä¾‹\n",
    "    \"\"\"\n",
    "    return PairwiseDataCollator(tokenizer, padding=\"longest\") \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f77990f",
   "metadata": {},
   "source": [
    "train_reward_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2af63ea",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\"\"\"\n",
    "Skyworkå¥–åŠ±æ¨¡å‹å¾®è°ƒè„šæœ¬\n",
    "åŸºäºLlamaForSequenceClassificationæ¶æ„\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import json\n",
    "import deepspeed\n",
    "import argparse\n",
    "from dataclasses import dataclass, field\n",
    "from typing import Optional\n",
    "from transformers import (\n",
    "    AutoTokenizer, AutoConfig, AutoModelForSequenceClassification,\n",
    "    TrainingArguments, Trainer, EarlyStoppingCallback, set_seed\n",
    ")\n",
    "\n",
    "# è§£å†³PyTorch weights_onlyé—®é¢˜çš„è¡¥ä¸\n",
    "# è¿™æ˜¯ä¸ºäº†å…¼å®¹ä¸åŒç‰ˆæœ¬çš„PyTorchï¼Œé¿å…åŠ è½½checkpointæ—¶å‡ºç°æƒé™é”™è¯¯\n",
    "original_torch_load = torch.load\n",
    "def patched_torch_load(f, map_location=None, pickle_module=None, weights_only=None, **kwargs):\n",
    "    # å¦‚æœæ˜¯åŠ è½½checkpointç›¸å…³æ–‡ä»¶ï¼Œå¼ºåˆ¶è®¾ç½®weights_only=False\n",
    "    # è¿™æ ·å¯ä»¥é¿å…æŸäº›ç‰ˆæœ¬çš„PyTorchè¿‡äºä¸¥æ ¼çš„å®‰å…¨æ£€æŸ¥\n",
    "    if weights_only is True and (\n",
    "        isinstance(f, str) and ('rng_state' in f or 'checkpoint' in f)\n",
    "    ):\n",
    "        weights_only = False\n",
    "    return original_torch_load(f, map_location=map_location, pickle_module=pickle_module, \n",
    "                              weights_only=weights_only, **kwargs)\n",
    "\n",
    "torch.load = patched_torch_load\n",
    "\n",
    "# æ·»åŠ é¡¹ç›®è·¯å¾„åˆ°Pythonæœç´¢è·¯å¾„\n",
    "# è¿™æ ·å¯ä»¥å¯¼å…¥é¡¹ç›®ä¸­çš„è‡ªå®šä¹‰æ¨¡å—\n",
    "current_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "sys.path.insert(0, current_dir)\n",
    "\n",
    "# å¯¼å…¥é¡¹ç›®è‡ªå®šä¹‰æ¨¡å—\n",
    "from data.dataset import create_reward_dataset, create_data_collator\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class FinetuningArguments:\n",
    "    \"\"\"\n",
    "    å¾®è°ƒå‚æ•°é…ç½®ç±»\n",
    "    \n",
    "    è¿™ä¸ªç±»å®šä¹‰äº†freeze tuningçš„ç›¸å…³å‚æ•°\n",
    "    freeze tuningæ˜¯ä¸€ç§åªè®­ç»ƒæ¨¡å‹éƒ¨åˆ†å±‚çš„æŠ€æœ¯ï¼Œå¯ä»¥èŠ‚çœæ˜¾å­˜å’Œè®¡ç®—èµ„æº\n",
    "    \"\"\"\n",
    "    freeze_trainable_layers: int = field(default=4)        # å¯è®­ç»ƒçš„å±‚æ•°ï¼ˆä»åå¾€å‰æ•°ï¼‰\n",
    "    freeze_trainable_modules: str = field(default=\"all\")   # å¯è®­ç»ƒçš„æ¨¡å—ç±»å‹\n",
    "    freeze_extra_modules: Optional[str] = field(default=None)  # é¢å¤–çš„å¯è®­ç»ƒæ¨¡å—\n",
    "\n",
    "\n",
    "def setup_freeze_tuning(model, finetuning_args: FinetuningArguments):\n",
    "    \"\"\"\n",
    "    è®¾ç½®freeze tuningå‚æ•°\n",
    "    \n",
    "    è¿™ä¸ªå‡½æ•°å®ç°éƒ¨åˆ†å‚æ•°å¾®è°ƒï¼Œåªè®­ç»ƒæ¨¡å‹çš„æœ€åå‡ å±‚å’Œåˆ†ç±»å¤´\n",
    "    è¿™æ ·å¯ä»¥åœ¨ä¿æŒæ¨¡å‹å¤§éƒ¨åˆ†çŸ¥è¯†çš„åŒæ—¶ï¼Œç”¨è¾ƒå°‘çš„è®¡ç®—èµ„æºè¿›è¡Œå¾®è°ƒ\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model: è¦è®¾ç½®çš„æ¨¡å‹\n",
    "        finetuning_args: å¾®è°ƒå‚æ•°é…ç½®\n",
    "    \n",
    "    å·¥ä½œåŸç†:\n",
    "        1. è·å–æ¨¡å‹æ€»å±‚æ•°\n",
    "        2. ç¡®å®šå“ªäº›å±‚éœ€è¦è®­ç»ƒï¼ˆé€šå¸¸æ˜¯æœ€åå‡ å±‚ï¼‰\n",
    "        3. å†»ç»“å…¶ä»–å±‚çš„å‚æ•°ï¼Œåªè®­ç»ƒæŒ‡å®šå±‚\n",
    "        4. ç»Ÿè®¡å¯è®­ç»ƒå‚æ•°æ•°é‡\n",
    "    \"\"\"\n",
    "    print(\"é…ç½®Freeze Tuning...\")\n",
    "    \n",
    "    # è·å–æ¨¡å‹çš„æ€»å±‚æ•°\n",
    "    # å¯¹äºLLaMAæ¨¡å‹ï¼Œè¿™é€šå¸¸æ˜¯32å±‚\n",
    "    num_layers = model.config.num_hidden_layers\n",
    "    \n",
    "    # ç¡®å®šå¯è®­ç»ƒå±‚çš„èŒƒå›´\n",
    "    # ä¾‹å¦‚ï¼šå¦‚æœæ€»å…±32å±‚ï¼Œfreeze_trainable_layers=4ï¼Œåˆ™è®­ç»ƒç¬¬28-31å±‚ï¼ˆæœ€å4å±‚ï¼‰\n",
    "    trainable_layer_ids = range(\n",
    "        max(0, num_layers - finetuning_args.freeze_trainable_layers), \n",
    "        num_layers\n",
    "    )\n",
    "    \n",
    "    # æ„å»ºå¯è®­ç»ƒå‚æ•°çš„åŒ¹é…æ¨¡å¼\n",
    "    # è¿™äº›æ¨¡å¼ç”¨äºè¯†åˆ«å“ªäº›å‚æ•°éœ€è¦è®­ç»ƒ\n",
    "    trainable_patterns = []\n",
    "    for idx in trainable_layer_ids:\n",
    "        if finetuning_args.freeze_trainable_modules == \"all\":\n",
    "            # å¦‚æœæ˜¯\"all\"ï¼Œåˆ™è¯¥å±‚çš„æ‰€æœ‰æ¨¡å—éƒ½å¯è®­ç»ƒ\n",
    "            trainable_patterns.append(f\".{idx}.\")\n",
    "        else:\n",
    "            # å¦åˆ™åªè®­ç»ƒæŒ‡å®šçš„æ¨¡å—ï¼ˆå¦‚attentionã€mlpç­‰ï¼‰\n",
    "            modules = [m.strip() for m in finetuning_args.freeze_trainable_modules.split(\",\")]\n",
    "            for module in modules:\n",
    "                trainable_patterns.append(f\".{idx}.{module}\")\n",
    "    \n",
    "    # æ·»åŠ é¢å¤–çš„å¯è®­ç»ƒæ¨¡å—\n",
    "    # ä¾‹å¦‚åˆ†ç±»å¤´ï¼ˆscoreå±‚ï¼‰é€šå¸¸æ€»æ˜¯éœ€è¦è®­ç»ƒçš„\n",
    "    if finetuning_args.freeze_extra_modules:\n",
    "        extra_modules = [m.strip() for m in finetuning_args.freeze_extra_modules.split(\",\")]\n",
    "        trainable_patterns.extend(extra_modules)\n",
    "    \n",
    "    # éå†æ¨¡å‹çš„æ‰€æœ‰å‚æ•°ï¼Œè®¾ç½®æ˜¯å¦å¯è®­ç»ƒ\n",
    "    trainable_params = 0  # å¯è®­ç»ƒå‚æ•°æ•°é‡\n",
    "    total_params = 0      # æ€»å‚æ•°æ•°é‡\n",
    "    \n",
    "    for name, param in model.named_parameters():\n",
    "        total_params += param.numel()\n",
    "        # æ£€æŸ¥å‚æ•°åæ˜¯å¦åŒ¹é…å¯è®­ç»ƒæ¨¡å¼\n",
    "        is_trainable = any(pattern in name for pattern in trainable_patterns)\n",
    "        param.requires_grad = is_trainable  # è®¾ç½®æ˜¯å¦è®¡ç®—æ¢¯åº¦\n",
    "        if is_trainable:\n",
    "            trainable_params += param.numel()\n",
    "    \n",
    "    # æ‰“å°é…ç½®ä¿¡æ¯\n",
    "    print(f\"æ¨¡å‹å±‚æ•°: {num_layers}\")\n",
    "    print(f\"å¯è®­ç»ƒå±‚: {list(trainable_layer_ids)}\")\n",
    "    print(f\"å¯è®­ç»ƒå‚æ•°: {trainable_params:,} / {total_params:,} ({100*trainable_params/total_params:.2f}%)\")\n",
    "\n",
    "\n",
    "class RewardTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    å¥–åŠ±æ¨¡å‹è®­ç»ƒå™¨\n",
    "    \n",
    "    è¿™ä¸ªç±»ç»§æ‰¿è‡ªHuggingFaceçš„Trainerï¼Œä¸“é—¨ç”¨äºè®­ç»ƒå¥–åŠ±æ¨¡å‹\n",
    "    é‡å†™äº†æŸå¤±è®¡ç®—å’Œè¯„ä¼°æ–¹æ³•ï¼Œå®ç°äº†pairwiseå¯¹æ¯”å­¦ä¹ \n",
    "    \n",
    "    å¥–åŠ±æ¨¡å‹çš„æ ¸å¿ƒæ€æƒ³ï¼š\n",
    "    - è¾“å…¥ä¸¤ä¸ªå›ç­”ï¼ˆchosenå’Œrejectedï¼‰\n",
    "    - æ¨¡å‹åˆ†åˆ«ç»™å‡ºåˆ†æ•°\n",
    "    - è®­ç»ƒç›®æ ‡æ˜¯è®©chosençš„åˆ†æ•°é«˜äºrejectedçš„åˆ†æ•°\n",
    "    \"\"\"\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        \"\"\"\n",
    "        è®¡ç®—å¥–åŠ±æ¨¡å‹çš„å¯¹æ¯”æŸå¤±\n",
    "        \n",
    "        è¿™æ˜¯å¥–åŠ±æ¨¡å‹è®­ç»ƒçš„æ ¸å¿ƒæ–¹æ³•ï¼Œå®ç°äº†pairwiseå¯¹æ¯”å­¦ä¹ \n",
    "        \n",
    "        å‚æ•°:\n",
    "            model: å¥–åŠ±æ¨¡å‹\n",
    "            inputs: è¾“å…¥æ•°æ®ï¼ŒåŒ…å«chosenå’Œrejectedçš„tokenåºåˆ—\n",
    "            return_outputs: æ˜¯å¦è¿”å›æ¨¡å‹è¾“å‡º\n",
    "            num_items_in_batch: æ‰¹æ¬¡ä¸­çš„æ ·æœ¬æ•°é‡\n",
    "        \n",
    "        è¿”å›:\n",
    "            æŸå¤±å€¼æˆ–(æŸå¤±å€¼, æ¨¡å‹è¾“å‡º)\n",
    "        \n",
    "        å·¥ä½œåŸç†:\n",
    "            1. åˆ†åˆ«å¯¹chosenå’Œrejectedå›ç­”è¿›è¡Œæ¨ç†\n",
    "            2. è·å–ä¸¤ä¸ªå›ç­”çš„åˆ†æ•°\n",
    "            3. è®¡ç®—å¯¹æ¯”æŸå¤±ï¼š-log(sigmoid(chosen_score - rejected_score))\n",
    "            4. è¿™ä¸ªæŸå¤±å‡½æ•°é¼“åŠ±chosenåˆ†æ•°é«˜äºrejectedåˆ†æ•°\n",
    "        \"\"\"\n",
    "        # å¯¹chosenå›ç­”è¿›è¡Œæ¨ç†\n",
    "        # chosenå›ç­”æ˜¯äººç±»æ ‡æ³¨çš„æ›´å¥½çš„å›ç­”\n",
    "        chosen_outputs = model(\n",
    "            input_ids=inputs[\"chosen_input_ids\"],\n",
    "            attention_mask=inputs[\"chosen_attention_mask\"]\n",
    "        )\n",
    "        # æå–chosenå›ç­”çš„åˆ†æ•°\n",
    "        # squeeze(-1)æ˜¯ä¸ºäº†å»æ‰æœ€åä¸€ä¸ªç»´åº¦ï¼Œå¾—åˆ°æ ‡é‡åˆ†æ•°\n",
    "        chosen_rewards = chosen_outputs.logits.squeeze(-1)\n",
    "        \n",
    "        # å¯¹rejectedå›ç­”è¿›è¡Œæ¨ç†\n",
    "        # rejectedå›ç­”æ˜¯äººç±»æ ‡æ³¨çš„è¾ƒå·®çš„å›ç­”\n",
    "        rejected_outputs = model(\n",
    "            input_ids=inputs[\"rejected_input_ids\"],\n",
    "            attention_mask=inputs[\"rejected_attention_mask\"]\n",
    "        )\n",
    "        # æå–rejectedå›ç­”çš„åˆ†æ•°\n",
    "        rejected_rewards = rejected_outputs.logits.squeeze(-1)\n",
    "        \n",
    "        # è®¡ç®—å¯¹æ¯”æŸå¤±\n",
    "        # logsigmoid(chosen - rejected)é¼“åŠ±chosenåˆ†æ•°é«˜äºrejectedåˆ†æ•°\n",
    "        # è´Ÿå·æ˜¯å› ä¸ºæˆ‘ä»¬è¦æœ€å°åŒ–æŸå¤±ï¼ˆæœ€å¤§åŒ–chosenç›¸å¯¹äºrejectedçš„ä¼˜åŠ¿ï¼‰\n",
    "        loss = -torch.nn.functional.logsigmoid(chosen_rewards - rejected_rewards).mean()\n",
    "        \n",
    "        if return_outputs:\n",
    "            return loss, {\"chosen_rewards\": chosen_rewards, \"rejected_rewards\": rejected_rewards}\n",
    "        return loss\n",
    "    \n",
    "    def prediction_step(self, model, inputs, prediction_loss_only: bool, ignore_keys=None):\n",
    "        \"\"\"\n",
    "        é‡å†™é¢„æµ‹æ­¥éª¤ï¼Œæ­£ç¡®å¤„ç†è‡ªå®šä¹‰æ•°æ®æ ¼å¼\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•åœ¨è¯„ä¼°æ—¶è¢«è°ƒç”¨ï¼Œç”¨äºè®¡ç®—éªŒè¯é›†ä¸Šçš„æŸå¤±å’Œé¢„æµ‹ç»“æœ\n",
    "        \n",
    "        å‚æ•°:\n",
    "            model: æ¨¡å‹\n",
    "            inputs: è¾“å…¥æ•°æ®\n",
    "            prediction_loss_only: æ˜¯å¦åªè¿”å›æŸå¤±\n",
    "            ignore_keys: å¿½ç•¥çš„é”®\n",
    "        \n",
    "        è¿”å›:\n",
    "            (æŸå¤±, é¢„æµ‹ç»“æœ, æ ‡ç­¾)\n",
    "        \"\"\"\n",
    "        model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "        \n",
    "        with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜\n",
    "            # ä½¿ç”¨è‡ªå®šä¹‰çš„compute_lossæ–¹æ³•è®¡ç®—æŸå¤±\n",
    "            loss = self.compute_loss(model, inputs)\n",
    "            \n",
    "            # å¦‚æœåªéœ€è¦æŸå¤±ï¼Œç›´æ¥è¿”å›\n",
    "            if prediction_loss_only:\n",
    "                return (loss, None, None)\n",
    "            \n",
    "            # è®¡ç®—chosenå’Œrejectedçš„å¥–åŠ±åˆ†æ•°\n",
    "            chosen_outputs = model(\n",
    "                input_ids=inputs[\"chosen_input_ids\"],\n",
    "                attention_mask=inputs[\"chosen_attention_mask\"]\n",
    "            )\n",
    "            rejected_outputs = model(\n",
    "                input_ids=inputs[\"rejected_input_ids\"],\n",
    "                attention_mask=inputs[\"rejected_attention_mask\"]\n",
    "            )\n",
    "                \n",
    "            chosen_rewards = chosen_outputs.logits.squeeze(-1)\n",
    "            rejected_rewards = rejected_outputs.logits.squeeze(-1)\n",
    "            \n",
    "            # åˆ›å»ºé¢„æµ‹ç»“æœï¼šchosen > rejected ä¸ºæ­£ç¡®é¢„æµ‹\n",
    "            # è¿™é‡Œå°†å¸ƒå°”å€¼è½¬æ¢ä¸ºæµ®ç‚¹æ•°ï¼ˆTrue->1.0, False->0.0ï¼‰\n",
    "            predictions = (chosen_rewards > rejected_rewards).float()\n",
    "            \n",
    "            # åˆ›å»ºæ ‡ç­¾ï¼šå…¨éƒ¨ä¸º1ï¼ˆchosenåº”è¯¥æ€»æ˜¯æ¯”rejectedå¥½ï¼‰\n",
    "            # åœ¨å¥–åŠ±æ¨¡å‹ä¸­ï¼Œç†æƒ³æƒ…å†µä¸‹chosenæ€»æ˜¯åº”è¯¥å¾—åˆ°æ›´é«˜åˆ†æ•°\n",
    "            labels = torch.ones_like(predictions)\n",
    "            \n",
    "            return (loss, predictions, labels)\n",
    "    \n",
    "    def evaluate(self, eval_dataset=None, ignore_keys=None, metric_key_prefix=\"eval\"):\n",
    "        \"\"\"\n",
    "        é‡å†™è¯„ä¼°æ–¹æ³•ï¼Œè®¡ç®—å¥–åŠ±æ¨¡å‹çš„å‡†ç¡®ç‡\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•åœ¨éªŒè¯æ—¶è¢«è°ƒç”¨ï¼Œè®¡ç®—æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šçš„è¡¨ç°\n",
    "        \n",
    "        å‚æ•°:\n",
    "            eval_dataset: è¯„ä¼°æ•°æ®é›†\n",
    "            ignore_keys: å¿½ç•¥çš„é”®\n",
    "            metric_key_prefix: æŒ‡æ ‡å‰ç¼€\n",
    "        \n",
    "        è¿”å›:\n",
    "            è¯„ä¼°ç»“æœå­—å…¸\n",
    "        \n",
    "        å‡†ç¡®ç‡è®¡ç®—ï¼š\n",
    "            å‡†ç¡®ç‡ = æ­£ç¡®é¢„æµ‹æ•°é‡ / æ€»é¢„æµ‹æ•°é‡\n",
    "            æ­£ç¡®é¢„æµ‹ = chosen_score > rejected_score\n",
    "        \"\"\"\n",
    "        # è°ƒç”¨çˆ¶ç±»è¯„ä¼°æ–¹æ³•ï¼Œè·å–åŸºæœ¬çš„è¯„ä¼°ç»“æœ\n",
    "        eval_results = super().evaluate(eval_dataset, ignore_keys, metric_key_prefix)\n",
    "        \n",
    "        # æ‰‹åŠ¨è®¡ç®—å‡†ç¡®ç‡\n",
    "        if eval_dataset is not None:\n",
    "            correct = 0  # æ­£ç¡®é¢„æµ‹çš„æ•°é‡\n",
    "            total = 0    # æ€»é¢„æµ‹æ•°é‡\n",
    "            \n",
    "            self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "            eval_dataloader = self.get_eval_dataloader(eval_dataset)\n",
    "            \n",
    "            with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦\n",
    "                for batch in eval_dataloader:\n",
    "                    # å°†æ•°æ®ç§»åŠ¨åˆ°GPU\n",
    "                    batch = {k: v.to(self.args.device) for k, v in batch.items()}\n",
    "                    \n",
    "                    # åˆ†åˆ«å¯¹chosenå’Œrejectedè¿›è¡Œæ¨ç†\n",
    "                    chosen_outputs = self.model(\n",
    "                        input_ids=batch[\"chosen_input_ids\"],\n",
    "                        attention_mask=batch[\"chosen_attention_mask\"]\n",
    "                    )\n",
    "                    rejected_outputs = self.model(\n",
    "                        input_ids=batch[\"rejected_input_ids\"],\n",
    "                        attention_mask=batch[\"rejected_attention_mask\"]\n",
    "                    )\n",
    "                    \n",
    "                    chosen_rewards = chosen_outputs.logits.squeeze(-1)\n",
    "                    rejected_rewards = rejected_outputs.logits.squeeze(-1)\n",
    "                    \n",
    "                    # ç»Ÿè®¡æ­£ç¡®é¢„æµ‹çš„æ•°é‡\n",
    "                    # å¦‚æœchosenåˆ†æ•°é«˜äºrejectedåˆ†æ•°ï¼Œåˆ™é¢„æµ‹æ­£ç¡®\n",
    "                    correct += (chosen_rewards > rejected_rewards).sum().item()\n",
    "                    total += chosen_rewards.size(0)\n",
    "            \n",
    "            # è®¡ç®—å‡†ç¡®ç‡\n",
    "            accuracy = correct / total if total > 0 else 0.0\n",
    "            eval_results[f\"{metric_key_prefix}_accuracy\"] = accuracy\n",
    "            \n",
    "            # æ‰“å°è¯„ä¼°ç»“æœ\n",
    "            print(f\"è¯„ä¼°ç»“æœ - Loss: {eval_results[f'{metric_key_prefix}_loss']:.6f}, \"\n",
    "                  f\"Accuracy: {accuracy:.4f} ({correct}/{total})\")\n",
    "        \n",
    "        return eval_results\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    ä¸»è®­ç»ƒå‡½æ•°\n",
    "    \n",
    "    è¿™æ˜¯æ•´ä¸ªè®­ç»ƒè„šæœ¬çš„å…¥å£ç‚¹ï¼Œè´Ÿè´£ï¼š\n",
    "    1. è§£æå‘½ä»¤è¡Œå‚æ•°\n",
    "    2. åˆå§‹åŒ–åˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ\n",
    "    3. åŠ è½½æ¨¡å‹å’Œæ•°æ®\n",
    "    4. é…ç½®è®­ç»ƒå‚æ•°\n",
    "    5. å¼€å§‹è®­ç»ƒ\n",
    "    6. ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "    \"\"\"\n",
    "    \n",
    "    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨\n",
    "    parser = argparse.ArgumentParser(description=\"Skyworkå¥–åŠ±æ¨¡å‹å¾®è°ƒ\")\n",
    "    parser.add_argument(\"--resume_from_checkpoint\", type=str, default=None,\n",
    "                       help=\"ä»checkpointæ¢å¤è®­ç»ƒ\")\n",
    "    parser.add_argument(\"--config\", type=str, default=\"configs/training/config.json\",\n",
    "                       help=\"é…ç½®æ–‡ä»¶è·¯å¾„\")\n",
    "    parser.add_argument(\"--local_rank\", type=int, default=-1,\n",
    "                       help=\"DeepSpeedæœ¬åœ°rank\")\n",
    "    parser.add_argument(\"--deepspeed\", type=str, default=None,\n",
    "                       help=\"DeepSpeedé…ç½®æ–‡ä»¶\")\n",
    "    \n",
    "    # è§£æå‘½ä»¤è¡Œå‚æ•°\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # åˆå§‹åŒ–DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒç¯å¢ƒ\n",
    "    # DeepSpeedæ˜¯å¾®è½¯å¼€å‘çš„æ·±åº¦å­¦ä¹ ä¼˜åŒ–åº“ï¼Œæ”¯æŒå¤§æ¨¡å‹è®­ç»ƒ\n",
    "    deepspeed.init_distributed()\n",
    "    \n",
    "    # è·å–åˆ†å¸ƒå¼è®­ç»ƒçš„ç›¸å…³ä¿¡æ¯\n",
    "    # è¿™äº›ç¯å¢ƒå˜é‡ç”±DeepSpeedæˆ–å…¶ä»–åˆ†å¸ƒå¼è®­ç»ƒæ¡†æ¶è®¾ç½®\n",
    "    local_rank = int(os.environ.get('LOCAL_RANK', args.local_rank if args.local_rank != -1 else 0))\n",
    "    world_size = int(os.environ.get('WORLD_SIZE', 1))  # æ€»è¿›ç¨‹æ•°\n",
    "    rank = int(os.environ.get('RANK', 0))              # å½“å‰è¿›ç¨‹çš„å…¨å±€rank\n",
    "    \n",
    "    print(f\"å¯åŠ¨è¿›ç¨‹ {rank}/{world_size} (GPU {local_rank})\")\n",
    "    \n",
    "    # å¦‚æœæŒ‡å®šäº†checkpointï¼Œæ‰“å°æ¢å¤ä¿¡æ¯\n",
    "    if args.resume_from_checkpoint:\n",
    "        print(f\"ä»checkpointæ¢å¤è®­ç»ƒ: {args.resume_from_checkpoint}\")\n",
    "    \n",
    "    # è®¾ç½®å½“å‰è¿›ç¨‹ä½¿ç”¨çš„GPU\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    \n",
    "    # åŠ è½½è®­ç»ƒé…ç½®æ–‡ä»¶\n",
    "    with open(args.config, 'r', encoding='utf-8') as f:\n",
    "        config = json.load(f)\n",
    "    \n",
    "    # åˆ›å»ºè¾“å‡ºç›®å½•ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ä¸­åˆ›å»ºï¼Œé¿å…ç«äº‰æ¡ä»¶ï¼‰\n",
    "    if rank == 0:\n",
    "        os.makedirs(config[\"output_dir\"], exist_ok=True)\n",
    "        os.makedirs(config[\"logging_dir\"], exist_ok=True)\n",
    "    \n",
    "    # è®¾ç½®éšæœºç§å­ï¼Œç¡®ä¿å®éªŒå¯é‡ç°\n",
    "    set_seed(config[\"seed\"])\n",
    "    \n",
    "    # åˆ›å»ºå¾®è°ƒå‚æ•°é…ç½®\n",
    "    finetuning_args = FinetuningArguments(\n",
    "        freeze_trainable_layers=config[\"freeze_trainable_layers\"],\n",
    "        freeze_trainable_modules=config[\"freeze_trainable_modules\"],\n",
    "        freeze_extra_modules=config.get(\"freeze_extra_modules\")\n",
    "    )\n",
    "    \n",
    "    # æ‰“å°é…ç½®ä¿¡æ¯ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰“å°ï¼‰\n",
    "    if rank == 0:\n",
    "        print(f\"åŸºç¡€æ¨¡å‹: {config['model_name_or_path']}\")\n",
    "        print(f\"Freezeå±‚æ•°: {finetuning_args.freeze_trainable_layers}\")\n",
    "        print(f\"è¾“å‡ºç›®å½•: {config['output_dir']}\")\n",
    "    \n",
    "    # åŠ è½½tokenizerï¼ˆæ–‡æœ¬åˆ†è¯å™¨ï¼‰\n",
    "    # tokenizerè´Ÿè´£å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ•°å­—åºåˆ—\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\n",
    "        config[\"model_name_or_path\"], \n",
    "        trust_remote_code=config[\"trust_remote_code\"]\n",
    "    )\n",
    "    # å¦‚æœæ²¡æœ‰pad_tokenï¼Œä½¿ç”¨eos_tokenä½œä¸ºpad_token\n",
    "    # pad_tokenç”¨äºå°†ä¸åŒé•¿åº¦çš„åºåˆ—å¡«å……åˆ°ç›¸åŒé•¿åº¦\n",
    "    if tokenizer.pad_token is None:\n",
    "        tokenizer.pad_token = tokenizer.eos_token\n",
    "    \n",
    "    # åŠ è½½æ¨¡å‹é…ç½®\n",
    "    model_config = AutoConfig.from_pretrained(\n",
    "        config[\"model_name_or_path\"], \n",
    "        trust_remote_code=config[\"trust_remote_code\"]\n",
    "    )\n",
    "    # è®¾ç½®è¾“å‡ºæ ‡ç­¾æ•°ä¸º1ï¼Œå› ä¸ºå¥–åŠ±æ¨¡å‹è¾“å‡ºå•ä¸ªåˆ†æ•°\n",
    "    model_config.num_labels = 1\n",
    "    \n",
    "    # åœ¨CPUä¸Šåˆå§‹åŒ–æ¨¡å‹\n",
    "    # è¿™æ˜¯ä¸ºäº†èŠ‚çœGPUå†…å­˜ï¼ŒDeepSpeedä¼šè‡ªåŠ¨å°†æ¨¡å‹ç§»åŠ¨åˆ°GPU\n",
    "    with torch.device('cpu'):\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(\n",
    "            config[\"model_name_or_path\"],\n",
    "            config=model_config,\n",
    "            torch_dtype=getattr(torch, config[\"torch_dtype\"]),\n",
    "            trust_remote_code=config[\"trust_remote_code\"]\n",
    "        )\n",
    "    \n",
    "    # è®¾ç½®freeze tuningï¼Œåªè®­ç»ƒéƒ¨åˆ†å‚æ•°\n",
    "    setup_freeze_tuning(model, finetuning_args)\n",
    "    \n",
    "    # åˆ›å»ºæ•°æ®é›†\n",
    "    # è¿™ä¼šåŠ è½½è®­ç»ƒæ•°æ®å’ŒéªŒè¯æ•°æ®ï¼Œå¹¶è¿›è¡Œé¢„å¤„ç†\n",
    "    train_dataset, eval_dataset = create_reward_dataset(\n",
    "        config[\"data_path\"], tokenizer, config[\"max_length\"]\n",
    "    )\n",
    "    # åˆ›å»ºæ•°æ®æ•´ç†å™¨ï¼Œè´Ÿè´£å°†æ•°æ®ç»„ç»‡æˆæ‰¹æ¬¡\n",
    "    data_collator = create_data_collator(tokenizer)\n",
    "    \n",
    "    # æ‰“å°æ•°æ®é›†ä¿¡æ¯\n",
    "    if rank == 0:\n",
    "        print(f\"æ•°æ®é›† - è®­ç»ƒ: {len(train_dataset)}, éªŒè¯: {len(eval_dataset)}\")\n",
    "    \n",
    "    # åˆ›å»ºè®­ç»ƒå‚æ•°é…ç½®\n",
    "    training_args = TrainingArguments(\n",
    "        # åŸºæœ¬è®­ç»ƒå‚æ•°\n",
    "        output_dir=config[\"output_dir\"],                    # è¾“å‡ºç›®å½•\n",
    "        num_train_epochs=config[\"num_train_epochs\"],        # è®­ç»ƒè½®æ•°\n",
    "        learning_rate=config[\"learning_rate\"],              # å­¦ä¹ ç‡\n",
    "        weight_decay=config[\"weight_decay\"],                # æƒé‡è¡°å‡ï¼ˆæ­£åˆ™åŒ–ï¼‰\n",
    "        warmup_ratio=config[\"warmup_ratio\"],                # å­¦ä¹ ç‡é¢„çƒ­æ¯”ä¾‹\n",
    "        max_grad_norm=config[\"max_grad_norm\"],              # æ¢¯åº¦è£å‰ªé˜ˆå€¼\n",
    "        seed=config[\"seed\"],                                # éšæœºç§å­\n",
    "        \n",
    "        # æ‰¹æ¬¡å¤§å°è®¾ç½®\n",
    "        per_device_train_batch_size=config[\"per_device_train_batch_size\"],    # æ¯ä¸ªè®¾å¤‡çš„è®­ç»ƒæ‰¹æ¬¡å¤§å°\n",
    "        per_device_eval_batch_size=config[\"per_device_eval_batch_size\"],      # æ¯ä¸ªè®¾å¤‡çš„è¯„ä¼°æ‰¹æ¬¡å¤§å°\n",
    "        gradient_accumulation_steps=config[\"gradient_accumulation_steps\"],    # æ¢¯åº¦ç´¯ç§¯æ­¥æ•°\n",
    "        \n",
    "        # è¯„ä¼°ç­–ç•¥\n",
    "        eval_strategy=config[\"evaluation_strategy\"],        # è¯„ä¼°ç­–ç•¥ï¼ˆæŒ‰æ­¥æ•°è¯„ä¼°ï¼‰\n",
    "        eval_steps=config[\"eval_steps\"],                    # è¯„ä¼°é—´éš”æ­¥æ•°\n",
    "        do_eval=True,                                       # å¯ç”¨è¯„ä¼°\n",
    "        \n",
    "        # ä¿å­˜ç­–ç•¥\n",
    "        save_strategy=config[\"save_strategy\"],              # ä¿å­˜ç­–ç•¥ï¼ˆæŒ‰æ­¥æ•°ä¿å­˜ï¼‰\n",
    "        save_steps=config[\"save_steps\"],                    # ä¿å­˜é—´éš”æ­¥æ•°\n",
    "        save_total_limit=config[\"save_total_limit\"],        # æœ€å¤šä¿å­˜çš„checkpointæ•°é‡\n",
    "        save_safetensors=True,                              # ä½¿ç”¨safetensorsæ ¼å¼ä¿å­˜\n",
    "        \n",
    "        # æ¨¡å‹é€‰æ‹©ç­–ç•¥\n",
    "        load_best_model_at_end=config[\"load_best_model_at_end\"],        # è®­ç»ƒç»“æŸæ—¶åŠ è½½æœ€ä½³æ¨¡å‹\n",
    "        metric_for_best_model=config[\"metric_for_best_model\"],          # æœ€ä½³æ¨¡å‹çš„è¯„ä¼°æŒ‡æ ‡\n",
    "        greater_is_better=config[\"greater_is_better\"],                  # æŒ‡æ ‡æ˜¯å¦è¶Šå¤§è¶Šå¥½\n",
    "        \n",
    "        # æ—¥å¿—è®¾ç½®\n",
    "        logging_steps=config[\"logging_steps\"],              # æ—¥å¿—è®°å½•é—´éš”\n",
    "        logging_dir=config[\"logging_dir\"],                  # æ—¥å¿—ç›®å½•\n",
    "        \n",
    "        # ç²¾åº¦è®¾ç½®\n",
    "        bf16=config[\"bf16\"],                                # ä½¿ç”¨bfloat16ç²¾åº¦\n",
    "        fp16=config[\"fp16\"],                                # ä½¿ç”¨float16ç²¾åº¦\n",
    "        tf32=config[\"tf32\"],                                # ä½¿ç”¨TensorFloat-32\n",
    "        \n",
    "        # DeepSpeedé…ç½®\n",
    "        deepspeed=\"configs/training/deepspeed_only.json\",   # DeepSpeedé…ç½®æ–‡ä»¶\n",
    "        \n",
    "        # åˆ†å¸ƒå¼è®­ç»ƒè®¾ç½®\n",
    "        local_rank=local_rank,                              # æœ¬åœ°rank\n",
    "        ddp_find_unused_parameters=False,                   # ä¸æŸ¥æ‰¾æœªä½¿ç”¨çš„å‚æ•°\n",
    "        dataloader_num_workers=0,                           # æ•°æ®åŠ è½½å™¨å·¥ä½œè¿›ç¨‹æ•°\n",
    "        remove_unused_columns=False,                        # ä¸ç§»é™¤æœªä½¿ç”¨çš„åˆ—ï¼ˆé‡è¦ï¼šä¿ç•™è‡ªå®šä¹‰æ•°æ®æ ¼å¼ï¼‰\n",
    "        report_to=[],                                       # ä¸ä¸ŠæŠ¥åˆ°å¤–éƒ¨æœåŠ¡\n",
    "    )\n",
    "    \n",
    "    # åˆ›å»ºè®­ç»ƒå™¨\n",
    "    trainer = RewardTrainer(\n",
    "        model=model,                                        # è¦è®­ç»ƒçš„æ¨¡å‹\n",
    "        args=training_args,                                 # è®­ç»ƒå‚æ•°\n",
    "        train_dataset=train_dataset,                        # è®­ç»ƒæ•°æ®é›†\n",
    "        eval_dataset=eval_dataset,                          # éªŒè¯æ•°æ®é›†\n",
    "        data_collator=data_collator,                        # æ•°æ®æ•´ç†å™¨\n",
    "        processing_class=tokenizer,                         # å¤„ç†ç±»ï¼ˆtokenizerï¼‰\n",
    "        callbacks=[\n",
    "            # æ—©åœå›è°ƒï¼šå¦‚æœéªŒè¯æŸå¤±ä¸å†æ”¹å–„ï¼Œæå‰åœæ­¢è®­ç»ƒ\n",
    "            EarlyStoppingCallback(\n",
    "                early_stopping_patience=config.get(\"early_stopping_patience\", 5),  # å®¹å¿çš„è¯„ä¼°æ¬¡æ•°\n",
    "                early_stopping_threshold=0.001                                      # æ”¹å–„çš„æœ€å°é˜ˆå€¼\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # å¼€å§‹è®­ç»ƒ\n",
    "    if rank == 0:\n",
    "        print(\"å¼€å§‹è®­ç»ƒ...\")\n",
    "    \n",
    "    # æ‰§è¡Œè®­ç»ƒè¿‡ç¨‹\n",
    "    # å¦‚æœæŒ‡å®šäº†checkpointï¼Œä¼šä»è¯¥checkpointæ¢å¤è®­ç»ƒ\n",
    "    trainer.train(resume_from_checkpoint=args.resume_from_checkpoint)\n",
    "    \n",
    "    # è®­ç»ƒå®Œæˆåçš„å¤„ç†ï¼ˆåªåœ¨ä¸»è¿›ç¨‹ä¸­æ‰§è¡Œï¼‰\n",
    "    if rank == 0:\n",
    "        print(\"è®­ç»ƒå®Œæˆ\")\n",
    "        \n",
    "        # ä¿å­˜æœ€ç»ˆæ¨¡å‹\n",
    "        # è¿™ä¼šä¿å­˜å®Œæ•´çš„æ¨¡å‹å’Œtokenizeråˆ°final_modelç›®å½•\n",
    "        final_model_path = os.path.join(config[\"output_dir\"], \"final_model\")\n",
    "        trainer.save_model(final_model_path)\n",
    "        print(f\"æœ€ç»ˆæ¨¡å‹ä¿å­˜åˆ°: {final_model_path}\")\n",
    "\n",
    "\n",
    "# å¦‚æœè¿™ä¸ªæ–‡ä»¶è¢«ç›´æ¥è¿è¡Œï¼ˆè€Œä¸æ˜¯è¢«å¯¼å…¥ï¼‰ï¼Œåˆ™æ‰§è¡Œä¸»å‡½æ•°\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbdd1c5",
   "metadata": {},
   "source": [
    "deepspeed_cluster_launcher.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abbca012",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# ================================================================================\n",
    "#  æ–‡ä»¶ä½œç”¨è¯´æ˜ï¼š\n",
    "# è¿™æ˜¯DeepSpeedå¤šæœºå¤šå¡åˆ†å¸ƒå¼è®­ç»ƒçš„ä¸»å¯åŠ¨è„šæœ¬\n",
    "# \n",
    "#  é¡¹ç›®ä¸­çš„æ•´ä½“ä½œç”¨ï¼š\n",
    "# 1. ä½œä¸ºåˆ†å¸ƒå¼è®­ç»ƒçš„å…¥å£ç‚¹ï¼Œè´Ÿè´£å¯åŠ¨å¤šå°æœåŠ¡å™¨ä¸Šçš„è®­ç»ƒè¿›ç¨‹\n",
    "# 2. è‡ªåŠ¨ç®¡ç†é›†ç¾¤èŠ‚ç‚¹é…ç½®ï¼Œåˆ›å»ºDeepSpeedéœ€è¦çš„hostfileæ–‡ä»¶\n",
    "# 3. æä¾›è®­ç»ƒè¿›ç¨‹çš„å¯åŠ¨ã€åœæ­¢ã€æ—¥å¿—æŸ¥çœ‹ç­‰ç®¡ç†åŠŸèƒ½\n",
    "# 4. è¿™æ˜¯ä½ åœ¨å¤šæœºè®­ç»ƒæ—¶å®é™…ä½¿ç”¨çš„ä¸»è¦è„šæœ¬\n",
    "#\n",
    "#  ä½¿ç”¨æ–¹å¼ï¼š\n",
    "# bash deepspeed_cluster_launcher.sh start  # å¯åŠ¨è®­ç»ƒ\n",
    "# bash deepspeed_cluster_launcher.sh stop   # åœæ­¢è®­ç»ƒ  \n",
    "# bash deepspeed_cluster_launcher.sh logs   # æŸ¥çœ‹æ—¥å¿—\n",
    "# ================================================================================\n",
    "\n",
    "# ä¿®æ­£ç‰ˆDeepSpeedå¤šæœºå¤šå¡å¯åŠ¨è„šæœ¬\n",
    "# è§£å†³GPUè®¾å¤‡ç¼–å·é—®é¢˜\n",
    "\n",
    "# ============================================================================\n",
    "#  é¢œè‰²å®šä¹‰ï¼šç”¨äºåœ¨ç»ˆç«¯ä¸­æ˜¾ç¤ºä¸åŒé¢œè‰²çš„æ—¥å¿—ä¿¡æ¯ï¼Œæé«˜å¯è¯»æ€§\n",
    "# ============================================================================\n",
    "RED='\\033[0;31m'      # çº¢è‰²ï¼šç”¨äºé”™è¯¯ä¿¡æ¯\n",
    "GREEN='\\033[0;32m'    # ç»¿è‰²ï¼šç”¨äºæˆåŠŸä¿¡æ¯  \n",
    "BLUE='\\033[0;34m'     # è“è‰²ï¼šç”¨äºä¸€èˆ¬ä¿¡æ¯\n",
    "YELLOW='\\033[1;33m'   # é»„è‰²ï¼šç”¨äºè°ƒè¯•ä¿¡æ¯\n",
    "NC='\\033[0m'          # æ— é¢œè‰²ï¼šé‡ç½®é¢œè‰²\n",
    "\n",
    "# ============================================================================\n",
    "#  æ—¥å¿—è¾“å‡ºå‡½æ•°ï¼šç»Ÿä¸€ç®¡ç†æ—¥å¿—æ ¼å¼ï¼Œæ–¹ä¾¿è°ƒè¯•å’Œç›‘æ§\n",
    "# è¿™äº›å‡½æ•°åœ¨æ•´ä¸ªé¡¹ç›®ä¸­ç”¨äºï¼šè¾“å‡ºæ ¼å¼åŒ–çš„æ—¥å¿—ä¿¡æ¯ï¼Œä¾¿äºè¿ç»´äººå‘˜æŸ¥çœ‹\n",
    "# ============================================================================\n",
    "log_info() { echo -e \"${BLUE}[INFO]${NC} $1\"; }      # è¾“å‡ºè“è‰²çš„ä¿¡æ¯æ—¥å¿—\n",
    "log_success() { echo -e \"${GREEN}[SUCCESS]${NC} $1\"; } # è¾“å‡ºç»¿è‰²çš„æˆåŠŸæ—¥å¿—\n",
    "log_error() { echo -e \"${RED}[ERROR]${NC} $1\"; }     # è¾“å‡ºçº¢è‰²çš„é”™è¯¯æ—¥å¿—  \n",
    "log_debug() { echo -e \"${YELLOW}[DEBUG]${NC} $1\"; }  # è¾“å‡ºé»„è‰²çš„è°ƒè¯•æ—¥å¿—\n",
    "\n",
    "# ============================================================================\n",
    "#  é›†ç¾¤èŠ‚ç‚¹é…ç½®ï¼šå®šä¹‰æ‰€æœ‰å‚ä¸è®­ç»ƒçš„æœåŠ¡å™¨èŠ‚ç‚¹å’ŒGPUæ•°é‡\n",
    "# \n",
    "#  é¡¹ç›®ä¸­çš„æ•´ä½“ä½œç”¨ï¼š\n",
    "# 1. è¿™æ˜¯åˆ†å¸ƒå¼è®­ç»ƒçš„æ ¸å¿ƒé…ç½®ï¼Œå‘Šè¯‰DeepSpeedæœ‰å“ªäº›æœåŠ¡å™¨å¯ä»¥ç”¨\n",
    "# 2. æ¯ä¸ªIPå¯¹åº”ä¸€å°æœåŠ¡å™¨ï¼Œæ•°å­—è¡¨ç¤ºè¯¥æœåŠ¡å™¨æœ‰å¤šå°‘å¼ GPUå¡\n",
    "# 3. DeepSpeedä¼šæ ¹æ®è¿™ä¸ªé…ç½®è‡ªåŠ¨åˆ†é…è®­ç»ƒä»»åŠ¡åˆ°å„ä¸ªGPUä¸Š\n",
    "# 4. å¦‚æœè¦å¢åŠ /å‡å°‘è®­ç»ƒèŠ‚ç‚¹ï¼Œåªéœ€è¦ä¿®æ”¹è¿™ä¸ªæ•°ç»„å³å¯\n",
    "# ============================================================================\n",
    "declare -A NODES=(\n",
    "    [\"10.60.11.131\"]=4    # ä¸»èŠ‚ç‚¹ï¼ˆæœåŠ¡å™¨1ï¼‰ï¼šæ‹¥æœ‰4å¼ GPUå¡\n",
    "    [\"10.60.240.249\"]=2   # å·¥ä½œèŠ‚ç‚¹2ï¼šæ‹¥æœ‰2å¼ GPUå¡\n",
    "    # [\"10.60.79.49\"]=2    # å·¥ä½œèŠ‚ç‚¹3ï¼šæ‹¥æœ‰2å¼ GPUå¡ï¼ˆå·²æ³¨é‡Šï¼Œè¡¨ç¤ºæš‚æ—¶ä¸ä½¿ç”¨ï¼‰\n",
    "    # [\"10.60.11.133\"]=2    # å·¥ä½œèŠ‚ç‚¹4ï¼šæ‹¥æœ‰2å¼ GPUå¡ï¼ˆå·²æ³¨é‡Šï¼Œè¡¨ç¤ºæš‚æ—¶ä¸ä½¿ç”¨ï¼‰\n",
    ")\n",
    "\n",
    "# ä¸»èŠ‚ç‚¹ï¼ˆç¬¬ä¸€ä¸ªèŠ‚ç‚¹ï¼‰ï¼šè´Ÿè´£åè°ƒæ•´ä¸ªè®­ç»ƒè¿‡ç¨‹çš„æœåŠ¡å™¨\n",
    "MASTER_ADDR=\"10.60.11.131\"\n",
    "\n",
    "# ============================================================================\n",
    "#  åˆ›å»ºhostfileå‡½æ•°ï¼šç”ŸæˆDeepSpeedåˆ†å¸ƒå¼è®­ç»ƒéœ€è¦çš„èŠ‚ç‚¹é…ç½®æ–‡ä»¶\n",
    "# \n",
    "#  é¡¹ç›®ä¸­çš„æ•´ä½“ä½œç”¨ï¼š\n",
    "# 1. DeepSpeedéœ€è¦ä¸€ä¸ªhostfileæ–‡ä»¶æ¥çŸ¥é“æœ‰å“ªäº›æœåŠ¡å™¨å‚ä¸è®­ç»ƒ\n",
    "# 2. è¿™ä¸ªæ–‡ä»¶å‘Šè¯‰DeepSpeedæ¯å°æœåŠ¡å™¨çš„IPåœ°å€å’ŒGPUæ•°é‡\n",
    "# 3. è®­ç»ƒå¼€å§‹å‰å¿…é¡»å…ˆåˆ›å»ºè¿™ä¸ªæ–‡ä»¶ï¼Œå¦åˆ™DeepSpeedæ— æ³•å¯åŠ¨\n",
    "# 4. æ¯æ¬¡å¯åŠ¨è®­ç»ƒéƒ½ä¼šé‡æ–°ç”Ÿæˆï¼Œç¡®ä¿é…ç½®æ˜¯æœ€æ–°çš„\n",
    "# ============================================================================\n",
    "create_hostfile() {\n",
    "    log_info \"åˆ›å»ºDeepSpeed hostfile...\"\n",
    "    \n",
    "    # æ¸…ç©ºç°æœ‰hostfileæ–‡ä»¶ï¼ˆå¦‚æœå­˜åœ¨çš„è¯ï¼‰\n",
    "    > /shared/financial_reward_model/hostfile\n",
    "    \n",
    "    # éå†æ‰€æœ‰é…ç½®çš„èŠ‚ç‚¹ï¼Œå°†æ¯ä¸ªèŠ‚ç‚¹ä¿¡æ¯å†™å…¥hostfile\n",
    "    for node_ip in \"${!NODES[@]}\"; do\n",
    "        gpu_count=${NODES[$node_ip]}  # è·å–è¯¥èŠ‚ç‚¹çš„GPUæ•°é‡\n",
    "        # æŒ‰DeepSpeedè¦æ±‚çš„æ ¼å¼å†™å…¥ï¼šIPåœ°å€ slots=GPUæ•°é‡\n",
    "        echo \"$node_ip slots=$gpu_count\" >> /shared/financial_reward_model/hostfile\n",
    "    done\n",
    "    \n",
    "    log_success \"Hostfileåˆ›å»ºå®Œæˆ\"\n",
    "    # æ˜¾ç¤ºåˆ›å»ºçš„hostfileå†…å®¹ï¼Œä¾¿äºç¡®è®¤é…ç½®æ­£ç¡®\n",
    "    cat /shared/financial_reward_model/hostfile\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "#  åœæ­¢è®­ç»ƒå‡½æ•°ï¼šå®‰å…¨åœ°åœæ­¢æ‰€æœ‰æœåŠ¡å™¨ä¸Šæ­£åœ¨è¿è¡Œçš„è®­ç»ƒè¿›ç¨‹\n",
    "# \n",
    "#  é¡¹ç›®ä¸­çš„æ•´ä½“ä½œç”¨ï¼š\n",
    "# 1. åœ¨å¯åŠ¨æ–°è®­ç»ƒå‰ï¼Œå…ˆåœæ­¢å¯èƒ½å­˜åœ¨çš„æ—§è®­ç»ƒè¿›ç¨‹ï¼Œé¿å…å†²çª\n",
    "# 2. ç¡®ä¿æ‰€æœ‰æœåŠ¡å™¨ä¸Šçš„è®­ç»ƒè¿›ç¨‹éƒ½è¢«æ­£ç¡®æ¸…ç†\n",
    "# 3. é˜²æ­¢å‡ºç°å¤šä¸ªè®­ç»ƒè¿›ç¨‹åŒæ—¶è¿è¡Œçš„é—®é¢˜\n",
    "# 4. ä¸ºæ–°çš„è®­ç»ƒå¯åŠ¨åšå‡†å¤‡\n",
    "# ============================================================================\n",
    "stop_all_training() {\n",
    "    log_info \" åœæ­¢æ‰€æœ‰èŠ‚ç‚¹çš„è®­ç»ƒè¿›ç¨‹...\"\n",
    "    \n",
    "    # éå†æ‰€æœ‰é…ç½®çš„èŠ‚ç‚¹\n",
    "    for node_ip in \"${!NODES[@]}\"; do\n",
    "        if [[ \"$node_ip\" == \"$MASTER_ADDR\" ]]; then\n",
    "            # å¦‚æœæ˜¯ä¸»èŠ‚ç‚¹ï¼Œç›´æ¥åœ¨æœ¬åœ°æ‰§è¡Œåœæ­¢å‘½ä»¤\n",
    "            pkill -f \"deepspeed.*train_reward_model\" 2>/dev/null || true\n",
    "        else\n",
    "            # å¦‚æœæ˜¯å…¶ä»–èŠ‚ç‚¹ï¼Œé€šè¿‡SSHè¿œç¨‹æ‰§è¡Œåœæ­¢å‘½ä»¤\n",
    "            # ä½¿ç”¨&ç¬¦å·è®©SSHå‘½ä»¤åœ¨åå°å¹¶è¡Œæ‰§è¡Œï¼Œæé«˜æ•ˆç‡\n",
    "            ssh ubuntu@$node_ip \"pkill -f 'deepspeed.*train_reward_model' 2>/dev/null || true\" &\n",
    "        fi\n",
    "    done\n",
    "    \n",
    "    wait  # ç­‰å¾…æ‰€æœ‰SSHå‘½ä»¤å®Œæˆ\n",
    "    sleep 3  # ç¨ç­‰ç‰‡åˆ»ï¼Œç¡®ä¿è¿›ç¨‹å®Œå…¨åœæ­¢\n",
    "    log_success \"æ‰€æœ‰èŠ‚ç‚¹è®­ç»ƒè¿›ç¨‹æ¸…ç†å®Œæˆ\"\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "#  å¯åŠ¨è®­ç»ƒå‡½æ•°ï¼šè¿™æ˜¯æ•´ä¸ªè„šæœ¬çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œè´Ÿè´£å¯åŠ¨åˆ†å¸ƒå¼è®­ç»ƒ\n",
    "# \n",
    "#  é¡¹ç›®ä¸­çš„æ•´ä½“ä½œç”¨ï¼š\n",
    "# 1. è¿™æ˜¯åˆ†å¸ƒå¼è®­ç»ƒçš„ä¸»å…¥å£ï¼Œåè°ƒæ•´ä¸ªè®­ç»ƒæµç¨‹çš„å¯åŠ¨\n",
    "# 2. æŒ‰é¡ºåºæ‰§è¡Œï¼šåœæ­¢æ—§è¿›ç¨‹ â†’ åˆ›å»ºé…ç½®æ–‡ä»¶ â†’ æ¿€æ´»ç¯å¢ƒ â†’ å¯åŠ¨è®­ç»ƒ\n",
    "# 3. è´Ÿè´£ç®¡ç†è®­ç»ƒæ—¥å¿—çš„ä¿å­˜å’Œè¿›ç¨‹ç›‘æ§\n",
    "# 4. ç¡®ä¿è®­ç»ƒèƒ½å¤Ÿæ­£ç¡®å¯åŠ¨å¹¶æä¾›ç›‘æ§ä¿¡æ¯\n",
    "# ============================================================================\n",
    "start_training() {\n",
    "    log_info \" å¯åŠ¨DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒ...\"\n",
    "    \n",
    "    # ç¬¬1æ­¥ï¼šæ¸…ç†ç¯å¢ƒï¼Œåœæ­¢å¯èƒ½å­˜åœ¨çš„æ—§è®­ç»ƒè¿›ç¨‹\n",
    "    stop_all_training\n",
    "    \n",
    "    # ç¬¬2æ­¥ï¼šåˆ›å»ºDeepSpeedéœ€è¦çš„hostfileé…ç½®æ–‡ä»¶\n",
    "    create_hostfile\n",
    "    \n",
    "    # ç¬¬3æ­¥ï¼šåˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•\n",
    "    cd /shared/financial_reward_model\n",
    "    \n",
    "    # ç¬¬4æ­¥ï¼šåˆ›å»ºæ—¥å¿—å­˜å‚¨ç›®å½•\n",
    "    mkdir -p logs/distributed\n",
    "    TIMESTAMP=$(date +%Y%m%d_%H%M%S)  # ç”Ÿæˆæ—¶é—´æˆ³ï¼Œç”¨äºæ—¥å¿—æ–‡ä»¶å‘½å\n",
    "    \n",
    "    # ç¬¬5æ­¥ï¼šæ¿€æ´»condaè™šæ‹Ÿç¯å¢ƒï¼ˆåŒ…å«æ‰€éœ€çš„PythonåŒ…ï¼‰\n",
    "    log_info \"æ¿€æ´»condaç¯å¢ƒ...\"\n",
    "    source ~/miniconda3/etc/profile.d/conda.sh\n",
    "    conda activate reward2  # æ¿€æ´»åä¸º\"reward\"çš„condaç¯å¢ƒ\n",
    "    \n",
    "    log_info \"ä½¿ç”¨ä¿®æ­£çš„é…ç½®å¯åŠ¨å¤šæœºè®­ç»ƒ...\"\n",
    "    \n",
    "    # ğŸ”‘ æ”¯æŒé¢å¤–å‚æ•°çš„å¯åŠ¨å‘½ä»¤\n",
    "    EXTRA_ARGS=\"$2\"  # æ¥æ”¶é¢å¤–å‚æ•°\n",
    "    if [[ -n \"$EXTRA_ARGS\" ]]; then\n",
    "        LAUNCH_CMD=\"deepspeed --hostfile=hostfile src/train_reward_model.py $EXTRA_ARGS\"\n",
    "    else\n",
    "        LAUNCH_CMD=\"deepspeed --hostfile=hostfile src/train_reward_model.py\"\n",
    "    fi\n",
    "    LOG_FILE=\"logs/distributed/deepspeed_final_${TIMESTAMP}.log\"  # æ—¥å¿—æ–‡ä»¶è·¯å¾„\n",
    "    \n",
    "    log_debug \"å¯åŠ¨å‘½ä»¤: $LAUNCH_CMD\"\n",
    "    log_debug \"æ—¥å¿—æ–‡ä»¶: $LOG_FILE\"\n",
    "    \n",
    "    # ç¬¬7æ­¥ï¼šå¯åŠ¨è®­ç»ƒè¿›ç¨‹\n",
    "    # > $LOG_FILE 2>&1 å°†æ ‡å‡†è¾“å‡ºå’Œé”™è¯¯è¾“å‡ºéƒ½é‡å®šå‘åˆ°æ—¥å¿—æ–‡ä»¶\n",
    "    # & è®©è®­ç»ƒåœ¨åå°è¿è¡Œï¼Œä¸é˜»å¡å½“å‰ç»ˆç«¯\n",
    "    $LAUNCH_CMD > $LOG_FILE 2>&1 &\n",
    "    TRAIN_PID=$!  # è·å–è®­ç»ƒè¿›ç¨‹çš„PID\n",
    "    \n",
    "    log_success \"è®­ç»ƒå¯åŠ¨å®Œæˆï¼ŒPID: $TRAIN_PID\"\n",
    "    \n",
    "    # ç¬¬8æ­¥ï¼šç­‰å¾…å¹¶æ£€æŸ¥è®­ç»ƒæ˜¯å¦æˆåŠŸå¯åŠ¨\n",
    "    sleep 15  # ç­‰å¾…15ç§’ï¼Œè®©è®­ç»ƒè¿›ç¨‹æœ‰æ—¶é—´åˆå§‹åŒ–\n",
    "    \n",
    "    # æ£€æŸ¥è®­ç»ƒè¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ\n",
    "    if ps -p $TRAIN_PID > /dev/null; then\n",
    "        log_success \"è®­ç»ƒè¿›ç¨‹è¿è¡Œä¸­\"\n",
    "        log_info \"æ—¥å¿—æ–‡ä»¶: $LOG_FILE\"\n",
    "        log_info \"ç›‘æ§å‘½ä»¤: tail -f -n 300 $LOG_FILE\"\n",
    "        \n",
    "        # æ˜¾ç¤ºè®­ç»ƒæ—¥å¿—çš„å‰30è¡Œï¼Œä¾¿äºå¿«é€Ÿç¡®è®¤å¯åŠ¨çŠ¶æ€\n",
    "        sleep 5\n",
    "        echo \"=== ä¿®æ­£ç‰ˆè®­ç»ƒæ—¥å¿—å‰30è¡Œ ===\"\n",
    "        head -30 $LOG_FILE\n",
    "    else\n",
    "        # å¦‚æœè¿›ç¨‹å·²ç»é€€å‡ºï¼Œè¯´æ˜å¯åŠ¨å¤±è´¥\n",
    "        log_error \"è®­ç»ƒè¿›ç¨‹å·²é€€å‡º\"\n",
    "        echo \"=== é”™è¯¯æ—¥å¿— ===\"\n",
    "        cat $LOG_FILE  # æ˜¾ç¤ºå®Œæ•´çš„é”™è¯¯æ—¥å¿—\n",
    "        return 1\n",
    "    fi\n",
    "    \n",
    "    return 0\n",
    "}\n",
    "\n",
    "# ============================================================================\n",
    "#  ä¸»å‡½æ•°ï¼šæ ¹æ®ç”¨æˆ·è¾“å…¥çš„å‚æ•°æ‰§è¡Œç›¸åº”çš„æ“ä½œ\n",
    "# \n",
    "# é¡¹ç›®ä¸­çš„æ•´ä½“ä½œç”¨ï¼š\n",
    "# 1. è¿™æ˜¯è„šæœ¬çš„å…¥å£ç‚¹ï¼Œè§£æç”¨æˆ·çš„å‘½ä»¤è¡Œå‚æ•°\n",
    "# 2. æä¾›ç»Ÿä¸€çš„ç•Œé¢æ¥ç®¡ç†åˆ†å¸ƒå¼è®­ç»ƒçš„å„ç§æ“ä½œ\n",
    "# 3. æ”¯æŒstartï¼ˆå¯åŠ¨ï¼‰ã€stopï¼ˆåœæ­¢ï¼‰ã€logsï¼ˆæŸ¥çœ‹æ—¥å¿—ï¼‰ä¸‰ç§æ“ä½œ\n",
    "# 4. è®©è¿ç»´äººå‘˜å¯ä»¥æ–¹ä¾¿åœ°ç®¡ç†æ•´ä¸ªè®­ç»ƒæµç¨‹\n",
    "# ============================================================================\n",
    "case \"$1\" in\n",
    "    \"start\")\n",
    "        start_training \"$@\"  # ä¼ é€’æ‰€æœ‰å‚æ•°\n",
    "        ;;\n",
    "    \"resume\")\n",
    "        #  æ–°å¢resumeå‘½ä»¤\n",
    "        if [[ -z \"$2\" ]]; then\n",
    "            log_error \"è¯·æŒ‡å®šcheckpointè·¯å¾„\"\n",
    "            echo \"ç”¨æ³•: $0 resume <checkpoint_path>\"\n",
    "            exit 1\n",
    "        fi\n",
    "        start_training \"start\" \"--resume_from_checkpoint $2\"\n",
    "        ;;\n",
    "    \"stop\")\n",
    "        # åœæ­¢è®­ç»ƒï¼šè°ƒç”¨stop_all_trainingå‡½æ•°\n",
    "        stop_all_training\n",
    "        ;;\n",
    "    \"logs\")\n",
    "        # æŸ¥çœ‹æ—¥å¿—ï¼šæ‰¾åˆ°æœ€æ–°çš„æ—¥å¿—æ–‡ä»¶å¹¶å®æ—¶æ˜¾ç¤º\n",
    "        LATEST_LOG=$(ls -t /shared/financial_reward_model/logs/distributed/deepspeed_final_*.log 2>/dev/null | head -1)\n",
    "        if [[ -n \"$LATEST_LOG\" ]]; then\n",
    "            tail -f -n 300 \"$LATEST_LOG\"  # å®æ—¶æ˜¾ç¤ºæ—¥å¿—å†…å®¹\n",
    "        else\n",
    "            # å¦‚æœæ²¡æ‰¾åˆ°deepspeed_finalå¼€å¤´çš„æ—¥å¿—ï¼Œå°è¯•æŸ¥æ‰¾deepspeedå¼€å¤´çš„\n",
    "            LATEST_LOG=$(ls -t /shared/financial_reward_model/logs/distributed/deepspeed_*.log 2>/dev/null | head -1)\n",
    "            if [[ -n \"$LATEST_LOG\" ]]; then\n",
    "                tail -f \"$LATEST_LOG\"\n",
    "            else\n",
    "                log_error \"æœªæ‰¾åˆ°æ—¥å¿—æ–‡ä»¶\"\n",
    "            fi\n",
    "        fi\n",
    "        ;;\n",
    "    *)\n",
    "        echo \"ä¿®æ­£ç‰ˆDeepSpeedå¤šæœºå¤šå¡è®­ç»ƒ\"\n",
    "        echo \"ç”¨æ³•: $0 {start|stop|logs|resume}\"\n",
    "        echo \"\"\n",
    "        echo \"  start  - å¯åŠ¨æ–°è®­ç»ƒ\"\n",
    "        echo \"  stop   - åœæ­¢è®­ç»ƒ\"\n",
    "        echo \"  logs   - ç›‘æ§æ—¥å¿—\"\n",
    "        echo \"  resume <checkpoint> - ä»checkpointæ¢å¤è®­ç»ƒ\"\n",
    "        ;;\n",
    "esac\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7942b8",
   "metadata": {},
   "source": [
    "run_training.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334d4267",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# ================================================================================\n",
    "#  æ–‡ä»¶ä½œç”¨è¯´æ˜ï¼š\n",
    "# è¿™æ˜¯å•æœºå¤šå¡è®­ç»ƒçš„å¯åŠ¨è„šæœ¬ï¼ˆä½¿ç”¨torchrunæ–¹å¼ï¼‰\n",
    "# \n",
    "# åŸå› ï¼šé¡¹ç›®ä½¿ç”¨çš„æ˜¯DeepSpeedåˆ†å¸ƒå¼è®­ç»ƒï¼Œè€Œä¸æ˜¯torchrunæ–¹å¼\n",
    "# å®é™…ä½¿ç”¨çš„æ˜¯ï¼šdeepspeed_cluster_launcher.sh\n",
    "# \n",
    "#  åŸæœ¬çš„è®¾è®¡ä½œç”¨ï¼š\n",
    "# 1. åœ¨å•å°æœåŠ¡å™¨ä¸Šä½¿ç”¨4å¼ GPUè¿›è¡Œè®­ç»ƒ\n",
    "# 2. ä½¿ç”¨PyTorchåŸç”Ÿçš„torchrunè¿›è¡Œåˆ†å¸ƒå¼è®­ç»ƒ\n",
    "# 3. æä¾›åå°è®­ç»ƒå’Œæ—¥å¿—ç®¡ç†åŠŸèƒ½\n",
    "# \n",
    "#  ä¿ç•™åŸå› ï¼šä½œä¸ºå¤‡ç”¨æ–¹æ¡ˆï¼Œå¦‚æœéœ€è¦å•æœºè®­ç»ƒæ—¶å¯ä»¥å‚è€ƒ\n",
    "# ================================================================================\n",
    "\n",
    "# 4å¼ GPUè®­ç»ƒè„šæœ¬ï¼ˆnohupæ¨¡å¼ï¼‰\n",
    "echo \" å¼€å§‹åå°è®­ç»ƒé‡‘èå¥–åŠ±æ¨¡å‹ï¼ˆ4å¼ 4090 + DeepSpeed Stage 2ï¼‰\"\n",
    "\n",
    "# ============================================================================\n",
    "#  ç¯å¢ƒå˜é‡è®¾ç½®ï¼šé…ç½®CUDAå’Œè®­ç»ƒç›¸å…³çš„ç¯å¢ƒå‚æ•°\n",
    "# \n",
    "#  è¿™äº›å˜é‡çš„ä½œç”¨ï¼š\n",
    "# 1. CUDA_VISIBLE_DEVICESï¼šå‘Šè¯‰ç¨‹åºä½¿ç”¨å“ªäº›GPUï¼ˆ0,1,2,3è¡¨ç¤ºä½¿ç”¨å‰4å¼ å¡ï¼‰\n",
    "# 2. NCCL_DEBUGï¼šå¯ç”¨NCCLé€šä¿¡åº“çš„è°ƒè¯•ä¿¡æ¯ï¼Œå¸®åŠ©æ’æŸ¥åˆ†å¸ƒå¼è®­ç»ƒé—®é¢˜\n",
    "# 3. OMP_NUM_THREADSï¼šé™åˆ¶OpenMPçº¿ç¨‹æ•°ï¼Œé¿å…CPUèµ„æºç«äº‰\n",
    "# ============================================================================\n",
    "export CUDA_VISIBLE_DEVICES=0,1,2,3  # æŒ‡å®šä½¿ç”¨GPU 0,1,2,3\n",
    "export NCCL_DEBUG=INFO                # å¯ç”¨NCCLè°ƒè¯•ä¿¡æ¯\n",
    "export OMP_NUM_THREADS=1              # è®¾ç½®OpenMPçº¿ç¨‹æ•°ä¸º1\n",
    "\n",
    "# ============================================================================\n",
    "#  å¤šæœºå¤šå¡é…ç½®ï¼šå®šä¹‰åˆ†å¸ƒå¼è®­ç»ƒçš„ç½‘ç»œå‚æ•°\n",
    "# \n",
    "#  è¿™äº›å‚æ•°çš„ä½œç”¨ï¼š\n",
    "# 1. MASTER_ADDRï¼šä¸»èŠ‚ç‚¹çš„IPåœ°å€ï¼Œæ‰€æœ‰èŠ‚ç‚¹éƒ½è¦è¿æ¥åˆ°è¿™ä¸ªåœ°å€\n",
    "# 2. MASTER_PORTï¼šä¸»èŠ‚ç‚¹çš„ç«¯å£å·ï¼Œç”¨äºèŠ‚ç‚¹é—´é€šä¿¡\n",
    "# 3. NNODESï¼šæ€»èŠ‚ç‚¹æ•°ï¼ˆè¿™é‡Œè®¾ä¸º1ï¼Œè¡¨ç¤ºå•æœºè®­ç»ƒï¼‰\n",
    "# 4. NODE_RANKï¼šå½“å‰èŠ‚ç‚¹çš„ç¼–å·ï¼ˆä»0å¼€å§‹ï¼‰\n",
    "# 5. NPROC_PER_NODEï¼šæ¯ä¸ªèŠ‚ç‚¹çš„è¿›ç¨‹æ•°ï¼ˆç­‰äºGPUæ•°é‡ï¼‰\n",
    "# ============================================================================\n",
    "MASTER_ADDR=${MASTER_ADDR:-\"localhost\"}  # é»˜è®¤ä¸»èŠ‚ç‚¹åœ°å€ä¸ºlocalhost\n",
    "MASTER_PORT=${MASTER_PORT:-29500}        # é»˜è®¤ç«¯å£å·ä¸º29500\n",
    "NNODES=${NNODES:-1}                      # é»˜è®¤èŠ‚ç‚¹æ•°ä¸º1ï¼ˆå•æœºï¼‰\n",
    "NODE_RANK=${NODE_RANK:-0}                # é»˜è®¤èŠ‚ç‚¹ç¼–å·ä¸º0ï¼ˆä¸»èŠ‚ç‚¹ï¼‰\n",
    "NPROC_PER_NODE=${NPROC_PER_NODE:-4}      # é»˜è®¤æ¯èŠ‚ç‚¹4ä¸ªè¿›ç¨‹ï¼ˆ4å¼ GPUï¼‰\n",
    "\n",
    "# ============================================================================\n",
    "#  é¡¹ç›®è·¯å¾„è®¾ç½®ï¼šç¡®å®šé¡¹ç›®æ ¹ç›®å½•å¹¶åˆ‡æ¢åˆ°è¯¥ç›®å½•\n",
    "# \n",
    "#  è¿™æ®µä»£ç çš„ä½œç”¨ï¼š\n",
    "# 1. è‡ªåŠ¨æ‰¾åˆ°é¡¹ç›®çš„æ ¹ç›®å½•ï¼ˆå‘ä¸ŠæŸ¥æ‰¾ä¸¤çº§ç›®å½•ï¼‰\n",
    "# 2. åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•ï¼Œç¡®ä¿æ‰€æœ‰ç›¸å¯¹è·¯å¾„éƒ½æ˜¯æ­£ç¡®çš„\n",
    "# 3. æ‰“å°é¡¹ç›®ä¿¡æ¯ï¼Œä¾¿äºç¡®è®¤é…ç½®\n",
    "# ============================================================================\n",
    "PROJECT_ROOT=$(cd \"$(dirname \"$0\")/../..\" && pwd)  # è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„\n",
    "cd $PROJECT_ROOT  # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•\n",
    "\n",
    "echo \" é¡¹ç›®æ ¹ç›®å½•: $PROJECT_ROOT\"\n",
    "echo \" GPUé…ç½®: 4å¼ RTX 4090\"\n",
    "echo \" æ‰¹æ¬¡é…ç½®: æ€»æ‰¹æ¬¡å¤§å° = 4 GPU Ã— 2 batch Ã— 4 accumulation = 32\"\n",
    "\n",
    "# ============================================================================\n",
    "#  é¢„æ£€æŸ¥ï¼šè®­ç»ƒå¼€å§‹å‰çš„ç¯å¢ƒå’Œæ•°æ®æ£€æŸ¥\n",
    "# \n",
    "#  è¿™ä¸ªæ£€æŸ¥çš„ä½œç”¨ï¼š\n",
    "# 1. éªŒè¯è®­ç»ƒæ•°æ®æ˜¯å¦å­˜åœ¨ä¸”æ ¼å¼æ­£ç¡®\n",
    "# 2. éªŒè¯æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å®Œæ•´\n",
    "# 3. å¦‚æœæ£€æŸ¥å¤±è´¥ï¼Œæå‰ç»ˆæ­¢ï¼Œé¿å…æµªè´¹è®¡ç®—èµ„æº\n",
    "# \n",
    "# ============================================================================\n",
    "echo \" æ£€æŸ¥æ•°æ®å’Œæ¨¡å‹...\"\n",
    "python scripts/setup/check_data.py  # æ‰§è¡Œæ•°æ®å’Œæ¨¡å‹æ£€æŸ¥è„šæœ¬\n",
    "if [ $? -ne 0 ]; then              # å¦‚æœæ£€æŸ¥è„šæœ¬è¿”å›é0å€¼ï¼ˆè¡¨ç¤ºå¤±è´¥ï¼‰\n",
    "    echo \"âŒ æ•°æ®æˆ–æ¨¡å‹æ£€æŸ¥å¤±è´¥ï¼Œé€€å‡ºè®­ç»ƒ\"\n",
    "    exit 1                          # é€€å‡ºè„šæœ¬\n",
    "fi\n",
    "\n",
    "echo \"âœ… æ‰€æœ‰æ£€æŸ¥é€šè¿‡\"\n",
    "\n",
    "# ============================================================================\n",
    "#  æ—¥å¿—ç®¡ç†ï¼šåˆ›å»ºæ—¥å¿—ç›®å½•å’Œæ–‡ä»¶å\n",
    "# \n",
    "#  è¿™ä¸ªè®¾ç½®çš„ä½œç”¨ï¼š\n",
    "# 1. ä¸ºæ¯æ¬¡è®­ç»ƒåˆ›å»ºç‹¬ç‰¹çš„æ—¥å¿—æ–‡ä»¶ï¼ˆä½¿ç”¨æ—¶é—´æˆ³ï¼‰\n",
    "# 2. ä¿å­˜è¿›ç¨‹PIDï¼Œä¾¿äºåç»­ç®¡ç†å’Œåœæ­¢è®­ç»ƒ\n",
    "# 3. å°†æ‰€æœ‰è¾“å‡ºé‡å®šå‘åˆ°æ—¥å¿—æ–‡ä»¶ï¼Œä¾¿äºåç»­åˆ†æ\n",
    "# ============================================================================\n",
    "mkdir -p logs  # åˆ›å»ºlogsç›®å½•ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰\n",
    "\n",
    "# ç”Ÿæˆæ—¶é—´æˆ³ï¼Œæ ¼å¼ï¼šå¹´æœˆæ—¥_æ—¶åˆ†ç§’\n",
    "TIMESTAMP=$(date +\"%Y%m%d_%H%M%S\")\n",
    "LOG_FILE=\"logs/training_${TIMESTAMP}.log\"      # æ—¥å¿—æ–‡ä»¶è·¯å¾„\n",
    "PID_FILE=\"logs/training_${TIMESTAMP}.pid\"      # PIDæ–‡ä»¶è·¯å¾„\n",
    "\n",
    "echo \" æ—¥å¿—æ–‡ä»¶: $LOG_FILE\"\n",
    "echo \" PIDæ–‡ä»¶: $PID_FILE\"\n",
    "\n",
    "# ============================================================================\n",
    "#  å¯åŠ¨è®­ç»ƒï¼šä½¿ç”¨nohupå’Œtorchrunå¯åŠ¨åå°è®­ç»ƒ\n",
    "# \n",
    "#  è¿™ä¸ªå‘½ä»¤çš„ä½œç”¨ï¼š\n",
    "# 1. nohupï¼šè®©è®­ç»ƒåœ¨åå°è¿è¡Œï¼Œå³ä½¿ç»ˆç«¯å…³é—­ä¹Ÿä¸ä¼šåœæ­¢\n",
    "# 2. torchrunï¼šPyTorchçš„åˆ†å¸ƒå¼è®­ç»ƒå¯åŠ¨å™¨\n",
    "# 3. å„ç§å‚æ•°å‘Šè¯‰torchrunå¦‚ä½•åˆ†é…GPUå’Œç®¡ç†è¿›ç¨‹\n",
    "# \n",
    "# âš ï¸ é‡è¦ï¼šè¿™ä¸ªæ–¹å¼åœ¨å½“å‰é¡¹ç›®ä¸­æœªè¢«ä½¿ç”¨ï¼Œå®é™…ä½¿ç”¨çš„æ˜¯DeepSpeed\n",
    "# ============================================================================\n",
    "echo \" å¯åŠ¨åå°è®­ç»ƒ...\"\n",
    "nohup torchrun \\\n",
    "    --nnodes=$NNODES \\                    # èŠ‚ç‚¹æ•°é‡\n",
    "    --nproc_per_node=$NPROC_PER_NODE \\    # æ¯èŠ‚ç‚¹è¿›ç¨‹æ•°\n",
    "    --node_rank=$NODE_RANK \\              # èŠ‚ç‚¹ç¼–å·\n",
    "    --master_addr=$MASTER_ADDR \\          # ä¸»èŠ‚ç‚¹åœ°å€\n",
    "    --master_port=$MASTER_PORT \\          # ä¸»èŠ‚ç‚¹ç«¯å£\n",
    "    src/train_reward_model.py \\           # è®­ç»ƒè„šæœ¬è·¯å¾„\n",
    "    configs/training/config.json \\       # é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆæ³¨æ„ï¼šè¿™ä¸ªé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼‰\n",
    "    > $LOG_FILE 2>&1 &                   # é‡å®šå‘è¾“å‡ºåˆ°æ—¥å¿—æ–‡ä»¶å¹¶åå°è¿è¡Œ\n",
    "\n",
    "# ============================================================================\n",
    "#  ä¿å­˜PIDå’Œæä¾›ç›‘æ§ä¿¡æ¯\n",
    "# \n",
    "#  è¿™éƒ¨åˆ†çš„ä½œç”¨ï¼š\n",
    "# 1. ä¿å­˜è®­ç»ƒè¿›ç¨‹çš„PIDï¼Œä¾¿äºåç»­åœæ­¢è®­ç»ƒ\n",
    "# 2. å‘ç”¨æˆ·æä¾›å„ç§ç›‘æ§å’Œç®¡ç†å‘½ä»¤\n",
    "# 3. è®©ç”¨æˆ·çŸ¥é“å¦‚ä½•æŸ¥çœ‹è®­ç»ƒçŠ¶æ€å’Œåœæ­¢è®­ç»ƒ\n",
    "# ============================================================================\n",
    "TRAIN_PID=$!                    # è·å–åå°è¿›ç¨‹çš„PID\n",
    "echo $TRAIN_PID > $PID_FILE     # å°†PIDä¿å­˜åˆ°æ–‡ä»¶\n",
    "\n",
    "echo \" è®­ç»ƒå·²åœ¨åå°å¯åŠ¨ï¼\"\n",
    "echo \" è¿›ç¨‹ID: $TRAIN_PID\"\n",
    "echo \" æ—¥å¿—æ–‡ä»¶: $LOG_FILE\"\n",
    "echo \" PIDæ–‡ä»¶: $PID_FILE\"\n",
    "echo \"\"\n",
    "echo \" ç›‘æ§å‘½ä»¤:\"\n",
    "echo \"  æŸ¥çœ‹å®æ—¶æ—¥å¿—: tail -f -n 300 $LOG_FILE\"\n",
    "echo \"  æŸ¥çœ‹GPUä½¿ç”¨: watch -n 1 nvidia-smi\"\n",
    "echo \"  æŸ¥çœ‹è¿›ç¨‹çŠ¶æ€: ps aux | grep $TRAIN_PID\"\n",
    "echo \"  åœæ­¢è®­ç»ƒ: kill $TRAIN_PID\"\n",
    "echo \"  å¯åŠ¨tensorboard: tensorboard --logdir=./logs --port=6006\"\n",
    "echo \"\"\n",
    "echo \" è®­ç»ƒçŠ¶æ€æ£€æŸ¥:\"\n",
    "echo \"  ps aux | grep torchrun\"\n",
    "echo \"  tail -20 $LOG_FILE\" \n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c6295fe",
   "metadata": {},
   "source": [
    "config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1542b75f",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"model_name_or_path\": \"/shared/Skywork-Reward-Llama-3.1-8B\",\n",
    "  \"trust_remote_code\": true,\n",
    "  \"torch_dtype\": \"bfloat16\",\n",
    "  \n",
    "  \"data_path\": \"/shared/reward_model_data/reward_data\",\n",
    "  \"max_length\": 512,\n",
    "  \n",
    "  \"freeze_trainable_layers\": 4,\n",
    "  \"freeze_trainable_modules\": \"all\",\n",
    "  \"freeze_extra_modules\": \"score\",\n",
    "  \n",
    "  \"output_dir\": \"/shared/financial_reward_model/output/\",\n",
    "  \"logging_dir\": \"/shared/financial_reward_model/logs/\",\n",
    "  \"num_train_epochs\": 2,\n",
    "  \"learning_rate\": 5e-5,\n",
    "  \"warmup_ratio\": 0.1,\n",
    "  \"weight_decay\": 0.01,\n",
    "  \"seed\": 42,\n",
    "  \n",
    "  \"per_device_train_batch_size\": 2,\n",
    "  \"per_device_eval_batch_size\": 4,\n",
    "  \"gradient_accumulation_steps\": 4,\n",
    "  \n",
    "  \"bf16\": true,\n",
    "  \"fp16\": false,\n",
    "  \"tf32\": true,\n",
    "  \"max_grad_norm\": 1.0,\n",
    "  \n",
    "  \"evaluation_strategy\": \"steps\",\n",
    "  \"eval_steps\": 50,\n",
    "  \"save_strategy\": \"steps\", \n",
    "  \"save_steps\": 100,\n",
    "  \"save_total_limit\": 2,\n",
    "  \n",
    "  \"logging_steps\": 10,\n",
    "  \"load_best_model_at_end\": true,\n",
    "  \"metric_for_best_model\": \"eval_loss\",\n",
    "  \"greater_is_better\": false,\n",
    "  \"early_stopping_patience\": 5,\n",
    "  \n",
    "  \"deepspeed_stage\": 2,\n",
    "  \"deepspeed_offload_optimizer\": true,\n",
    "  \"deepspeed_offload_param\": false\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1681e55a",
   "metadata": {},
   "source": [
    "deepspeed_only.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19338a83",
   "metadata": {},
   "source": [
    "```json\n",
    "{\n",
    "  \"zero_optimization\": {\n",
    "    \"stage\": 2,\n",
    "    \"offload_optimizer\": {\n",
    "      \"device\": \"cpu\",\n",
    "      \"pin_memory\": true\n",
    "    },\n",
    "    \"allgather_partitions\": true,\n",
    "    \"allgather_bucket_size\": 5e8,\n",
    "    \"overlap_comm\": true,\n",
    "    \"reduce_scatter\": true,\n",
    "    \"reduce_bucket_size\": 5e8,\n",
    "    \"contiguous_gradients\": true\n",
    "  },\n",
    "  \"optimizer\": {\n",
    "    \"type\": \"AdamW\",\n",
    "    \"params\": {\n",
    "      \"lr\": \"auto\",\n",
    "      \"betas\": \"auto\",\n",
    "      \"eps\": \"auto\",\n",
    "      \"weight_decay\": \"auto\"\n",
    "    }\n",
    "  },\n",
    "  \"scheduler\": {\n",
    "    \"type\": \"WarmupLR\",\n",
    "    \"params\": {\n",
    "      \"warmup_min_lr\": \"auto\",\n",
    "      \"warmup_max_lr\": \"auto\",\n",
    "      \"warmup_num_steps\": \"auto\"\n",
    "    }\n",
    "  },\n",
    "  \"bf16\": {\n",
    "    \"enabled\": \"auto\"\n",
    "  },\n",
    "  \"train_batch_size\": \"auto\",\n",
    "  \"train_micro_batch_size_per_gpu\": \"auto\",\n",
    "  \"gradient_accumulation_steps\": \"auto\",\n",
    "  \"gradient_clipping\": 1.0,\n",
    "  \"steps_per_print\": 1000,\n",
    "  \"wall_clock_breakdown\": false,\n",
    "  \"dump_state\": false,\n",
    "  \"communication_data_type\": \"fp16\",\n",
    "  \"checkpoint\": {\n",
    "    \"save_zero_checkpoint\": false\n",
    "  },\n",
    "  \"flops_profiler\": {\n",
    "    \"enabled\": false,\n",
    "    \"profile_step\": 1,\n",
    "    \"module_depth\": -1,\n",
    "    \"top_modules\": 1,\n",
    "    \"detailed\": true,\n",
    "    \"output_file\": null\n",
    "  }\n",
    "} \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7934c54",
   "metadata": {},
   "source": [
    "ä»å¤´å¼€å§‹è®­ç»ƒï¼š bash scripts/training/deepspeed_cluster_launcher.sh start  å¼€å§‹è®­ç»ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fe02b8",
   "metadata": {},
   "source": [
    "checkpointèŠ‚ç‚¹ç»§ç»­è®­ç»ƒï¼šbash scripts/training/deepspeed_cluster_launcher.sh resume output/checkpoint-700"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bcd6fc7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625112348743.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2844861d",
   "metadata": {},
   "source": [
    "é›†ç¾¤èµ„æºå ç”¨æƒ…å†µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fec8560a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250617193326191.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce46b76",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250617193356957.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce8330f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250617193413751.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eae75d2c",
   "metadata": {},
   "source": [
    "checkpointä¸final_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51327692",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625113415966.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0e26d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625113540563.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606d1ca1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625113432900.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11a007d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625113513254.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba6ad0a",
   "metadata": {},
   "source": [
    "è®­ç»ƒå®Œæˆæ—¥å¿—ä¿¡æ¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe3112",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624191601169.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc21b493",
   "metadata": {},
   "source": [
    "æŸ¥çœ‹trainer_state.jsonæ–‡ä»¶ï¼Œé‡Œé¢åŒ…å«äº†å®Œæ•´çš„è®­ç»ƒçŠ¶æ€\n",
    "\n",
    "cat /shared/financial_reward_model/output/checkpoint-1000/trainer_state.json | grep -A 5 -B 5 \"eval_loss\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e419421",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624192638311.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a8ee8",
   "metadata": {},
   "source": [
    "QRM-Llama3.1-8B-v2   å‡†ç¡®ç‡100%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6651bb66",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625143413642.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bac7eb8c",
   "metadata": {},
   "source": [
    "# 4. æ­å»º+æµ‹è¯•æ‰§è¡Œç¯å¢ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c56332",
   "metadata": {},
   "source": [
    "## åˆ†å¸ƒå¼ç¯å¢ƒéƒ¨ç½²æ–¹å¼ä¸€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e5d9c1",
   "metadata": {},
   "source": [
    "**Ray+vllm**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba8bbd9",
   "metadata": {},
   "source": [
    "conda create -n vllm python=3.11 -y (æ³¨æ„å½“å‰ç¯å¢ƒåˆ›å»ºä»¥åŠä¹‹åçš„è®¾ç½®é›†ç¾¤ä¸­`å¿…é¡»ç›¸åŒ`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68f92b58",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618115211874.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77f6359",
   "metadata": {},
   "source": [
    "## Rayæ˜¯ä»€ä¹ˆï¼Ÿ\n",
    "\n",
    "**Rayæ˜¯ä¸€ä¸ªå¼€æºçš„åˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶**ï¼Œä¸“ä¸ºPythonå’Œæœºå™¨å­¦ä¹ åº”ç”¨è®¾è®¡ï¼Œèƒ½å¤Ÿå°†åº”ç”¨ä»å•æœºæ‰©å±•åˆ°å¤šèŠ‚ç‚¹é›†ç¾¤ã€‚\n",
    "\n",
    "### 1. é›†ç¾¤æ¶æ„\n",
    "Rayé‡‡ç”¨**é›†ç¾¤æ¶æ„**ï¼ŒåŒ…å«ï¼š\n",
    "- **å¤´èŠ‚ç‚¹ï¼ˆHead Nodeï¼‰**ï¼šå•ä¸ªèŠ‚ç‚¹ï¼Œè¿è¡Œé›†ç¾¤ç®¡ç†è¿›ç¨‹\n",
    "- **å·¥ä½œèŠ‚ç‚¹ï¼ˆWorker Nodesï¼‰**ï¼šå¤šä¸ªèŠ‚ç‚¹ï¼Œæ‰§è¡Œå®é™…ä»»åŠ¡\n",
    "\n",
    "### 2. æ ¸å¿ƒè¿›ç¨‹ç»„ä»¶\n",
    "\n",
    "#### **Raylet**ï¼ˆæ¯ä¸ªèŠ‚ç‚¹éƒ½æœ‰ï¼‰\n",
    "Rayletæ˜¯Rayåœ¨æ¯ä¸ªèŠ‚ç‚¹ä¸Šçš„æ ¸å¿ƒä»£ç†è¿›ç¨‹ï¼ŒåŒ…å«ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼š\n",
    "\n",
    "1. **è°ƒåº¦å™¨ï¼ˆSchedulerï¼‰**ï¼š\n",
    "   - è´Ÿè´£èµ„æºç®¡ç†å’Œä»»åŠ¡è°ƒåº¦\n",
    "   - å†³å®šå“ªä¸ªworkerè¿›ç¨‹æ‰§è¡Œå“ªä¸ªä»»åŠ¡\n",
    "   - ç®¡ç†CPUã€GPUã€å†…å­˜ç­‰èµ„æºåˆ†é…\n",
    "\n",
    "2. **å¯¹è±¡å­˜å‚¨ï¼ˆObject Storeï¼‰**ï¼š\n",
    "   - åŸºäºApache Arrowçš„Plasmaå¯¹è±¡å­˜å‚¨\n",
    "   - ä½¿ç”¨å…±äº«å†…å­˜å­˜å‚¨å¤§å‹å¯¹è±¡\n",
    "   - å®ç°é›¶æ‹·è´æ•°æ®å…±äº«ï¼ˆåŒèŠ‚ç‚¹å†…ï¼‰\n",
    "\n",
    "#### **GCSï¼ˆGlobal Control Storeï¼‰**\n",
    "- è¿è¡Œåœ¨å¤´èŠ‚ç‚¹ä¸Šçš„å…¨å±€æ§åˆ¶æœåŠ¡\n",
    "- é”®å€¼å­˜å‚¨ï¼Œä¿å­˜ç³»ç»Ÿçº§å…ƒæ•°æ®\n",
    "- å­˜å‚¨å¯¹è±¡ä½ç½®ã€Actorä¿¡æ¯ç­‰\n",
    "- æ¥æ”¶èŠ‚ç‚¹å¿ƒè·³ä¿¡å·\n",
    "\n",
    "#### **Workerè¿›ç¨‹**\n",
    "- æ‰§è¡Œå®é™…çš„Rayä»»åŠ¡å’ŒActoræ–¹æ³•\n",
    "- æ¯ä¸ªCPUæ ¸å¿ƒé€šå¸¸å¯¹åº”ä¸€ä¸ªworkerè¿›ç¨‹\n",
    "\n",
    "## Rayçš„è°ƒåº¦ç®—æ³•\n",
    "\n",
    "### 1. ä»»åŠ¡è°ƒåº¦æµç¨‹\n",
    "```json\n",
    "1. ç”¨æˆ·è°ƒç”¨ task.remote() â†’ \n",
    "2. å‘æœ¬åœ°Rayletç”³è¯·workerç§Ÿçº¦ â†’ \n",
    "3. Rayletæ£€æŸ¥èµ„æºéœ€æ±‚å’Œä¾èµ– â†’ \n",
    "4. åˆ†é…åˆé€‚çš„worker â†’ \n",
    "5. é€šè¿‡gRPCå‘é€ExecuteTask RPC â†’ \n",
    "6. Workeræ‰§è¡Œä»»åŠ¡å¹¶è¿”å›ç»“æœ\n",
    "```\n",
    "\n",
    "### 2. è°ƒåº¦ä¼˜åŒ–ç­–ç•¥\n",
    "- **è°ƒåº¦å†³ç­–ç¼“å­˜**ï¼šç›¸åŒç±»å‹ä»»åŠ¡é‡ç”¨ä¹‹å‰çš„è°ƒåº¦å†³ç­–\n",
    "- **å±€éƒ¨æ€§ä¼˜åŒ–**ï¼šä¼˜å…ˆåœ¨æœ‰æ•°æ®çš„èŠ‚ç‚¹ä¸Šè°ƒåº¦ä»»åŠ¡\n",
    "- **è´Ÿè½½å‡è¡¡**ï¼šä»»åŠ¡åˆ†å¸ƒåˆ°å¤šä¸ªèŠ‚ç‚¹ä»¥æœ€å¤§åŒ–èµ„æºåˆ©ç”¨ç‡\n",
    "\n",
    "### 3. è·¨èŠ‚ç‚¹è°ƒåº¦\n",
    "å¦‚æœæœ¬åœ°æ²¡æœ‰å¯ç”¨èµ„æºï¼š\n",
    "1. æœ¬åœ°Rayleté‡å®šå‘è¯·æ±‚åˆ°æœ‰èµ„æºçš„è¿œç¨‹Raylet\n",
    "2. é€šè¿‡gRPCç›´æ¥å‘è¿œç¨‹workerå‘é€ä»»åŠ¡\n",
    "3. æ”¯æŒé€æ˜çš„å¤šèŠ‚ç‚¹æ‰©å±•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be469571",
   "metadata": {},
   "source": [
    "### å¤šç§é€šä¿¡åç«¯æ”¯æŒ\n",
    "\n",
    "1. **NCCLï¼ˆNVIDIA Collective Communication Libraryï¼‰**\n",
    "   - ä¸»è¦ç”¨äºGPUé—´çš„é›†åˆé€šä¿¡ï¼ˆAll-Reduceã€All-Gatherç­‰ï¼‰\n",
    "   - é€‚ç”¨äºæ·±åº¦å­¦ä¹ çš„å¼ é‡å¹¶è¡Œåœºæ™¯\n",
    "   - éœ€è¦NVIDIA GPUå’ŒCUDAç¯å¢ƒ\n",
    "\n",
    "2. **Gloo**\n",
    "   - Facebookå¼€å‘çš„é€šä¿¡åº“\n",
    "   - æ”¯æŒCPUå’ŒGPU\n",
    "   - è·¨å¹³å°å…¼å®¹æ€§æ›´å¥½\n",
    "\n",
    "3. **Rayå†…ç½®é€šä¿¡åè®®**\n",
    "   - åŸºäºgRPCå’ŒApache Arrow\n",
    "   - ç”¨äºä¸€èˆ¬çš„åˆ†å¸ƒå¼å¯¹è±¡ä¼ è¾“\n",
    "   - ä¸ä¾èµ–ç‰¹å®šçš„ç¡¬ä»¶\n",
    "\n",
    "4. **TCP/InfiniBandç›´è¿**\n",
    "   - ç‚¹å¯¹ç‚¹çš„ç½‘ç»œé€šä¿¡\n",
    "   - ç”¨äºå¤§æ•°æ®ä¼ è¾“\n",
    "\n",
    "### é€šä¿¡æ–¹å¼çš„é€‰æ‹©é€»è¾‘\n",
    "\n",
    "```json\n",
    "æ ¹æ®ä»»åŠ¡ç±»å‹è‡ªåŠ¨é€‰æ‹©:\n",
    "â”œâ”€â”€ æ·±åº¦å­¦ä¹ å¼ é‡å¹¶è¡Œ â†’ NCCL\n",
    "â”œâ”€â”€ ä¸€èˆ¬åˆ†å¸ƒå¼è®¡ç®— â†’ Gloo\n",
    "â”œâ”€â”€ å¯¹è±¡ä¼ è¾“ â†’ Rayå†…ç½®åè®®\n",
    "â””â”€â”€ å¤§æ–‡ä»¶ä¼ è¾“ â†’ ç›´æ¥TCPè¿æ¥\n",
    "```\n",
    "\n",
    "### å­èŠ‚ç‚¹é—´é€šä¿¡æœºåˆ¶\n",
    "\n",
    "#### ç›´æ¥é€šä¿¡çš„å®ç°\n",
    "\n",
    "**Rayçš„WorkerèŠ‚ç‚¹é—´å¯ä»¥ç›´æ¥é€šä¿¡ï¼Œæ— éœ€é€šè¿‡ä¸»èŠ‚ç‚¹ä¸­è½¬ï¼š**\n",
    "\n",
    "1. **å»ºç«‹è¿æ¥çš„è¿‡ç¨‹ï¼š**\n",
    "```json\n",
    "Worker A éœ€è¦ä¸ Worker B é€šä¿¡\n",
    "    â†“\n",
    "Worker A å‘ Head Node è¯·æ±‚ Worker B çš„åœ°å€ä¿¡æ¯\n",
    "    â†“\n",
    "Head Node è¿”å› Worker B çš„ IP:Port\n",
    "    â†“\n",
    "Worker A ç›´æ¥è¿æ¥ Worker B å»ºç«‹é€šä¿¡é“¾è·¯\n",
    "    â†“\n",
    "åç»­æ•°æ®ä¼ è¾“ç»•è¿‡ Head Node\n",
    "```\n",
    "\n",
    "2. **è¿æ¥å¤ç”¨æœºåˆ¶ï¼š**\n",
    "   - ä¸€æ—¦å»ºç«‹è¿æ¥ï¼ŒWorkeré—´ä¼šå¤ç”¨è¿™ä¸ªè¿æ¥\n",
    "   - é¿å…æ¯æ¬¡é€šä¿¡éƒ½è¯¢é—®Head Node\n",
    "   - æé«˜é€šä¿¡æ•ˆç‡\n",
    "\n",
    "### ä¸»èŠ‚ç‚¹çš„æ ¸å¿ƒä½œç”¨è§£æ\n",
    "\n",
    "#### 1. é›†ç¾¤å¼•å¯¼å’ŒæœåŠ¡å‘ç°\n",
    "\n",
    "**ä¸»èŠ‚ç‚¹æ˜¯é›†ç¾¤çš„\"ç”µè¯ç°¿\"ï¼š**\n",
    "- ç»´æŠ¤æ‰€æœ‰WorkerèŠ‚ç‚¹çš„åœ°å€ä¿¡æ¯\n",
    "- æ–°èŠ‚ç‚¹åŠ å…¥æ—¶çš„æ³¨å†Œä¸­å¿ƒ\n",
    "- æä¾›èŠ‚ç‚¹é—´çš„æœåŠ¡å‘ç°èƒ½åŠ›\n",
    "\n",
    "```json\n",
    "Workerå¯åŠ¨æ—¶:\n",
    "Worker â†’ å‘Head Nodeæ³¨å†Œ (æˆ‘åœ¨192.168.1.100:8001)\n",
    "Head Node â†’ è®°å½•åˆ°èŠ‚ç‚¹åˆ—è¡¨\n",
    "å…¶ä»–Worker â†’ è¯¢é—®Head NodeæŸä¸ªæœåŠ¡åœ¨å“ªé‡Œ\n",
    "Head Node â†’ è¿”å›åœ°å€ä¿¡æ¯\n",
    "```\n",
    "\n",
    "#### 2. èµ„æºè°ƒåº¦å’Œä»»åŠ¡åˆ†å‘\n",
    "\n",
    "**ä¸»èŠ‚ç‚¹æ˜¯\"è°ƒåº¦ä¸­å¿ƒ\"ï¼š**\n",
    "- ç»´æŠ¤å…¨å±€èµ„æºçŠ¶æ€ï¼ˆCPUã€GPUã€å†…å­˜ä½¿ç”¨æƒ…å†µï¼‰\n",
    "- å†³å®šæ–°ä»»åŠ¡åº”è¯¥åœ¨å“ªä¸ªèŠ‚ç‚¹æ‰§è¡Œ\n",
    "- å®ç°è´Ÿè½½å‡è¡¡å’Œèµ„æºä¼˜åŒ–\n",
    "\n",
    "#### 3. åˆ†å¸ƒå¼å¯¹è±¡å­˜å‚¨çš„å…ƒæ•°æ®ç®¡ç†\n",
    "\n",
    "**ä¸»èŠ‚ç‚¹ç®¡ç†\"æ•°æ®åœ°å›¾\"ï¼š**\n",
    "- è®°å½•åˆ†å¸ƒå¼å¯¹è±¡å­˜å‚¨åœ¨å“ªä¸ªèŠ‚ç‚¹\n",
    "- ç®¡ç†å¯¹è±¡çš„å¼•ç”¨è®¡æ•°å’Œç”Ÿå‘½å‘¨æœŸ\n",
    "- åè°ƒè·¨èŠ‚ç‚¹çš„æ•°æ®ä¼ è¾“\n",
    "\n",
    "#### 4. å…¨å±€çŠ¶æ€åŒæ­¥\n",
    "\n",
    "**ä¸»èŠ‚ç‚¹æ˜¯\"çŠ¶æ€ä¸­å¿ƒ\"ï¼š**\n",
    "- æ”¶é›†å„èŠ‚ç‚¹çš„å¥åº·çŠ¶æ€\n",
    "- å¤„ç†èŠ‚ç‚¹æ•…éšœå’Œæ¢å¤\n",
    "- ç»´æŠ¤å…¨å±€çš„å‘½åç©ºé—´\n",
    "\n",
    "\n",
    "**åœ¨Ray + Transformeræ¶æ„ä¸­ï¼š**\n",
    "\n",
    "1. **HTTPè¯·æ±‚è·¯ç”±**ï¼šå¿…é¡»é€šè¿‡Head Node\n",
    "2. **æ¨¡å‹æ¨ç†**ï¼šå„Workerç‹¬ç«‹æ‰§è¡Œï¼Œæ— éœ€ç›¸äº’é€šä¿¡\n",
    "3. **ç»“æœè¿”å›**ï¼šç›´æ¥ä»Workerè¿”å›ç»™å®¢æˆ·ç«¯\n",
    "\n",
    "**åœ¨Ray + vLLMæ¶æ„ä¸­ï¼š**\n",
    "\n",
    "1. **ä»»åŠ¡è°ƒåº¦**ï¼šé€šè¿‡Head Node\n",
    "2. **å¼ é‡å¹¶è¡Œé€šä¿¡**ï¼šWorkeré—´NCCLç›´è¿\n",
    "3. **æƒé‡åŒæ­¥**ï¼šWorkeré—´é«˜é€Ÿç½‘ç»œç›´è¿\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cef6fc",
   "metadata": {},
   "source": [
    "å½“å‰vllmç¯å¢ƒå®‰è£…ray\n",
    "\n",
    "pip install \"ray[default]\" -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07a0e69",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618141857154.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45796e2",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618142255790.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b414fa3",
   "metadata": {},
   "source": [
    "å®‰è£…å…¶ä»–ä¾èµ–ç¯å¢ƒ\n",
    "\n",
    "pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "\n",
    "pip install accelerate==0.29.3 -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a10034",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618143425202.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b7afe9",
   "metadata": {},
   "source": [
    "```bash\n",
    "# æŸ¥çœ‹ä¾èµ–ç‰ˆæœ¬\n",
    "\n",
    "python3 -c \"\n",
    "import torch\n",
    "print(f'PyTorch version: {torch.__version__}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "print(f'CUDA version: {torch.version.cuda}')\n",
    "print(f'GPU count: {torch.cuda.device_count()}')\n",
    "if torch.cuda.is_available():\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f'GPU {i}: {torch.cuda.get_device_name(i)}')\n",
    "\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a065ee7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618143411271.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "607c5e18",
   "metadata": {},
   "source": [
    "å½“å‰ç¯å¢ƒå®‰è£…vllm\n",
    "\n",
    "pip install vllm -i https://pypi.tuna.tsinghua.edu.cn/simple\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4263cda4",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618144336728.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a42e186",
   "metadata": {},
   "source": [
    "å®‰è£…å®Œæˆ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca5f832",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618144405318.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a81423",
   "metadata": {},
   "source": [
    "```bash  \n",
    "#å®‰è£…transformersï¼ˆä½¿ç”¨é•œåƒï¼‰\n",
    "pip install transformers \n",
    "pip install torchaudio==2.5.1 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "pip install vllm==0.6.6 transformers==4.45.2 tokenizers==0.20.3 -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "#å®‰è£…å…¶ä»–å¿…è¦ä¾èµ–\n",
    "pip install requests numpy -i https://pypi.tuna.tsinghua.edu.cn/simple\n",
    "python3 -c \"\n",
    "import sys\n",
    "print(f'Python version: {sys.version}')\n",
    "try:\n",
    "â€‹    import torch\n",
    "â€‹    print(f'âœ… PyTorch {torch.__version__} installed')\n",
    "â€‹    print(f'âœ… CUDA available: {torch.cuda.is_available()}')\n",
    "â€‹    if torch.cuda.is_available():\n",
    "â€‹        print(f'âœ… CUDA version: {torch.version.cuda}')\n",
    "except ImportError as e:\n",
    "â€‹    print(f'âŒ PyTorch import failed: {e}')\n",
    "try:\n",
    "â€‹    import ray\n",
    "â€‹    print(f'âœ… Ray {ray.__version__} installed')\n",
    "except ImportError as e:\n",
    "â€‹    print(f'âŒ Ray import failed: {e}')\n",
    "try:\n",
    "â€‹    import vllm\n",
    "â€‹    print(f'âœ… vLLM {vllm.__version__} installed')\n",
    "except ImportError as e:\n",
    "â€‹    print(f'âŒ vLLM import failed: {e}')\n",
    "\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98fe1bc",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618144625237.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e49fbba6",
   "metadata": {},
   "source": [
    "```bash  \n",
    "#åœ¨host0 (10.60.11.131) ä¸Šæ‰§è¡Œ\n",
    "cd /shared/financial_reward_model\n",
    "#å¯åŠ¨Rayå¤´èŠ‚ç‚¹\n",
    "ray start --head --port=6379 --dashboard-host=0.0.0.0 --dashboard-port=8265 --num-gpus=4\n",
    "#è®°å½•è¾“å‡ºçš„è¿æ¥ä¿¡æ¯ï¼Œç±»ä¼¼ï¼š\n",
    "#ray start --address='10.60.11.131:6379'\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ad1f3d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618153915877.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41592499",
   "metadata": {},
   "source": [
    "```bash  \n",
    "#åœ¨host1 (10.60.240.249) ä¸Šæ‰§è¡Œ\n",
    "#ä½¿ç”¨host0è¾“å‡ºçš„è¿æ¥å‘½ä»¤\n",
    "ray start --address='10.60.11.131:6379' --num-gpus=2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7456cd6c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618154118631.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc22d415",
   "metadata": {},
   "source": [
    "```bash  \n",
    "#åœ¨host0ä¸Šæ‰§è¡Œ\n",
    "ray status\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df59bec",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618154307616.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049071a2",
   "metadata": {},
   "source": [
    "```bash  \n",
    "#åœ¨ä¸¤å°æœºå™¨ä¸Šéƒ½æ‰§è¡Œï¼Œå¼€æ”¾PyTorchåˆ†å¸ƒå¼é€šä¿¡ç«¯å£\n",
    "sudo ufw allow 29500:29510/tcp\n",
    "sudo ufw allow 6379/tcp    # Rayç«¯å£\n",
    "sudo ufw allow 8265/tcp    # Ray Dashboardç«¯å£\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7989998",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618171540695.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90fee604",
   "metadata": {},
   "source": [
    "ä¸‹è½½Qwen2.5-14B-Instruct è¿›è¡Œæ¨¡å‹éªŒè¯ï¼Œæµ‹è¯•åˆ†å¸ƒå¼ç¯å¢ƒé€‚ç”¨æƒ…å†µ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e628a4",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618191103326.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32da9bd7",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m vllm.entrypoints.openai.api_server \\\n",
    "  --model /shared/Qwen2.5-14B-Instruct \\\n",
    "  --host 0.0.0.0 \\\n",
    "  --port 8000 \\\n",
    "  --tensor-parallel-size 2 \\\n",
    "  --pipeline-parallel-size 3 \\\n",
    "  --dtype bfloat16 \\\n",
    "  --max-model-len 2048 \\\n",
    "  --gpu-memory-utilization 0.85 \\\n",
    "  --disable-log-requests \\\n",
    "  --api-key financial-reward-model-key \\\n",
    "  --distributed-executor-backend ray\n",
    "```\n",
    "\n",
    "\n",
    "```bash\n",
    "\n",
    "## vLLMå‘½ä»¤å‚æ•°è¯¦è§£\n",
    "\n",
    "### æ¨¡å‹å’ŒæœåŠ¡å‚æ•°\n",
    "--model: æŒ‡å®šè¦åŠ è½½çš„æ¨¡å‹è·¯å¾„\n",
    "--host 0.0.0.0: å…è®¸æ‰€æœ‰IPè®¿é—®ï¼ˆä¸é™åˆ¶æ¥æºï¼‰\n",
    "--port 8000: APIæœåŠ¡ç›‘å¬çš„ç«¯å£å·\n",
    "--api-key: APIè®¿é—®çš„å®‰å…¨å¯†é’¥\n",
    "\n",
    "### æ¨¡å‹é…ç½®å‚æ•°\n",
    "--dtype bfloat16: ä½¿ç”¨åŠç²¾åº¦æµ®ç‚¹æ•°ï¼ŒèŠ‚çœæ˜¾å­˜ï¼Œç•¥å¾®é™ä½ç²¾åº¦\n",
    "--max-model-len 2048: æ¨¡å‹å¤„ç†çš„æœ€å¤§åºåˆ—é•¿åº¦\n",
    "--gpu-memory-utilization 0.85: ä½¿ç”¨85%çš„GPUæ˜¾å­˜ï¼Œç•™15%ä½œä¸ºç¼“å†²\n",
    "\n",
    "### å¹¶è¡Œé…ç½®å‚æ•°\n",
    "--tensor-parallel-size 2: å¼ é‡å¹¶è¡Œåº¦\n",
    "--pipeline-parallel-size 3: æµæ°´çº¿å¹¶è¡Œåº¦\n",
    "--distributed-executor-backend ray: ä½¿ç”¨Rayä½œä¸ºåˆ†å¸ƒå¼æ‰§è¡Œåç«¯\n",
    "\n",
    "### æ€§èƒ½ä¼˜åŒ–å‚æ•°\n",
    "--disable-log-requests: å…³é—­è¯·æ±‚æ—¥å¿—ï¼Œå‡å°‘IOå¼€é”€\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39998294",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618200053492.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7be9e5c1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618200028412.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26cbe338",
   "metadata": {},
   "source": [
    "## æ³¨æ„åŠ›å¤´æ•°çš„è¯¦ç»†è§£é‡Š\n",
    "\n",
    "### ä»€ä¹ˆæ˜¯æ³¨æ„åŠ›å¤´æ•°ï¼Ÿ\n",
    "æ³¨æ„åŠ›å¤´æ•°æ˜¯Transformeræ¶æ„ä¸­å¤šå¤´æ³¨æ„åŠ›æœºåˆ¶çš„æ ¸å¿ƒæ¦‚å¿µï¼š\n",
    "\n",
    "**å•å¤´æ³¨æ„åŠ›**ï¼šå°±åƒä¸€ä¸ªäººåªç”¨ä¸€ç§æ–¹å¼å…³æ³¨ä¿¡æ¯\n",
    "**å¤šå¤´æ³¨æ„åŠ›**ï¼šå°±åƒä¸€ä¸ªäººåŒæ—¶ç”¨å¤šç§ä¸åŒè§’åº¦å…³æ³¨åŒä¸€ä¸ªä¿¡æ¯\n",
    "\n",
    "æ¯”å¦‚Qwen2.5-14Bå¯èƒ½æœ‰32ä¸ªæ³¨æ„åŠ›å¤´ï¼Œæ„å‘³ç€ï¼š\n",
    "- æ¯ä¸€å±‚éƒ½æœ‰32ä¸ª\"æ³¨æ„åŠ›æ¢æµ‹å™¨\"\n",
    "- æ¯ä¸ªå¤´è´Ÿè´£æ•æ‰ä¸åŒç±»å‹çš„è¯­è¨€æ¨¡å¼\n",
    "- æœ‰äº›å¤´å…³æ³¨è¯­æ³•ï¼Œæœ‰äº›å…³æ³¨è¯­ä¹‰ï¼Œæœ‰äº›å…³æ³¨é•¿è·ç¦»ä¾èµ–\n",
    "\n",
    "### ä¸ºä»€ä¹ˆè¦èƒ½è¢«GPUæ•°æ•´é™¤ï¼Ÿ\n",
    "\n",
    "**å¼ é‡å¹¶è¡Œçš„å·¥ä½œæ–¹å¼**ï¼š\n",
    "- å‡è®¾æœ‰32ä¸ªæ³¨æ„åŠ›å¤´ï¼Œä½¿ç”¨4å¼ GPUåšå¼ é‡å¹¶è¡Œ\n",
    "- æ¯å¼ GPUåˆ†é… 32Ã·4=8ä¸ªæ³¨æ„åŠ›å¤´\n",
    "- GPU1å¤„ç†å¤´1-8ï¼ŒGPU2å¤„ç†å¤´9-16ï¼Œä»¥æ­¤ç±»æ¨\n",
    "- **å¦‚æœä¸èƒ½æ•´é™¤**ï¼šæ¯”å¦‚32ä¸ªå¤´åˆ†ç»™5å¼ GPUï¼Œå°±æ— æ³•å‡åŒ€åˆ†é…\n",
    "- ä¼šå¯¼è‡´æŸäº›GPUç©ºé—²ï¼ŒæŸäº›GPUè¿‡è½½ï¼Œç”šè‡³ç¨‹åºå´©æºƒ\n",
    "\n",
    "**æ•´é™¤çš„æ„ä¹‰**ï¼š\n",
    "- **è®¡ç®—å‡åŒ€**ï¼šæ¯å¼ GPUè´Ÿè½½ç›¸åŒï¼Œæ²¡æœ‰ç©ºé—²èµ„æº\n",
    "- **å†…å­˜å‡åŒ€**ï¼šæ¯å¼ GPUå­˜å‚¨ç›¸åŒå¤§å°çš„æ¨¡å‹éƒ¨åˆ†\n",
    "- **é€šä¿¡é«˜æ•ˆ**ï¼šæ•°æ®ä¼ è¾“æ¨¡å¼è§„æ•´ï¼Œå‡å°‘åŒæ­¥ç­‰å¾…æ—¶é—´\n",
    "\n",
    "## å¼ é‡å¹¶è¡Œ vs æµæ°´çº¿å¹¶è¡Œçš„æ·±åº¦è§£é‡Š\n",
    "\n",
    "### å¼ é‡å¹¶è¡Œï¼ˆæ¨ªå‘åˆ‡åˆ†ï¼‰\n",
    "**æ¯”å–»**ï¼šå°±åƒä¸€ä¸ªå¤§å·¥å‚çš„åŒä¸€æ¡ç”Ÿäº§çº¿ï¼Œè¢«å¤šä¸ªå·¥äººåŒæ—¶æ“ä½œ\n",
    "\n",
    "**å·¥ä½œæœºåˆ¶**ï¼š\n",
    "- æŠŠæ¨¡å‹çš„**åŒä¸€å±‚**çš„è®¡ç®—åˆ†å‰²ç»™å¤šä¸ªGPU\n",
    "- æ¯ä¸ªGPUè®¡ç®—è¿™ä¸€å±‚çš„ä¸€éƒ¨åˆ†ï¼Œç„¶åæ±‡æ€»ç»“æœ\n",
    "- éœ€è¦é¢‘ç¹çš„GPUé—´é€šä¿¡ï¼ˆAllReduceæ“ä½œï¼‰\n",
    "- é€‚åˆ**å•ä¸ªå±‚å¤ªå¤§**çš„æƒ…å†µ\n",
    "\n",
    "**ä¼˜ç¼ºç‚¹**ï¼š\n",
    "- âœ… å¯ä»¥å¤„ç†è¶…å¤§æ¨¡å‹å±‚\n",
    "- âœ… å»¶è¿Ÿè¾ƒä½ï¼ˆæ‰€æœ‰GPUåŒæ­¥å·¥ä½œï¼‰\n",
    "- âŒ é€šä¿¡å¼€é”€å¤§ï¼ˆæ¯å±‚éƒ½è¦åŒæ­¥ï¼‰\n",
    "- âŒ æ‰©å±•æ€§æœ‰é™ï¼ˆé€šä¿¡å¸¦å®½é™åˆ¶ï¼‰\n",
    "\n",
    "### æµæ°´çº¿å¹¶è¡Œï¼ˆçºµå‘åˆ‡åˆ†ï¼‰\n",
    "**æ¯”å–»**ï¼šå°±åƒæ±½è½¦ç”Ÿäº§æµæ°´çº¿ï¼Œæ¯ä¸ªå·¥äººè´Ÿè´£ä¸åŒçš„è£…é…æ­¥éª¤\n",
    "\n",
    "**å·¥ä½œæœºåˆ¶**ï¼š\n",
    "- æŠŠæ¨¡å‹çš„**ä¸åŒå±‚**åˆ†é…ç»™ä¸åŒGPU\n",
    "- æ•°æ®åƒä¼ é€å¸¦ä¸€æ ·ä¾æ¬¡é€šè¿‡å„ä¸ªGPU\n",
    "- GPUé—´é€šä¿¡è¾ƒå°‘ï¼ˆåªä¼ é€’æ¿€æ´»å€¼ï¼‰\n",
    "- é€‚åˆ**å±‚æ•°å¾ˆå¤š**çš„æƒ…å†µ\n",
    "\n",
    "**ä¼˜ç¼ºç‚¹**ï¼š\n",
    "- âœ… é€šä¿¡å¼€é”€å°\n",
    "- âœ… æ‰©å±•æ€§å¥½ï¼ˆå¯ä»¥ç”¨å¾ˆå¤šGPUï¼‰\n",
    "- âŒ æœ‰æµæ°´çº¿æ°”æ³¡ï¼ˆæŸäº›æ—¶åˆ»GPUç©ºé—²ï¼‰\n",
    "- âŒ æ‰¹æ¬¡å¤§å°éœ€è¦ä»”ç»†è°ƒä¼˜\n",
    "\n",
    "\n",
    "æ€»GPUæ•° = tensor-parallel-size Ã— pipeline-parallel-size = 2 Ã— 3 = 6å¼ GPU    \n",
    "\n",
    "GPUåˆ†å¸ƒï¼š    \n",
    "Stage 1: [GPU0, GPU1] - å¤„ç†æ¨¡å‹å‰1/3å±‚ï¼Œæ¯å±‚åœ¨2ä¸ªGPUé—´åšå¼ é‡å¹¶è¡Œ    \n",
    "Stage 2: [GPU2, GPU3] - å¤„ç†æ¨¡å‹ä¸­1/3å±‚ï¼Œæ¯å±‚åœ¨2ä¸ªGPUé—´åšå¼ é‡å¹¶è¡Œ     \n",
    "Stage 3: [GPU4, GPU5] - å¤„ç†æ¨¡å‹å1/3å±‚ï¼Œæ¯å±‚åœ¨2ä¸ªGPUé—´åšå¼ é‡å¹¶è¡Œ    \n",
    "\n",
    "## vLLMä¸Rayçš„åä½œæœºåˆ¶\n",
    "\n",
    "### Rayçš„ä½œç”¨\n",
    "**Rayæœ¬è´¨**ï¼šæ˜¯ä¸€ä¸ªåˆ†å¸ƒå¼è®¡ç®—æ¡†æ¶ï¼Œä¸“é—¨å¤„ç†å¤šæœºå¤šå¡çš„èµ„æºç®¡ç†å’Œä»»åŠ¡è°ƒåº¦\n",
    "\n",
    "**åœ¨è¿™é‡Œçš„èŒè´£**ï¼š\n",
    "1. **èµ„æºå‘ç°**ï¼šè‡ªåŠ¨æ£€æµ‹é›†ç¾¤ä¸­æœ‰å“ªäº›GPUå¯ç”¨\n",
    "2. **è¿›ç¨‹ç®¡ç†**ï¼šåœ¨ä¸åŒGPUä¸Šå¯åŠ¨vLLMçš„å·¥ä½œè¿›ç¨‹\n",
    "3. **é€šä¿¡åè°ƒ**ï¼šç®¡ç†GPUé—´çš„æ•°æ®ä¼ è¾“å’ŒåŒæ­¥\n",
    "4. **å®¹é”™å¤„ç†**ï¼šå¦‚æœæŸä¸ªGPUå¤±æ•ˆï¼ŒRayè´Ÿè´£é‡å¯å’Œæ¢å¤\n",
    "\n",
    "### vLLMä¸Rayçš„äº¤äº’æµç¨‹\n",
    "\n",
    "**å¯åŠ¨é˜¶æ®µ**ï¼š\n",
    "1. ä½ æ‰§è¡Œå‘½ä»¤åï¼ŒvLLMä¸»è¿›ç¨‹å¯åŠ¨\n",
    "2. vLLMæ£€æµ‹åˆ°`--distributed-executor-backend ray`å‚æ•°\n",
    "3. vLLMå‘Rayé›†ç¾¤æ³¨å†Œï¼Œç”³è¯·6å¼ GPUèµ„æº\n",
    "4. Rayæ ¹æ®é…ç½®ï¼Œåœ¨6å¼ GPUä¸Šåˆ†åˆ«å¯åŠ¨vLLMå·¥ä½œè¿›ç¨‹\n",
    "5. Rayå»ºç«‹GPUé—´çš„é€šä¿¡é€šé“ï¼ˆNCCLç­‰ï¼‰\n",
    "\n",
    "**è¿è¡Œé˜¶æ®µ**ï¼š\n",
    "1. ä¸»è¿›ç¨‹æ¥æ”¶APIè¯·æ±‚\n",
    "2. å°†è¯·æ±‚åˆ†å‘ç»™Rayç®¡ç†çš„GPUå·¥ä½œè¿›ç¨‹\n",
    "3. GPUè¿›ç¨‹æŒ‰ç…§å¼ é‡å¹¶è¡Œ+æµæ°´çº¿å¹¶è¡Œæ¨¡å¼åä½œè®¡ç®—\n",
    "4. Rayåè°ƒGPUé—´çš„æ•°æ®åŒæ­¥å’Œç»“æœæ±‡æ€»\n",
    "5. ä¸»è¿›ç¨‹å°†æœ€ç»ˆç»“æœè¿”å›ç»™APIè°ƒç”¨è€…\n",
    "\n",
    "**å…³é”®ç†è§£**ï¼š\n",
    "- **vLLMè´Ÿè´£æ¨¡å‹æ¨ç†é€»è¾‘**ï¼šæ€ä¹ˆåšæ³¨æ„åŠ›è®¡ç®—ã€æ€ä¹ˆç”Ÿæˆæ–‡æœ¬\n",
    "- **Rayè´Ÿè´£åŸºç¡€è®¾æ–½ç®¡ç†**ï¼šå“ªä¸ªGPUåšä»€ä¹ˆã€æ€ä¹ˆé€šä¿¡ã€æ€ä¹ˆå®¹é”™\n",
    "- **ä¸¤è€…åˆ†å·¥æ˜ç¡®**ï¼švLLMä¸“æ³¨AIç®—æ³•ï¼ŒRayä¸“æ³¨åˆ†å¸ƒå¼ç³»ç»Ÿ\n",
    "\n",
    "### ä¸ºä»€ä¹ˆéœ€è¦Rayï¼Ÿ\n",
    "å¦‚æœæ²¡æœ‰Rayï¼Œä½ éœ€è¦æ‰‹åŠ¨ï¼š\n",
    "- åœ¨æ¯å¼ GPUä¸Šå¯åŠ¨è¿›ç¨‹\n",
    "- é…ç½®GPUé—´çš„ç½‘ç»œé€šä¿¡\n",
    "- å¤„ç†è¿›ç¨‹é—´çš„åŒæ­¥å’Œå®¹é”™\n",
    "- ç®¡ç†å†…å­˜å’Œèµ„æºåˆ†é…\n",
    "\n",
    "RayæŠŠè¿™äº›å¤æ‚çš„åˆ†å¸ƒå¼ç³»ç»Ÿé—®é¢˜éƒ½è‡ªåŠ¨åŒ–å¤„ç†äº†ï¼Œè®©vLLMåªéœ€è¦ä¸“æ³¨äºAIæ¨ç†æœ¬èº«ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2ec41f",
   "metadata": {},
   "source": [
    "```bash\n",
    "curl -s http://10.60.11.131:8000/v1/models \\\n",
    "  -H \"Authorization: Bearer financial-reward-model-key\" | jq .\n",
    "\n",
    "# curl -sï¼šé™é»˜æ¨¡å¼å‘é€HTTPè¯·æ±‚ï¼Œä¸æ˜¾ç¤ºè¿›åº¦ä¿¡æ¯\n",
    "# http://10.60.11.131:8000/v1/modelsï¼šè¯·æ±‚çš„APIç«¯ç‚¹\n",
    "# 10.60.11.131:8000ï¼švLLMæœåŠ¡å™¨çš„IPåœ°å€å’Œç«¯å£\n",
    "# /v1/modelsï¼šOpenAIå…¼å®¹APIçš„æ ‡å‡†ç«¯ç‚¹ï¼Œç”¨äºè·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨\n",
    "# -H \"Authorization: Bearer financial-reward-model-key\"ï¼šæ·»åŠ è®¤è¯å¤´\n",
    "# ä½¿ç”¨ä½ åœ¨å¯åŠ¨vLLMæ—¶è®¾ç½®çš„APIå¯†é’¥è¿›è¡Œèº«ä»½éªŒè¯\n",
    "# | jq .ï¼šå°†JSONå“åº”æ ¼å¼åŒ–è¾“å‡ºï¼Œä¾¿äºé˜…è¯»\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "747c8f9c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618200222660.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94acbc5c",
   "metadata": {},
   "source": [
    "```bash\n",
    "curl -s http://10.60.11.131:8000/v1/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer financial-reward-model-key\" \\\n",
    "  -d '{\n",
    "â€‹    \"model\": \"/shared/Qwen2.5-14B-Instruct\",\n",
    "â€‹    \"prompt\": \"ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼š\",\n",
    "â€‹    \"max_tokens\": 50,\n",
    "â€‹    \"temperature\": 0.3\n",
    "  }' | jq .\n",
    "\n",
    "# curl -sï¼šåŒæ ·æ˜¯é™é»˜æ¨¡å¼\n",
    "# http://10.60.11.131:8000/v1/completionsï¼šæ–‡æœ¬è¡¥å…¨APIç«¯ç‚¹\n",
    "# -H \"Content-Type: application/json\"ï¼šæŒ‡å®šè¯·æ±‚ä½“ä¸ºJSONæ ¼å¼\n",
    "# -H \"Authorization: Bearer financial-reward-model-key\"ï¼šAPIè®¤è¯\n",
    "# -d '{...}'ï¼šPOSTè¯·æ±‚çš„JSONæ•°æ®ä½“\n",
    "# JSONå‚æ•°è¯¦è§£ï¼š\n",
    "# \"model\": \"/shared/Qwen2.5-14B-Instruct\"ï¼š\n",
    "# æŒ‡å®šä½¿ç”¨çš„æ¨¡å‹è·¯å¾„\n",
    "# å¿…é¡»ä¸vLLMåŠ è½½çš„æ¨¡å‹è·¯å¾„å®Œå…¨åŒ¹é…\n",
    "# \"prompt\": \"ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±ï¼š\"ï¼š\n",
    "# è¾“å…¥çš„æç¤ºæ–‡æœ¬\n",
    "# æ¨¡å‹å°†åŸºäºè¿™ä¸ªæç¤ºç”Ÿæˆåç»­å†…å®¹\n",
    "# \"max_tokens\": 50ï¼š\n",
    "# é™åˆ¶ç”Ÿæˆçš„æœ€å¤§tokenæ•°é‡\n",
    "# æ§åˆ¶å“åº”é•¿åº¦ï¼Œé¿å…ç”Ÿæˆè¿‡é•¿å†…å®¹\n",
    "# \"temperature\": 0.3ï¼š\n",
    "# æ§åˆ¶ç”Ÿæˆæ–‡æœ¬çš„éšæœºæ€§\n",
    "# èŒƒå›´é€šå¸¸æ˜¯0-2ï¼Œå€¼è¶Šå°è¶Šç¡®å®šæ€§ï¼Œè¶Šå¤§è¶Šæœ‰åˆ›é€ æ€§\n",
    "# 0.3æ˜¯è¾ƒä½çš„å€¼ï¼Œç”Ÿæˆå†…å®¹ä¼šæ¯”è¾ƒç¨³å®šå’Œä¸€è‡´\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1348f98",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618200313317.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a716bb86",
   "metadata": {},
   "source": [
    "```bash\n",
    "curl -s http://10.60.11.131:8000/v1/chat/completions \\\n",
    "  -H \"Content-Type: application/json\" \\\n",
    "  -H \"Authorization: Bearer financial-reward-model-key\" \\\n",
    "  -d '{\n",
    "    \"model\": \"/shared/Qwen2.5-14B-Instruct\",\n",
    "    \"messages\": [\n",
    "      {\"role\": \"user\", \"content\": \"1+1ç­‰äºå¤šå°‘ï¼Ÿ\"}\n",
    "    ],\n",
    "    \"max_tokens\": 30,\n",
    "    \"temperature\": 0.1\n",
    "  }' | jq .\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44376e68",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618200525767.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6797e83d",
   "metadata": {},
   "source": [
    "èµ„æºå ç”¨åˆ†å¸ƒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c36d698",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618200554176.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf1a2826",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618200611749.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6afbf5",
   "metadata": {},
   "source": [
    "vllm æ”¯æŒçš„æ¨¡å‹  https://vllm.hyper.ai/docs/models/supported_models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fc329b7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624204556063.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c9407a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624204528715.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fafca1",
   "metadata": {},
   "source": [
    "\n",
    "```bash \n",
    " #æŸ¥çœ‹æ¨¡å‹çš„é…ç½®æ–‡ä»¶\n",
    "cat /shared/QRM-Llama3.1-8B-v2/config.json | grep -E \"architectures|model_type\"\n",
    " #æˆ–è€…å®Œæ•´æŸ¥çœ‹é…ç½®\n",
    "head -20 /shared/QRM-Llama3.1-8B-v2/config.json\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d016d6af",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618200901680.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3b81b5",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624204205033.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ae4021",
   "metadata": {},
   "source": [
    "## ä¸¤ä¸ªæ¨¡å‹çš„æ ¸å¿ƒåŒºåˆ«\n",
    "\n",
    "### 1. **æ¶æ„ç±»å‹å·®å¼‚**\n",
    "\n",
    "**Skywork-Reward-Llama-3.1-8B**:\n",
    "```json\n",
    "\"architectures\": [\"LlamaForSequenceClassification\"]\n",
    "```\n",
    "\n",
    "**QRM-Llama3.1-8B-v2**:\n",
    "```json\n",
    "\"architectures\": [\"LlamaForRewardModelWithGating\"]\n",
    "```\n",
    "\n",
    "- **LlamaForSequenceClassification**: æ ‡å‡†çš„åºåˆ—åˆ†ç±»æ¶æ„ï¼Œé€šå¸¸ç”¨äºåŸºç¡€çš„å¥–åŠ±æ¨¡å‹\n",
    "- **LlamaForRewardModelWithGating**: å¸¦æœ‰é—¨æ§æœºåˆ¶çš„è‡ªå®šä¹‰å¥–åŠ±æ¨¡å‹æ¶æ„ï¼Œæ›´å¤æ‚\n",
    "\n",
    "é—¨æ§æœºåˆ¶æœ¬è´¨ä¸Šæ˜¯ä¸€ç§å­¦ä¹ å‹çš„æ³¨æ„åŠ›æœºåˆ¶ï¼Œè®©æ¨¡å‹èƒ½å¤Ÿï¼š   \n",
    "- è‡ªåŠ¨å­¦ä¼šä»€ä¹ˆæ—¶å€™å…³æ³¨ä»€ä¹ˆä¿¡æ¯    \n",
    "- æ ¹æ®ä¸Šä¸‹æ–‡åŠ¨æ€è°ƒæ•´å¤„ç†ç­–ç•¥    \n",
    "- æä¾›æ›´ç²¾ç»†å’Œçµæ´»çš„æ§åˆ¶èƒ½åŠ›   \n",
    "- åœ¨å¥–åŠ±æ¨¡å‹ä¸­ï¼Œé—¨æ§æœºåˆ¶å¯èƒ½å¸®åŠ©æ¨¡å‹æ›´å¥½åœ°ç†è§£å’Œè¯„ä¼°ä¸åŒç±»å‹å†…å®¹çš„è´¨é‡ï¼Œæä¾›æ›´å‡†ç¡®å’Œç»†è‡´çš„å¥–åŠ±ä¿¡å·ã€‚   \n",
    "\n",
    "### 2. **é—¨æ§æœºåˆ¶ç›¸å…³å‚æ•°**\n",
    "\n",
    "QRMæ¨¡å‹ç‹¬æœ‰çš„é—¨æ§é…ç½®ï¼š\n",
    "```json\n",
    "\"gating_hidden_dim\": 1024,      // é—¨æ§ç½‘ç»œéšè—å±‚ç»´åº¦\n",
    "\"gating_n_hidden\": 3,           // é—¨æ§ç½‘ç»œéšè—å±‚æ•°é‡\n",
    "\"gating_newtork\": true,         // å¯ç”¨é—¨æ§ç½‘ç»œï¼ˆæ³¨æ„è¿™é‡Œæœ‰æ‹¼å†™é”™è¯¯ï¼‰\n",
    "\"gating_temperature\": 5.0,      // é—¨æ§æ¸©åº¦å‚æ•°ï¼Œæ§åˆ¶é—¨æ§çš„æ•æ„Ÿåº¦\n",
    "```\n",
    "\n",
    "è¿™äº›å‚æ•°è¡¨æ˜QRMæ¨¡å‹ä½¿ç”¨äº†**é—¨æ§æœºåˆ¶**æ¥åŠ¨æ€è°ƒæ•´ä¸åŒè¾“å…¥çš„å¤„ç†æ–¹å¼ã€‚\n",
    "\n",
    "## auto_map çš„ä½œç”¨\n",
    "\n",
    "```json\n",
    "\"auto_map\": {\n",
    "  \"AutoModelForSequenceClassification\": \"modeling_custom.LlamaForRewardModelWithGating\"\n",
    "}\n",
    "```\n",
    "\n",
    "### **auto_mapçš„æ ¸å¿ƒåŠŸèƒ½**ï¼š\n",
    "\n",
    "1. **è‡ªå®šä¹‰æ¨¡å‹ç±»æ˜ å°„**ï¼š\n",
    "   - å‘Šè¯‰Transformersåº“å½“ä½¿ç”¨`AutoModelForSequenceClassification.from_pretrained()`æ—¶\n",
    "   - åº”è¯¥åŠ è½½`modeling_custom.LlamaForRewardModelWithGating`è¿™ä¸ªè‡ªå®šä¹‰ç±»\n",
    "   - è€Œä¸æ˜¯ä½¿ç”¨æ ‡å‡†çš„Llamaåºåˆ—åˆ†ç±»æ¨¡å‹\n",
    "\n",
    "2. **æ¨¡å—è·¯å¾„æŒ‡å®š**ï¼š\n",
    "   - `modeling_custom`ï¼šæŒ‡å‘è‡ªå®šä¹‰æ¨¡å‹å®ç°æ–‡ä»¶ï¼ˆé€šå¸¸æ˜¯`modeling_custom.py`ï¼‰\n",
    "   - `LlamaForRewardModelWithGating`ï¼šæ–‡ä»¶ä¸­çš„å…·ä½“ç±»å\n",
    "\n",
    "3. **å…¼å®¹æ€§ä¿è¯**ï¼š\n",
    "   - è®©è‡ªå®šä¹‰æ¶æ„èƒ½å¤Ÿä¸Transformersçš„AutoModelç³»ç»Ÿå…¼å®¹\n",
    "   - ç”¨æˆ·å¯ä»¥åƒä½¿ç”¨æ ‡å‡†æ¨¡å‹ä¸€æ ·ä½¿ç”¨è‡ªå®šä¹‰æ¨¡å‹\n",
    "\n",
    "### **å·¥ä½œæµç¨‹**ï¼š\n",
    "```python\n",
    "# å½“æ‰§è¡Œè¿™è¡Œä»£ç æ—¶\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"/shared/QRM-Llama3.1-8B-v2\")\n",
    "\n",
    "# Transformersä¼šï¼š\n",
    "# 1. è¯»å–config.jsonä¸­çš„auto_map\n",
    "# 2. å¯¼å…¥modeling_custom.pyæ–‡ä»¶\n",
    "# 3. å®ä¾‹åŒ–LlamaForRewardModelWithGatingç±»\n",
    "# 4. è€Œä¸æ˜¯æ ‡å‡†çš„LlamaForSequenceClassification\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8df093e",
   "metadata": {},
   "source": [
    "\n",
    "## config.json çš„å…³é”®ä½œç”¨\n",
    "\n",
    "### 1. **æ¨¡å‹æ¶æ„å®šä¹‰**\n",
    "- å®šä¹‰æ¨¡å‹çš„ç»“æ„å‚æ•°ï¼ˆå±‚æ•°ã€éšè—ç»´åº¦ç­‰ï¼‰\n",
    "- æŒ‡å®šæ¨¡å‹ç±»å‹å’Œè‡ªå®šä¹‰ç»„ä»¶\n",
    "- è®¾ç½®ç‰¹æ®Šå‚æ•°ï¼ˆå¦‚é—¨æ§æœºåˆ¶é…ç½®ï¼‰\n",
    "\n",
    "### 2. **åŠ è½½è¡Œä¸ºæ§åˆ¶**\n",
    "- å‘Šè¯‰æ¡†æ¶å¦‚ä½•æ­£ç¡®å®ä¾‹åŒ–æ¨¡å‹\n",
    "- æŒ‡å®šä½¿ç”¨å“ªä¸ªæ¨¡å‹ç±»\n",
    "- é…ç½®æ¨¡å‹çš„åˆå§‹åŒ–å‚æ•°\n",
    "\n",
    "### 3. **å…¼å®¹æ€§å’Œäº’æ“ä½œæ€§**\n",
    "- ç¡®ä¿æ¨¡å‹èƒ½åœ¨ä¸åŒç¯å¢ƒä¸­æ­£ç¡®åŠ è½½\n",
    "- æä¾›æ¨¡å‹çš„å…ƒæ•°æ®ä¿¡æ¯\n",
    "- æ”¯æŒæ¨¡å‹çš„åºåˆ—åŒ–å’Œååºåˆ—åŒ–\n",
    "\n",
    "### 4. **æ¨ç†å‚æ•°é…ç½®**\n",
    "- è®¾ç½®tokenizerç›¸å…³å‚æ•°ï¼ˆbos_token_id, eos_token_idï¼‰\n",
    "- é…ç½®æ³¨æ„åŠ›æœºåˆ¶å‚æ•°\n",
    "- å®šä¹‰æ ‡ç­¾æ˜ å°„å…³ç³»\n",
    "\n",
    "## å®é™…å½±å“\n",
    "\n",
    "1. **åŠ è½½æ–¹å¼**ï¼š\n",
    "   - Skyworkæ¨¡å‹å¯ä»¥ç›´æ¥ç”¨æ ‡å‡†æ–¹æ³•åŠ è½½\n",
    "   - QRMæ¨¡å‹éœ€è¦è‡ªå®šä¹‰çš„modeling_custom.pyæ–‡ä»¶æ”¯æŒ\n",
    "\n",
    "2. **åŠŸèƒ½å·®å¼‚**ï¼š\n",
    "   - QRMæ¨¡å‹çš„é—¨æ§æœºåˆ¶å¯èƒ½æä¾›æ›´ç²¾ç»†çš„å¥–åŠ±è¯„ä¼°\n",
    "   - Skyworkæ¨¡å‹ä½¿ç”¨æ ‡å‡†çš„åˆ†ç±»æ–¹æ³•\n",
    "\n",
    "3. **éƒ¨ç½²è¦æ±‚**ï¼š\n",
    "   - QRMæ¨¡å‹éƒ¨ç½²æ—¶å¿…é¡»åŒ…å«è‡ªå®šä¹‰æ¨¡å‹å®ç°æ–‡ä»¶\n",
    "   - Skyworkæ¨¡å‹å¯ä»¥ç›´æ¥ä½¿ç”¨æ ‡å‡†Transformersåº“\n",
    "\n",
    "è¿™äº›é…ç½®ç›´æ¥å½±å“æ¨¡å‹çš„åŠ è½½ã€åˆå§‹åŒ–å’Œæ¨ç†è¡Œä¸ºï¼Œæ˜¯æ¨¡å‹æ­£å¸¸è¿è¡Œçš„å…³é”®é…ç½®æ–‡ä»¶ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212264b4",
   "metadata": {},
   "source": [
    "æ ¡éªŒåŠ è½½QRM-Llama3.1-8B-v2 æ¨¡å‹æ— æ³•åŠ è½½"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ca9eeae",
   "metadata": {},
   "source": [
    "```bash  #ç®€åŒ–æµ‹è¯•\n",
    "python -c \"\n",
    "from vllm import LLM\n",
    "try:\n",
    "â€‹    llm = LLM(\n",
    "â€‹        model='/shared/QRM-Llama3.1-8B-v2',\n",
    "â€‹        task='reward',\n",
    "â€‹        trust_remote_code=True,\n",
    "â€‹        tensor_parallel_size=1\n",
    "â€‹    )\n",
    "â€‹    print('âœ… æ¨¡å‹åŠ è½½æˆåŠŸï¼')\n",
    "â€‹    \n",
    "â€‹   \n",
    "â€‹    outputs = llm.encode(['è¿™æ˜¯ä¸€ä¸ªå¥½çš„å›ç­”', 'è¿™æ˜¯ä¸€ä¸ªä¸å¥½çš„å›ç­”'])\n",
    "â€‹    print('âœ… å¥–åŠ±è¯„åˆ†æˆåŠŸï¼')\n",
    "â€‹    for i, output in enumerate(outputs):\n",
    "â€‹        print(f'æ–‡æœ¬ {i+1} çš„å¥–åŠ±åˆ†æ•°: {output}')\n",
    "â€‹        \n",
    "except Exception as e:\n",
    "â€‹    print('âŒ é”™è¯¯:', e)\n",
    "â€‹    import traceback\n",
    "â€‹    traceback.print_exc()\n",
    "\"\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0de834",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250618201218697.png\" width=100%></div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a398afc9",
   "metadata": {},
   "source": [
    "## åˆ†å¸ƒå¼ç¯å¢ƒéƒ¨ç½²æ–¹å¼äºŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c75cfa99",
   "metadata": {},
   "source": [
    "### **Ray+transformeræ•°æ®å¹¶è¡Œæ¨¡å¼**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c42aaf8",
   "metadata": {},
   "source": [
    "\n",
    "### Ray + Transformer vs Ray + vLLMçš„åŒºåˆ«\n",
    "\n",
    "#### è®¡ç®—æ¨¡å¼å·®å¼‚\n",
    "\n",
    "**Ray + Transformerï¼ˆæ•°æ®å¹¶è¡Œï¼‰ï¼š**\n",
    "- **æ¨¡å‹åˆ†å¸ƒ**ï¼šæ¯ä¸ªGPUæœ‰å®Œæ•´æ¨¡å‹å‰¯æœ¬\n",
    "- **è®¡ç®—æ–¹å¼**ï¼šGPUç‹¬ç«‹è®¡ç®—ï¼Œäº’ä¸å¹²æ‰°\n",
    "- **é€šä¿¡éœ€æ±‚**ï¼šå‡ ä¹æ— GPUé—´é€šä¿¡\n",
    "- **å†…å­˜ä½¿ç”¨**ï¼šæ¯å¼ GPUé‡å¤å­˜å‚¨ç›¸åŒæ¨¡å‹\n",
    "\n",
    "**Ray + vLLMï¼ˆå¼ é‡å¹¶è¡Œï¼‰ï¼š**\n",
    "- **æ¨¡å‹åˆ†å¸ƒ**ï¼šæ¨¡å‹æƒé‡æŒ‰å¼ é‡ç»´åº¦åˆ‡åˆ†åˆ°å¤šå¼ GPU\n",
    "- **è®¡ç®—æ–¹å¼**ï¼šå¤šå¼ GPUååŒè®¡ç®—å•ä¸ªè¯·æ±‚\n",
    "- **é€šä¿¡éœ€æ±‚**ï¼šé¢‘ç¹çš„GPUé—´æ•°æ®åŒæ­¥\n",
    "- **å†…å­˜ä½¿ç”¨**ï¼šæ¨¡å‹å‚æ•°åœ¨å¤šå¼ GPUé—´åˆ†æ•£å­˜å‚¨\n",
    "\n",
    "#### æ€§èƒ½ç‰¹å¾å¯¹æ¯”\n",
    "\n",
    "**å¹¶å‘å¤„ç†èƒ½åŠ›ï¼š**\n",
    "- æ•°æ®å¹¶è¡Œï¼šå¯åŒæ—¶å¤„ç†Nä¸ªè¯·æ±‚ï¼ˆN=å‰¯æœ¬æ•°ï¼‰\n",
    "- å¼ é‡å¹¶è¡Œï¼šé€šå¸¸åŒæ—¶å¤„ç†1ä¸ªè¯·æ±‚ï¼Œä½†å¯ä»¥å¤„ç†æ›´å¤§çš„æ¨¡å‹\n",
    "\n",
    "**å»¶è¿Ÿç‰¹å¾ï¼š**\n",
    "- æ•°æ®å¹¶è¡Œï¼šå•è¯·æ±‚å»¶è¿Ÿä½ï¼Œä½†å—å‰¯æœ¬å¯ç”¨æ€§å½±å“\n",
    "- å¼ é‡å¹¶è¡Œï¼šéœ€è¦GPUé—´åŒæ­¥ï¼Œå»¶è¿Ÿç›¸å¯¹è¾ƒé«˜\n",
    "\n",
    "**ååé‡ç‰¹å¾ï¼š**\n",
    "- æ•°æ®å¹¶è¡Œï¼šé€‚åˆå¤§é‡å°è¯·æ±‚çš„é«˜é¢‘åœºæ™¯\n",
    "- å¼ é‡å¹¶è¡Œï¼šé€‚åˆå°‘é‡å¤§è¯·æ±‚æˆ–éœ€è¦é«˜è®¡ç®—å¯†åº¦çš„åœºæ™¯\n",
    "\n",
    "### å‰¯æœ¬ä½¿ç”¨å¤šå¼ GPUçš„é—®é¢˜\n",
    "\n",
    "#### æŠ€æœ¯å¯è¡Œæ€§\n",
    "\n",
    "**å½“å‰æ¶æ„ä¸‹ä¸å¯è¡Œï¼š**\n",
    "- `AutoModelForSequenceClassification`ä¸æ”¯æŒåŸç”Ÿçš„å¤šGPUæ¨ç†\n",
    "- Ray Actorçš„`num_gpus=1`è®¾è®¡å°±æ˜¯å•GPUç»‘å®š\n",
    "- éœ€è¦æ‰‹åŠ¨å®ç°åˆ†å¸ƒå¼æ¨ç†é€»è¾‘\n",
    "\n",
    "**å¦‚æœè¦å®ç°å¤šGPUå‰¯æœ¬ï¼š**\n",
    "- éœ€è¦ä½¿ç”¨`torch.nn.DataParallel`åŒ…è£…æ¨¡å‹\n",
    "- æˆ–è€…ä½¿ç”¨æ”¯æŒå¼ é‡å¹¶è¡Œçš„æ¨ç†æ¡†æ¶\n",
    "- ä½†è¿™ä¼šè®©æ¶æ„å˜å¾—å¤æ‚ï¼Œå¤±å»æ•°æ®å¹¶è¡Œçš„ç®€æ´æ€§\n",
    "\n",
    "#### ä¸å¼ é‡å¹¶è¡Œçš„æœ¬è´¨åŒºåˆ«\n",
    "\n",
    "**å‰¯æœ¬å¤šGPUï¼ˆå¦‚æœå®ç°ï¼‰ï¼š**\n",
    "- æ¯ä¸ªå‰¯æœ¬å†…éƒ¨ä½¿ç”¨å¤šå¼ GPUåŠ é€Ÿå•ä¸ªè¯·æ±‚\n",
    "- å‰¯æœ¬é—´ä»ç„¶æ˜¯æ•°æ®å¹¶è¡Œå…³ç³»\n",
    "- æœ¬è´¨ä¸Šæ˜¯\"æ•°æ®å¹¶è¡Œ + æ¨¡å‹å¹¶è¡Œ\"çš„æ··åˆæ¨¡å¼\n",
    "\n",
    "**vLLMå¼ é‡å¹¶è¡Œï¼š**\n",
    "- æ•´ä¸ªé›†ç¾¤ä½œä¸ºä¸€ä¸ªå¤§çš„æ¨ç†å¼•æ“\n",
    "- æ‰€æœ‰GPUååŒå¤„ç†è¯·æ±‚\n",
    "- ä¸“é—¨ä¸ºå¤§æ¨¡å‹è®¾è®¡çš„åˆ†å¸ƒå¼æ¨ç†\n",
    "\n",
    "### æµå¼æ„å»ºçš„å·®å¼‚\n",
    "\n",
    "#### æ•°æ®å¹¶è¡Œæ¨¡å¼çš„å¤„ç†æ–¹å¼\n",
    "\n",
    "**æ‰¹å¤„ç†ç‰¹å¾ï¼š**\n",
    "- æ¯ä¸ªå‰¯æœ¬ç‹¬ç«‹å¤„ç†è‡ªå·±çš„è¯·æ±‚\n",
    "- å¯ä»¥å„è‡ªè¿›è¡Œå°æ‰¹é‡å¤„ç†\n",
    "- æ‰¹å¤§å°å—å•GPUå†…å­˜é™åˆ¶\n",
    "\n",
    "**å“åº”æ¨¡å¼ï¼š**\n",
    "- é€šå¸¸æ˜¯ä¸€æ¬¡æ€§è¿”å›å®Œæ•´ç»“æœ\n",
    "- é€‚åˆåˆ†ç±»ã€è¯„åˆ†ç­‰éç”Ÿæˆä»»åŠ¡\n",
    "- ä¸éœ€è¦æµå¼è¾“å‡º\n",
    "\n",
    "#### vLLMçš„æµå¼ä¼˜åŠ¿\n",
    "\n",
    "**è¿ç»­æ‰¹å¤„ç†ï¼š**\n",
    "- åŠ¨æ€è°ƒæ•´æ‰¹æ¬¡å¤§å°\n",
    "- å……åˆ†åˆ©ç”¨GPUè®¡ç®—èµ„æº\n",
    "- è‡ªåŠ¨ä¼˜åŒ–å†…å­˜ä½¿ç”¨\n",
    "\n",
    "**æµå¼ç”Ÿæˆï¼š**\n",
    "- æ”¯æŒå®æ—¶è¾“å‡ºtoken\n",
    "- é™ä½é¦–å­—å»¶è¿Ÿ\n",
    "- é€‚åˆæ–‡æœ¬ç”Ÿæˆä»»åŠ¡\n",
    "\n",
    "### é€‚ç”¨åœºæ™¯åˆ†æ\n",
    "\n",
    "#### Ray + Transformeré€‚ç”¨åœºæ™¯\n",
    "\n",
    "**ä¸šåŠ¡ç‰¹å¾ï¼š**\n",
    "1. **é«˜å¹¶å‘çŸ­è¯·æ±‚**\n",
    "   - åœ¨çº¿å†…å®¹å®¡æ ¸\n",
    "   - å®æ—¶æ¨èè¯„åˆ†\n",
    "   - å®¢æœæ„å›¾è¯†åˆ«\n",
    "\n",
    "2. **ä¸­å°å‹æ¨¡å‹**\n",
    "   - 7Bä»¥ä¸‹å‚æ•°çš„æ¨¡å‹\n",
    "   - å•GPUå¯ä»¥è£…ä¸‹çš„æ¨¡å‹\n",
    "   - BERTã€RoBERTaç­‰ç¼–ç å™¨æ¨¡å‹\n",
    "\n",
    "3. **ç‹¬ç«‹ä»»åŠ¡å¤„ç†**\n",
    "   - æ¯ä¸ªè¯·æ±‚ç›¸äº’ç‹¬ç«‹\n",
    "   - ä¸éœ€è¦ç»´æŒä¼šè¯çŠ¶æ€\n",
    "   - ç»“æœå¯ä»¥ç«‹å³è¿”å›\n",
    "\n",
    "**æŠ€æœ¯ä¼˜åŠ¿ï¼š**\n",
    "- éƒ¨ç½²ç®€å•ï¼Œå‡ ä¹ä¸éœ€è¦ä¿®æ”¹ç°æœ‰ä»£ç \n",
    "- æ•…éšœéš”ç¦»æ€§å¥½ï¼Œå•ä¸ªå‰¯æœ¬å´©æºƒä¸å½±å“å…¶ä»–å‰¯æœ¬\n",
    "- æ˜“äºæ°´å¹³æ‰©å±•ï¼Œå¯ä»¥éšæ—¶å¢å‡å‰¯æœ¬\n",
    "- è¿ç»´æˆæœ¬ä½ï¼Œç›‘æ§å’Œè°ƒè¯•ç›¸å¯¹å®¹æ˜“\n",
    "\n",
    "#### Ray + vLLMé€‚ç”¨åœºæ™¯\n",
    "\n",
    "**ä¸šåŠ¡ç‰¹å¾ï¼š**\n",
    "1. **å¤§æ¨¡å‹æ¨ç†**\n",
    "   - 70B+è¶…å¤§è¯­è¨€æ¨¡å‹\n",
    "   - å•GPUè£…ä¸ä¸‹çš„æ¨¡å‹\n",
    "   - éœ€è¦æé«˜è®¡ç®—å¯†åº¦çš„ä»»åŠ¡\n",
    "\n",
    "2. **ç”Ÿæˆå¼ä»»åŠ¡**\n",
    "   - å¯¹è¯ç³»ç»Ÿ\n",
    "   - æ–‡æœ¬ç”Ÿæˆ\n",
    "   - ä»£ç ç”Ÿæˆ\n",
    "   - åˆ›æ„å†™ä½œ\n",
    "\n",
    "3. **æ‰¹é‡å¤„ç†**\n",
    "   - ç¦»çº¿å†…å®¹ç”Ÿæˆ\n",
    "   - å¤§è§„æ¨¡æ•°æ®å¤„ç†\n",
    "   - éœ€è¦é«˜GPUåˆ©ç”¨ç‡çš„åœºæ™¯\n",
    "\n",
    "**æŠ€æœ¯ä¼˜åŠ¿ï¼š**\n",
    "- å†…å­˜æ•ˆç‡é«˜ï¼Œå¯ä»¥æ”¯æŒæ›´å¤§çš„æ¨¡å‹\n",
    "- GPUåˆ©ç”¨ç‡é«˜ï¼Œè®¡ç®—èµ„æºæµªè´¹å°‘\n",
    "- æ”¯æŒæµå¼è¾“å‡ºï¼Œç”¨æˆ·ä½“éªŒå¥½\n",
    "- å¯¹å¤§æ‰¹é‡å¤„ç†ä¼˜åŒ–ç¨‹åº¦é«˜\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1371979a",
   "metadata": {},
   "source": [
    "## Rayåœ¨ä¸¤ç§æ¶æ„ä¸­çš„è§’è‰²å·®å¼‚\n",
    "\n",
    "### Ray + Transformeræ¨¡å¼ä¸­çš„RayèŒè´£\n",
    "\n",
    "**Rayçš„æ ¸å¿ƒä½œç”¨ï¼šåˆ†å¸ƒå¼æœåŠ¡ç¼–æ’å™¨**\n",
    "\n",
    "1. **é›†ç¾¤ç®¡ç†å±‚é¢ï¼š**\n",
    "   - ç®¡ç†å¤šå°ç‰©ç†æœåŠ¡å™¨çš„èµ„æº\n",
    "   - åè°ƒä¸åŒèŠ‚ç‚¹é—´çš„ä»»åŠ¡åˆ†å‘\n",
    "   - æä¾›ç»Ÿä¸€çš„èµ„æºè§†å›¾ï¼ˆCPUã€GPUã€å†…å­˜ï¼‰\n",
    "\n",
    "2. **æœåŠ¡éƒ¨ç½²å±‚é¢ï¼š**\n",
    "   - å°†æ¯ä¸ªTransformerå®ä¾‹åŒ…è£…æˆRay Actor\n",
    "   - åœ¨æŒ‡å®šçš„GPUä¸Šå¯åŠ¨ç‹¬ç«‹çš„æ¨¡å‹å®ä¾‹\n",
    "   - ç®¡ç†å®ä¾‹çš„ç”Ÿå‘½å‘¨æœŸï¼ˆå¯åŠ¨ã€é‡å¯ã€å…³é—­ï¼‰\n",
    "\n",
    "3. **è¯·æ±‚è·¯ç”±å±‚é¢ï¼š**\n",
    "   - æ¥æ”¶HTTPè¯·æ±‚\n",
    "   - æ ¹æ®è´Ÿè½½å‡è¡¡ç­–ç•¥é€‰æ‹©ç©ºé—²çš„Actor\n",
    "   - å°†è¯·æ±‚è½¬å‘ç»™é€‰ä¸­çš„Actor\n",
    "   - æ”¶é›†ç»“æœå¹¶è¿”å›ç»™å®¢æˆ·ç«¯\n",
    "\n",
    "**å…³é”®ç‰¹ç‚¹ï¼šRayä¸å‚ä¸æ¨¡å‹å†…éƒ¨çš„è®¡ç®—**\n",
    "- Transformeråœ¨å„è‡ªçš„GPUä¸Šå®Œå…¨ç‹¬ç«‹è¿è¡Œ\n",
    "- Rayåªè´Ÿè´£\"è°æ¥å¤„ç†è¿™ä¸ªè¯·æ±‚\"ï¼Œä¸ç®¡\"æ€ä¹ˆå¤„ç†\"\n",
    "- ç±»ä¼¼äºKubernetes + Dockerçš„å…³ç³»\n",
    "\n",
    "### Ray + vLLMæ¨¡å¼ä¸­çš„RayèŒè´£\n",
    "\n",
    "**Rayçš„æ ¸å¿ƒä½œç”¨ï¼šåˆ†å¸ƒå¼è®¡ç®—åŸºç¡€è®¾æ–½**\n",
    "\n",
    "1. **é›†ç¾¤ç®¡ç†å±‚é¢ï¼š**\n",
    "   - åŒæ ·ç®¡ç†ç‰©ç†èŠ‚ç‚¹å’Œèµ„æº\n",
    "   - ä½†éœ€è¦æ›´ç»†ç²’åº¦çš„GPUèµ„æºç®¡ç†\n",
    "   - æ”¯æŒGPUé—´çš„é«˜é€Ÿé€šä¿¡æ‹“æ‰‘\n",
    "\n",
    "2. **åˆ†å¸ƒå¼è®¡ç®—æ”¯æŒï¼š**\n",
    "   - æä¾›åˆ†å¸ƒå¼é€šä¿¡åŸè¯­ï¼ˆAll-Reduceã€All-Gatherï¼‰\n",
    "   - ç®¡ç†è·¨GPUçš„è®¡ç®—ä»»åŠ¡è°ƒåº¦\n",
    "   - åè°ƒå¼ é‡åœ¨ä¸åŒGPUé—´çš„ä¼ è¾“\n",
    "\n",
    "3. **ä¸vLLMçš„åä½œå…³ç³»ï¼š**\n",
    "   - **vLLMè´Ÿè´£**ï¼šæ¨¡å‹åˆ†ç‰‡ç­–ç•¥ã€å¼ é‡å¹¶è¡Œé€»è¾‘ã€GPUé—´é€šä¿¡åè®®\n",
    "   - **Rayè´Ÿè´£**ï¼šåº•å±‚çš„è¿›ç¨‹ç®¡ç†ã€ç½‘ç»œé€šä¿¡ã€èµ„æºåˆ†é…\n",
    "\n",
    "**å…³é”®ç‰¹ç‚¹ï¼šRayå‚ä¸è®¡ç®—çš„åŸºç¡€è®¾æ–½å±‚é¢**\n",
    "- vLLMå†³å®š\"å¦‚ä½•åˆ†ç‰‡\"å’Œ\"å¦‚ä½•è®¡ç®—\"\n",
    "- Rayæä¾›\"åœ¨å“ªé‡Œè®¡ç®—\"å’Œ\"å¦‚ä½•é€šä¿¡\"çš„åŸºç¡€è®¾æ–½\n",
    "- ç±»ä¼¼äºCUDA Runtime + NCCLçš„å…³ç³»\n",
    "\n",
    "### å…·ä½“çš„èŒè´£åˆ†å·¥è¯¦è§£\n",
    "\n",
    "#### Ray + Transformerçš„åˆ†å·¥\n",
    "\n",
    "```\n",
    "å®¢æˆ·ç«¯è¯·æ±‚ \n",
    "    â†“\n",
    "Ray Serve (HTTPæœåŠ¡å™¨)\n",
    "    â†“\n",
    "Rayè´Ÿè½½å‡è¡¡å™¨ (é€‰æ‹©å‰¯æœ¬)\n",
    "    â†“\n",
    "Ray Actorè°ƒåº¦å™¨ (æ‰¾åˆ°å¯¹åº”GPUèŠ‚ç‚¹)\n",
    "    â†“\n",
    "ç‹¬ç«‹çš„Transformerå®ä¾‹ (åœ¨æŒ‡å®šGPUä¸Šè¿è¡Œ)\n",
    "    â†“\n",
    "è¿”å›ç»“æœç»™Ray Serve\n",
    "    â†“\n",
    "è¿”å›ç»™å®¢æˆ·ç«¯\n",
    "```\n",
    "\n",
    "**Rayçš„èŒè´£è¾¹ç•Œï¼š**\n",
    "- âœ… ç®¡ç†6å°æœåŠ¡å™¨ä¸Šçš„GPUèµ„æº\n",
    "- âœ… å†³å®šè¯·æ±‚å‘é€åˆ°å“ªä¸ªGPU\n",
    "- âœ… ç›‘æ§æ¯ä¸ªTransformerå®ä¾‹çš„å¥åº·çŠ¶æ€\n",
    "- âœ… æä¾›æ•…éšœè½¬ç§»å’Œé‡å¯æœºåˆ¶\n",
    "- âŒ ä¸å‚ä¸æ¨¡å‹çš„å‰å‘æ¨ç†è®¡ç®—\n",
    "- âŒ ä¸å¤„ç†Transformerçš„å†…éƒ¨é€»è¾‘\n",
    "\n",
    "#### Ray + vLLMçš„åˆ†å·¥\n",
    "\n",
    "```\n",
    "å®¢æˆ·ç«¯è¯·æ±‚\n",
    "    â†“\n",
    "Ray Serve (HTTPæœåŠ¡å™¨)\n",
    "    â†“\n",
    "vLLMåˆ†å¸ƒå¼å¼•æ“ (å†³å®šå¦‚ä½•åˆ†ç‰‡å¤„ç†)\n",
    "    â†“\n",
    "Rayåˆ†å¸ƒå¼è®¡ç®—å±‚ (æä¾›è·¨GPUé€šä¿¡)\n",
    "    â†“\n",
    "å¤šä¸ªGPUååŒè®¡ç®— (å¼ é‡å¹¶è¡Œ)\n",
    "    â†“\n",
    "vLLMç»“æœèšåˆ\n",
    "    â†“\n",
    "è¿”å›ç»™å®¢æˆ·ç«¯\n",
    "```\n",
    "\n",
    "**Rayçš„èŒè´£è¾¹ç•Œï¼š**\n",
    "- âœ… ç®¡ç†åˆ†å¸ƒå¼é›†ç¾¤èµ„æº\n",
    "- âœ… æä¾›GPUé—´çš„é€šä¿¡åŸºç¡€è®¾æ–½\n",
    "- âœ… æ”¯æŒvLLMçš„åˆ†å¸ƒå¼è®¡ç®—éœ€æ±‚\n",
    "- âœ… ç®¡ç†åˆ†å¸ƒå¼ä»»åŠ¡çš„è°ƒåº¦\n",
    "- âŒ ä¸å†³å®šæ¨¡å‹å¦‚ä½•åˆ†ç‰‡\n",
    "- âŒ ä¸å‚ä¸å¼ é‡å¹¶è¡Œçš„å…·ä½“ç®—æ³•\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4495bcca",
   "metadata": {},
   "source": [
    "# 5. æ¨¡å‹æ ¡éªŒ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3e02a1f",
   "metadata": {},
   "source": [
    "## æ‰§è¡Œä»£ç "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9faaa29e",
   "metadata": {},
   "source": [
    "å¯åŠ¨ä»£ç ï¼šray_reward_service.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8180e9",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import signal\n",
    "import argparse\n",
    "import logging\n",
    "\n",
    "import ray\n",
    "from ray import serve\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, LlamaTokenizer\n",
    "\n",
    "# é…ç½®æ—¥å¿—ç³»ç»Ÿï¼Œè®¾ç½®æ—¥å¿—çº§åˆ«å’Œæ ¼å¼\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# ä½¿ç”¨Ray Serveè£…é¥°å™¨å®šä¹‰æœåŠ¡éƒ¨ç½²\n",
    "# è¿™ä¸ªè£…é¥°å™¨å‘Šè¯‰Rayå¦‚ä½•éƒ¨ç½²è¿™ä¸ªæœåŠ¡ç±»\n",
    "# num_gpus=1: æ¯ä¸ªæœåŠ¡å®ä¾‹ä½¿ç”¨1ä¸ªGPU\n",
    "# num_cpus=2: æ¯ä¸ªæœåŠ¡å®ä¾‹ä½¿ç”¨2ä¸ªCPUæ ¸å¿ƒ\n",
    "@serve.deployment(\n",
    "    ray_actor_options={\n",
    "        \"num_gpus\": 1,\n",
    "        \"num_cpus\": 2\n",
    "    }\n",
    ")\n",
    "class RewardService:\n",
    "    \"\"\"\n",
    "    å¥–åŠ±æ¨¡å‹æ¨ç†æœåŠ¡ç±»\n",
    "    \n",
    "    è¿™ä¸ªç±»æ˜¯æ•´ä¸ªæ¨ç†æœåŠ¡çš„æ ¸å¿ƒï¼Œè´Ÿè´£ï¼š\n",
    "    1. åŠ è½½å¥–åŠ±æ¨¡å‹å’Œtokenizer\n",
    "    2. å¤„ç†æ¨ç†è¯·æ±‚\n",
    "    3. è¿”å›chosenå’Œrejectedå›ç­”çš„åˆ†æ•°\n",
    "    \n",
    "    åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "    - æ¥æ”¶HTTPè¯·æ±‚ï¼ŒåŒ…å«questionã€chosenã€rejectedä¸‰ä¸ªå­—æ®µ\n",
    "    - ä½¿ç”¨è®­ç»ƒå¥½çš„å¥–åŠ±æ¨¡å‹å¯¹chosenå’Œrejectedå›ç­”è¿›è¡Œè¯„åˆ†\n",
    "    - è¿”å›åˆ†æ•°ç»“æœï¼Œç”¨äºåˆ¤æ–­å“ªä¸ªå›ç­”æ›´å¥½\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_path: str):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–å¥–åŠ±æ¨¡å‹æœåŠ¡\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•åœ¨æœåŠ¡å¯åŠ¨æ—¶è¢«è°ƒç”¨ï¼Œè´Ÿè´£åŠ è½½æ¨¡å‹å’Œtokenizer\n",
    "        \n",
    "        å‚æ•°:\n",
    "            model_path: è®­ç»ƒå¥½çš„å¥–åŠ±æ¨¡å‹çš„è·¯å¾„\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - è¿™æ˜¯æœåŠ¡çš„åˆå§‹åŒ–å…¥å£ï¼Œåªåœ¨æœåŠ¡å¯åŠ¨æ—¶æ‰§è¡Œä¸€æ¬¡\n",
    "        - åŠ è½½çš„æ¨¡å‹å’Œtokenizerä¼šè¢«åç»­çš„æ¨ç†è¯·æ±‚é‡å¤ä½¿ç”¨\n",
    "        \"\"\"\n",
    "        self.model_path = model_path\n",
    "        # æ£€æµ‹æ˜¯å¦æœ‰å¯ç”¨çš„GPUï¼Œä¼˜å…ˆä½¿ç”¨GPUè¿›è¡Œæ¨ç†\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        \n",
    "        # ç¬¬ä¸€æ­¥ï¼šåŠ è½½tokenizerï¼ˆæ–‡æœ¬åˆ†è¯å™¨ï¼‰\n",
    "        # tokenizerçš„ä½œç”¨æ˜¯å°†æ–‡æœ¬è½¬æ¢ä¸ºæ¨¡å‹å¯ä»¥ç†è§£çš„æ•°å­—åºåˆ—\n",
    "        try:\n",
    "            logger.info(\"å¼€å§‹åŠ è½½tokenizer...\")\n",
    "            logger.info(f\"æ¨¡å‹è·¯å¾„: {model_path}\")\n",
    "            \n",
    "            # æ£€æŸ¥æ¨¡å‹è·¯å¾„æ˜¯å¦å­˜åœ¨\n",
    "            if not os.path.exists(model_path):\n",
    "                raise FileNotFoundError(f\"æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {model_path}\")\n",
    "            \n",
    "            # æ£€æŸ¥tokenizerç›¸å…³æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "            # è¿™äº›æ–‡ä»¶æ˜¯tokenizeræ­£å¸¸å·¥ä½œæ‰€å¿…éœ€çš„\n",
    "            tokenizer_files = [\n",
    "                \"tokenizer.json\",          # ä¸»è¦çš„tokenizeré…ç½®\n",
    "                \"tokenizer_config.json\",   # tokenizeré…ç½®æ–‡ä»¶\n",
    "                \"vocab.json\",              # è¯æ±‡è¡¨æ–‡ä»¶\n",
    "                \"merges.txt\",              # BPEåˆå¹¶è§„åˆ™ï¼ˆå¦‚æœä½¿ç”¨BPEï¼‰\n",
    "                \"special_tokens_map.json\"  # ç‰¹æ®Štokenæ˜ å°„\n",
    "            ]\n",
    "            \n",
    "            existing_files = []\n",
    "            for file in tokenizer_files:\n",
    "                file_path = os.path.join(model_path, file)\n",
    "                if os.path.exists(file_path):\n",
    "                    existing_files.append(file)\n",
    "            \n",
    "            logger.info(f\"æ‰¾åˆ°çš„tokenizeræ–‡ä»¶: {existing_files}\")\n",
    "            \n",
    "            # å°è¯•å¤šç§æ–¹å¼åŠ è½½tokenizer\n",
    "            # è¿™æ˜¯ä¸ºäº†æé«˜å…¼å®¹æ€§ï¼Œå¦‚æœä¸€ç§æ–¹æ³•å¤±è´¥ï¼Œä¼šå°è¯•å…¶ä»–æ–¹æ³•\n",
    "            tokenizer = None\n",
    "            \n",
    "            # æ–¹æ³•1: ä½¿ç”¨AutoTokenizerè‡ªåŠ¨è¯†åˆ«tokenizerç±»å‹\n",
    "            try:\n",
    "                logger.info(\"å°è¯•ä½¿ç”¨AutoTokenizeråŠ è½½...\")\n",
    "                tokenizer = AutoTokenizer.from_pretrained(\n",
    "                    model_path, \n",
    "                    use_fast=False,        # ä¸ä½¿ç”¨å¿«é€Ÿtokenizerï¼Œæé«˜å…¼å®¹æ€§\n",
    "                    local_files_only=True, # åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶ï¼Œä¸ä»ç½‘ç»œä¸‹è½½\n",
    "                    trust_remote_code=False # ä¸ä¿¡ä»»è¿œç¨‹ä»£ç ï¼Œæé«˜å®‰å…¨æ€§\n",
    "                )\n",
    "                logger.info(f\"AutoTokenizeråŠ è½½æˆåŠŸï¼Œç±»å‹: {type(tokenizer)}\")\n",
    "                \n",
    "                # éªŒè¯tokenizerä¸æ˜¯å¸ƒå°”å€¼\n",
    "                # è¿™æ˜¯ä¸ºäº†é˜²æ­¢æŸäº›å¼‚å¸¸æƒ…å†µä¸‹tokenizerè¢«é”™è¯¯åœ°è®¾ç½®ä¸ºå¸ƒå°”å€¼\n",
    "                if isinstance(tokenizer, bool):\n",
    "                    logger.error(f\"AutoTokenizerè¿”å›äº†å¸ƒå°”å€¼: {tokenizer}\")\n",
    "                    tokenizer = None\n",
    "                    \n",
    "            except Exception as e:\n",
    "                logger.warning(f\"AutoTokenizeråŠ è½½å¤±è´¥: {e}\")\n",
    "                tokenizer = None\n",
    "            \n",
    "            # æ–¹æ³•2: å¦‚æœAutoTokenizerå¤±è´¥ï¼Œå°è¯•ç›´æ¥ä½¿ç”¨LlamaTokenizer\n",
    "            if tokenizer is None:\n",
    "                try:\n",
    "                    logger.info(\"å°è¯•ä½¿ç”¨LlamaTokenizeråŠ è½½...\")\n",
    "                    tokenizer = LlamaTokenizer.from_pretrained(\n",
    "                        model_path,\n",
    "                        use_fast=False,\n",
    "                        local_files_only=True,\n",
    "                        trust_remote_code=False\n",
    "                    )\n",
    "                    logger.info(f\"LlamaTokenizeråŠ è½½æˆåŠŸï¼Œç±»å‹: {type(tokenizer)}\")\n",
    "                    \n",
    "                    if isinstance(tokenizer, bool):\n",
    "                        logger.error(f\"LlamaTokenizerè¿”å›äº†å¸ƒå°”å€¼: {tokenizer}\")\n",
    "                        tokenizer = None\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"LlamaTokenizeråŠ è½½å¤±è´¥: {e}\")\n",
    "                    tokenizer = None\n",
    "            \n",
    "            # æ–¹æ³•3: å°è¯•ä»åŸºç¡€æ¨¡å‹è·¯å¾„åŠ è½½tokenizer\n",
    "            # è¿™æ˜¯æœ€åçš„å¤‡é€‰æ–¹æ¡ˆï¼Œä½¿ç”¨åŸå§‹çš„åŸºç¡€æ¨¡å‹çš„tokenizer\n",
    "            if tokenizer is None:\n",
    "                try:\n",
    "                    logger.info(\"å°è¯•ä»åŸºç¡€æ¨¡å‹è·¯å¾„åŠ è½½tokenizer...\")\n",
    "                    base_model_path = \"/shared/Skywork-Reward-Llama-3.1-8B\"\n",
    "                    if os.path.exists(base_model_path):\n",
    "                        tokenizer = AutoTokenizer.from_pretrained(\n",
    "                            base_model_path,\n",
    "                            use_fast=False,\n",
    "                            local_files_only=True,\n",
    "                            trust_remote_code=False\n",
    "                        )\n",
    "                        logger.info(f\"ä»åŸºç¡€æ¨¡å‹åŠ è½½tokenizeræˆåŠŸï¼Œç±»å‹: {type(tokenizer)}\")\n",
    "                        \n",
    "                        if isinstance(tokenizer, bool):\n",
    "                            logger.error(f\"ä»åŸºç¡€æ¨¡å‹åŠ è½½çš„tokenizeræ˜¯å¸ƒå°”å€¼: {tokenizer}\")\n",
    "                            tokenizer = None\n",
    "                    else:\n",
    "                        logger.warning(f\"åŸºç¡€æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: {base_model_path}\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    logger.warning(f\"ä»åŸºç¡€æ¨¡å‹åŠ è½½tokenizerå¤±è´¥: {e}\")\n",
    "                    tokenizer = None\n",
    "            \n",
    "            # å¦‚æœæ‰€æœ‰æ–¹æ³•éƒ½å¤±è´¥äº†ï¼ŒæŠ›å‡ºé”™è¯¯\n",
    "            if tokenizer is None:\n",
    "                raise RuntimeError(\"æ‰€æœ‰tokenizeråŠ è½½æ–¹æ³•éƒ½å¤±è´¥äº†\")\n",
    "            \n",
    "            # éªŒè¯tokenizerå¯¹è±¡æ˜¯å¦æ­£å¸¸\n",
    "            logger.info(f\"Tokenizeræœ€ç»ˆç±»å‹: {type(tokenizer)}\")\n",
    "            logger.info(f\"Tokenizeræ˜¯å¦å¯è°ƒç”¨: {callable(tokenizer)}\")\n",
    "            \n",
    "            # æ£€æŸ¥tokenizeræ˜¯å¦æœ‰pad_tokenå±æ€§\n",
    "            # pad_tokenç”¨äºå°†ä¸åŒé•¿åº¦çš„æ–‡æœ¬åºåˆ—å¡«å……åˆ°ç›¸åŒé•¿åº¦\n",
    "            if not hasattr(tokenizer, 'pad_token'):\n",
    "                raise RuntimeError(f\"Tokenizerå¯¹è±¡æ²¡æœ‰pad_tokenå±æ€§: {type(tokenizer)}\")\n",
    "            \n",
    "            # è®¾ç½®pad_token\n",
    "            # pad_tokenæ˜¯ç”¨äºå¡«å……åºåˆ—çš„ç‰¹æ®Štokenï¼Œç¡®ä¿æ‰¹æ¬¡ä¸­æ‰€æœ‰åºåˆ—é•¿åº¦ç›¸åŒ\n",
    "            logger.info(f\"å½“å‰pad_token: {getattr(tokenizer, 'pad_token', 'None')}\")\n",
    "            \n",
    "            if tokenizer.pad_token is None:\n",
    "                # å¦‚æœæ²¡æœ‰pad_tokenï¼Œå°è¯•ä½¿ç”¨eos_tokenä½œä¸ºpad_token\n",
    "                if hasattr(tokenizer, 'eos_token') and tokenizer.eos_token is not None:\n",
    "                    tokenizer.pad_token = tokenizer.eos_token\n",
    "                    logger.info(f\"è®¾ç½®pad_tokenä¸ºeos_token: {tokenizer.pad_token}\")\n",
    "                else:\n",
    "                    # å¦‚æœæ²¡æœ‰eos_tokenï¼Œæ‰‹åŠ¨æ·»åŠ ä¸€ä¸ªpad_token\n",
    "                    tokenizer.add_special_tokens({'pad_token': '<pad>'})\n",
    "                    logger.info(f\"æ·»åŠ æ–°çš„pad_token: {tokenizer.pad_token}\")\n",
    "            \n",
    "            logger.info(f\"æœ€ç»ˆpad_token: {tokenizer.pad_token}\")\n",
    "            \n",
    "            # åªæœ‰åœ¨ä¸€åˆ‡æ­£å¸¸çš„æƒ…å†µä¸‹æ‰å°†tokenizerèµ‹å€¼ç»™å®ä¾‹å˜é‡\n",
    "            self.tokenizer = tokenizer\n",
    "            logger.info(\"Tokenizeråˆå§‹åŒ–å®Œæˆ\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"tokenizeråŠ è½½å¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            logger.error(f\"é”™è¯¯å †æ ˆ: {traceback.format_exc()}\")\n",
    "            raise RuntimeError(f\"TokenizeråŠ è½½å¤±è´¥: {e}\")\n",
    "        \n",
    "        # ç¬¬äºŒæ­¥ï¼šåŠ è½½å¥–åŠ±æ¨¡å‹\n",
    "        # å¥–åŠ±æ¨¡å‹æ˜¯ä¸€ä¸ªåˆ†ç±»æ¨¡å‹ï¼Œç”¨äºå¯¹æ–‡æœ¬å›ç­”è¿›è¡Œè¯„åˆ†\n",
    "        try:\n",
    "            logger.info(\"å¼€å§‹åŠ è½½æ¨¡å‹...\")\n",
    "            self.model = AutoModelForSequenceClassification.from_pretrained(\n",
    "                model_path,\n",
    "                torch_dtype=torch.bfloat16,  # ä½¿ç”¨bfloat16ç²¾åº¦ï¼ŒèŠ‚çœæ˜¾å­˜\n",
    "                device_map=\"auto\",           # è‡ªåŠ¨åˆ†é…è®¾å¤‡\n",
    "                trust_remote_code=False,     # ä¸ä¿¡ä»»è¿œç¨‹ä»£ç \n",
    "                local_files_only=True        # åªä½¿ç”¨æœ¬åœ°æ–‡ä»¶\n",
    "            )\n",
    "            # è®¾ç½®æ¨¡å‹ä¸ºè¯„ä¼°æ¨¡å¼ï¼Œå…³é—­dropoutç­‰è®­ç»ƒæ—¶çš„éšæœºæ€§\n",
    "            self.model.eval()\n",
    "            logger.info(f\"æ¨¡å‹åŠ è½½å®Œæˆï¼Œè®¾å¤‡: {self.device}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "            import traceback\n",
    "            logger.error(f\"é”™è¯¯å †æ ˆ: {traceback.format_exc()}\")\n",
    "            raise RuntimeError(f\"æ¨¡å‹åŠ è½½å¤±è´¥: {e}\")\n",
    "    \n",
    "    def format_conversation(self, question: str, answer: str) -> str:\n",
    "        \"\"\"\n",
    "        æ ¼å¼åŒ–å¯¹è¯æ–‡æœ¬\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•å°†ç”¨æˆ·é—®é¢˜å’ŒåŠ©æ‰‹å›ç­”æ ¼å¼åŒ–ä¸ºLLaMA-3çš„å¯¹è¯æ ¼å¼\n",
    "        \n",
    "        å‚æ•°:\n",
    "            question: ç”¨æˆ·æå‡ºçš„é—®é¢˜\n",
    "            answer: åŠ©æ‰‹çš„å›ç­”\n",
    "        \n",
    "        è¿”å›:\n",
    "            æ ¼å¼åŒ–åçš„å¯¹è¯æ–‡æœ¬\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - å°†è¾“å…¥çš„é—®é¢˜å’Œå›ç­”è½¬æ¢ä¸ºæ¨¡å‹è®­ç»ƒæ—¶ä½¿ç”¨çš„æ ¼å¼\n",
    "        - ç¡®ä¿æ¨ç†æ—¶çš„æ ¼å¼ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼Œè¿™å¯¹æ¨¡å‹æ€§èƒ½å¾ˆé‡è¦\n",
    "        \"\"\"\n",
    "        return f\"<|begin_of_text|><|start_header_id|>user<|end_header_id|>\\n\\n{question}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n{answer}<|eot_id|>\"\n",
    "    \n",
    "    async def __call__(self, request):\n",
    "        \"\"\"\n",
    "        å¤„ç†æ¨ç†è¯·æ±‚çš„ä¸»è¦æ–¹æ³•\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•æ˜¯æ•´ä¸ªæœåŠ¡çš„æ ¸å¿ƒï¼Œå¤„ç†æ‰€æœ‰çš„HTTPè¯·æ±‚\n",
    "        \n",
    "        å‚æ•°:\n",
    "            request: HTTPè¯·æ±‚å¯¹è±¡ï¼ŒåŒ…å«questionã€chosenã€rejectedå­—æ®µ\n",
    "        \n",
    "        è¿”å›:\n",
    "            åŒ…å«åˆ†æ•°ç»“æœçš„å­—å…¸\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - è¿™æ˜¯æœåŠ¡çš„ä¸»è¦å…¥å£ç‚¹ï¼Œæ‰€æœ‰çš„æ¨ç†è¯·æ±‚éƒ½ä¼šè°ƒç”¨è¿™ä¸ªæ–¹æ³•\n",
    "        - æ¥æ”¶ç”¨æˆ·çš„é—®é¢˜å’Œä¸¤ä¸ªå€™é€‰å›ç­”ï¼Œè¿”å›å“ªä¸ªå›ç­”æ›´å¥½çš„è¯„åˆ†\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å¤„ç†å¥åº·æ£€æŸ¥è¯·æ±‚\n",
    "            # å¥åº·æ£€æŸ¥ç”¨äºç›‘æ§æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œ\n",
    "            if hasattr(request, 'url') and request.url and \"health\" in str(request.url):\n",
    "                return {\n",
    "                    \"status\": \"healthy\",\n",
    "                    \"model_path\": self.model_path,\n",
    "                    \"device\": str(self.device),\n",
    "                    \"tokenizer_type\": str(type(self.tokenizer)),\n",
    "                    \"node_id\": ray.get_runtime_context().get_node_id()\n",
    "                }\n",
    "            \n",
    "            # è§£æè¯·æ±‚æ•°æ®\n",
    "            # æ”¯æŒä¸¤ç§è¯·æ±‚æ ¼å¼ï¼šHTTPè¯·æ±‚å’Œç›´æ¥çš„å­—å…¸æ•°æ®\n",
    "            if hasattr(request, 'json'):\n",
    "                data = await request.json()\n",
    "            else:\n",
    "                data = request\n",
    "            \n",
    "            # æå–è¯·æ±‚ä¸­çš„ä¸‰ä¸ªå…³é”®å­—æ®µ\n",
    "            question = data[\"question\"]    # ç”¨æˆ·é—®é¢˜\n",
    "            chosen = data[\"chosen\"]        # äººç±»åå¥½çš„å›ç­”ï¼ˆå¥½å›ç­”ï¼‰\n",
    "            rejected = data[\"rejected\"]    # äººç±»ä¸åå¥½çš„å›ç­”ï¼ˆå·®å›ç­”ï¼‰\n",
    "            \n",
    "            # å°†é—®é¢˜å’Œå›ç­”æ ¼å¼åŒ–ä¸ºæ¨¡å‹è¾“å…¥æ ¼å¼\n",
    "            chosen_text = self.format_conversation(question, chosen)\n",
    "            rejected_text = self.format_conversation(question, rejected)\n",
    "            \n",
    "            logger.info(f\"å¼€å§‹æ¨ç† - tokenizerç±»å‹: {type(self.tokenizer)}\")\n",
    "            \n",
    "            # éªŒè¯tokenizerçŠ¶æ€\n",
    "            # è¿™äº›æ£€æŸ¥ç¡®ä¿tokenizerå·²ç»æ­£ç¡®åˆå§‹åŒ–\n",
    "            if self.tokenizer is None:\n",
    "                error_msg = \"tokenizeræœªæ­£ç¡®åˆå§‹åŒ–\"\n",
    "                logger.error(error_msg)\n",
    "                return {\"error\": error_msg}\n",
    "            \n",
    "            if not callable(self.tokenizer):\n",
    "                error_msg = f\"tokenizerä¸å¯è°ƒç”¨ï¼Œç±»å‹: {type(self.tokenizer)}\"\n",
    "                logger.error(error_msg)\n",
    "                return {\"error\": error_msg}\n",
    "            \n",
    "            start_time = time.time()\n",
    "            \n",
    "            # æ‰§è¡Œæ¨¡å‹æ¨ç†\n",
    "            # torch.no_grad()ç”¨äºå…³é—­æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜å’Œè®¡ç®—èµ„æº\n",
    "            with torch.no_grad():\n",
    "                # å¯¹chosenå›ç­”è¿›è¡Œtokenizationï¼ˆæ–‡æœ¬è½¬æ•°å­—ï¼‰\n",
    "                chosen_inputs = self.tokenizer(\n",
    "                    chosen_text, \n",
    "                    return_tensors=\"pt\",    # è¿”å›PyTorchå¼ é‡\n",
    "                    max_length=2048,        # æœ€å¤§åºåˆ—é•¿åº¦\n",
    "                    truncation=True,        # å¦‚æœè¶…é•¿åˆ™æˆªæ–­\n",
    "                    padding=True            # å¡«å……åˆ°æŒ‡å®šé•¿åº¦\n",
    "                ).to(self.device)           # ç§»åŠ¨åˆ°GPUè®¾å¤‡\n",
    "                \n",
    "                # å¯¹rejectedå›ç­”è¿›è¡Œtokenization\n",
    "                rejected_inputs = self.tokenizer(\n",
    "                    rejected_text, \n",
    "                    return_tensors=\"pt\", \n",
    "                    max_length=2048, \n",
    "                    truncation=True, \n",
    "                    padding=True\n",
    "                ).to(self.device)\n",
    "                \n",
    "                # ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œè·å–chosenå›ç­”çš„åˆ†æ•°\n",
    "                chosen_outputs = self.model(**chosen_inputs)\n",
    "                # ä½¿ç”¨æ¨¡å‹è¿›è¡Œæ¨ç†ï¼Œè·å–rejectedå›ç­”çš„åˆ†æ•°\n",
    "                rejected_outputs = self.model(**rejected_inputs)\n",
    "                \n",
    "                # è®°å½•æ¨¡å‹è¾“å‡ºçš„å½¢çŠ¶å’Œå†…å®¹ï¼Œç”¨äºè°ƒè¯•\n",
    "                logger.info(f\"chosen_outputs.logits shape: {chosen_outputs.logits.shape}\")\n",
    "                logger.info(f\"chosen_outputs.logits: {chosen_outputs.logits}\")\n",
    "                \n",
    "                # æå–åˆ†æ•°\n",
    "                # [0, 0]è¡¨ç¤ºå–ç¬¬ä¸€ä¸ªæ ·æœ¬çš„ç¬¬ä¸€ä¸ªè¾“å‡ºå€¼\n",
    "                chosen_score = float(chosen_outputs.logits[0, 0].cpu().item())\n",
    "                rejected_score = float(rejected_outputs.logits[0, 0].cpu().item())\n",
    "            \n",
    "            # è®¡ç®—å¤„ç†æ—¶é—´\n",
    "            processing_time = time.time() - start_time\n",
    "            # è®¡ç®—åå¥½å¼ºåº¦ï¼ˆchosenåˆ†æ•°ä¸rejectedåˆ†æ•°çš„å·®å€¼ï¼‰\n",
    "            preference_strength = chosen_score - rejected_score\n",
    "            # æ ¹æ®åˆ†æ•°é«˜ä½åˆ¤æ–­é¢„æµ‹ç»“æœ\n",
    "            prediction = \"chosen\" if chosen_score > rejected_score else \"rejected\"\n",
    "            \n",
    "            logger.info(f\"æ¨ç†å®Œæˆ - chosen: {chosen_score:.4f}, rejected: {rejected_score:.4f}\")\n",
    "            \n",
    "            # è¿”å›æ¨ç†ç»“æœ\n",
    "            return {\n",
    "                \"chosen_score\": chosen_score,              # chosenå›ç­”çš„åˆ†æ•°\n",
    "                \"rejected_score\": rejected_score,          # rejectedå›ç­”çš„åˆ†æ•°\n",
    "                \"preference_strength\": preference_strength, # åå¥½å¼ºåº¦\n",
    "                \"prediction\": prediction,                  # é¢„æµ‹ç»“æœ\n",
    "                \"processing_time\": processing_time,        # å¤„ç†æ—¶é—´\n",
    "                \"node_id\": ray.get_runtime_context().get_node_id()  # å¤„ç†èŠ‚ç‚¹ID\n",
    "            }\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"æ¨ç†é”™è¯¯: {str(e)}\")\n",
    "            import traceback\n",
    "            logger.error(f\"é”™è¯¯å †æ ˆ: {traceback.format_exc()}\")\n",
    "            return {\"error\": str(e)}\n",
    "\n",
    "def deploy_service(args):\n",
    "    \"\"\"\n",
    "    éƒ¨ç½²Ray ServeæœåŠ¡\n",
    "    \n",
    "    è¿™ä¸ªå‡½æ•°è´Ÿè´£å¯åŠ¨å’Œé…ç½®Ray ServeæœåŠ¡\n",
    "    \n",
    "    å‚æ•°:\n",
    "        args: å‘½ä»¤è¡Œå‚æ•°å¯¹è±¡ï¼ŒåŒ…å«æ¨¡å‹è·¯å¾„ã€å‰¯æœ¬æ•°é‡ã€ç«¯å£ç­‰é…ç½®\n",
    "    \n",
    "    è¿”å›:\n",
    "        True: éƒ¨ç½²æˆåŠŸ\n",
    "        False: éƒ¨ç½²å¤±è´¥\n",
    "    \n",
    "    åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "    - è¿™æ˜¯æœåŠ¡éƒ¨ç½²çš„æ ¸å¿ƒå‡½æ•°ï¼Œè´Ÿè´£å¯åŠ¨Rayé›†ç¾¤å’Œéƒ¨ç½²æ¨ç†æœåŠ¡\n",
    "    - é…ç½®æœåŠ¡çš„å‰¯æœ¬æ•°é‡ã€èµ„æºåˆ†é…ç­‰å‚æ•°\n",
    "    \"\"\"\n",
    "    # æ£€æŸ¥Rayæ˜¯å¦å·²ç»åˆå§‹åŒ–ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿æ¥åˆ°ç°æœ‰é›†ç¾¤\n",
    "    if not ray.is_initialized():\n",
    "        try:\n",
    "            # è¿æ¥åˆ°å·²ç»å¯åŠ¨çš„Rayé›†ç¾¤\n",
    "            ray.init(address=\"auto\", ignore_reinit_error=True)\n",
    "            logger.info(\"è¿æ¥åˆ°Rayé›†ç¾¤æˆåŠŸ\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"è¿æ¥Rayé›†ç¾¤å¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    # è·å–é›†ç¾¤èµ„æºä¿¡æ¯\n",
    "    cluster_resources = ray.cluster_resources()\n",
    "    total_gpus = int(cluster_resources.get(\"GPU\", 0))\n",
    "    # ç¡®ä¿å‰¯æœ¬æ•°é‡ä¸è¶…è¿‡å¯ç”¨GPUæ•°é‡\n",
    "    num_replicas = min(args.num_replicas, total_gpus)\n",
    "    \n",
    "    logger.info(f\"éƒ¨ç½²é…ç½®: {num_replicas} ä¸ªå‰¯æœ¬\")\n",
    "    \n",
    "    try:\n",
    "        # å¯åŠ¨Ray ServeæœåŠ¡\n",
    "        serve.start(\n",
    "            detached=True,  # åå°è¿è¡Œ\n",
    "            http_options={\n",
    "                \"host\": \"0.0.0.0\",  # ç›‘å¬æ‰€æœ‰ç½‘ç»œæ¥å£\n",
    "                \"port\": args.port   # æŒ‡å®šç«¯å£\n",
    "            }\n",
    "        )\n",
    "        \n",
    "        # é…ç½®æœåŠ¡éƒ¨ç½²é€‰é¡¹\n",
    "        app = RewardService.options(\n",
    "            num_replicas=num_replicas,  # å‰¯æœ¬æ•°é‡\n",
    "            ray_actor_options={\n",
    "                \"num_gpus\": 1,  # æ¯ä¸ªå‰¯æœ¬ä½¿ç”¨1ä¸ªGPU\n",
    "                \"num_cpus\": 2   # æ¯ä¸ªå‰¯æœ¬ä½¿ç”¨2ä¸ªCPUæ ¸å¿ƒ\n",
    "            }\n",
    "        ).bind(args.model_path)  # ç»‘å®šæ¨¡å‹è·¯å¾„å‚æ•°\n",
    "        \n",
    "        # è¿è¡ŒæœåŠ¡ï¼Œè®¾ç½®è·¯ç”±å‰ç¼€\n",
    "        serve.run(app, route_prefix=\"/\")\n",
    "        \n",
    "        logger.info(f\"æœåŠ¡éƒ¨ç½²æˆåŠŸ: http://0.0.0.0:{args.port}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        logger.error(f\"æœåŠ¡éƒ¨ç½²å¤±è´¥: {e}\")\n",
    "        return False\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    ä¸»å‡½æ•°ï¼Œç¨‹åºçš„å…¥å£ç‚¹\n",
    "    \n",
    "    è¿™ä¸ªå‡½æ•°è´Ÿè´£ï¼š\n",
    "    1. è§£æå‘½ä»¤è¡Œå‚æ•°\n",
    "    2. å¯åŠ¨æœåŠ¡\n",
    "    3. å¤„ç†ä¿¡å·å’Œä¿æŒæœåŠ¡è¿è¡Œ\n",
    "    \n",
    "    åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "    - è¿™æ˜¯æ•´ä¸ªæœåŠ¡çš„å¯åŠ¨å…¥å£\n",
    "    - å¤„ç†å‘½ä»¤è¡Œå‚æ•°ï¼Œå¯åŠ¨æœåŠ¡ï¼Œå¹¶ä¿æŒæœåŠ¡æŒç»­è¿è¡Œ\n",
    "    \"\"\"\n",
    "    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨\n",
    "    parser = argparse.ArgumentParser(description=\"å¥–åŠ±æ¨¡å‹æ¨ç†æœåŠ¡\")\n",
    "    parser.add_argument(\"--model_path\", required=True, help=\"æ¨¡å‹è·¯å¾„\")\n",
    "    parser.add_argument(\"--num_replicas\", type=int, default=2, help=\"å‰¯æœ¬æ•°é‡\")\n",
    "    parser.add_argument(\"--port\", type=int, default=8000, help=\"æœåŠ¡ç«¯å£\")\n",
    "    \n",
    "    # è§£æå‘½ä»¤è¡Œå‚æ•°\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    logger.info(\"å¯åŠ¨å¥–åŠ±æ¨¡å‹æœåŠ¡\")\n",
    "    logger.info(f\"æ¨¡å‹è·¯å¾„: {args.model_path}\")\n",
    "    logger.info(f\"å‰¯æœ¬æ•°é‡: {args.num_replicas}\")\n",
    "    logger.info(f\"æœåŠ¡ç«¯å£: {args.port}\")\n",
    "    \n",
    "    # å°è¯•éƒ¨ç½²æœåŠ¡\n",
    "    if deploy_service(args):\n",
    "        logger.info(\"æœåŠ¡å¯åŠ¨æˆåŠŸï¼Œä¿æŒè¿è¡ŒçŠ¶æ€\")\n",
    "        \n",
    "        # å®šä¹‰ä¿¡å·å¤„ç†å‡½æ•°ï¼Œç”¨äºä¼˜é›…åœ°å…³é—­æœåŠ¡\n",
    "        def signal_handler(sig, frame):\n",
    "            logger.info(\"æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œæ­£åœ¨å…³é—­æœåŠ¡\")\n",
    "            serve.shutdown()\n",
    "            sys.exit(0)\n",
    "        \n",
    "        # æ³¨å†Œä¿¡å·å¤„ç†å™¨ï¼Œå¤„ç†Ctrl+Cå’Œç»ˆæ­¢ä¿¡å·\n",
    "        signal.signal(signal.SIGINT, signal_handler)\n",
    "        signal.signal(signal.SIGTERM, signal_handler)\n",
    "        \n",
    "        try:\n",
    "            # ä¿æŒæœåŠ¡è¿è¡Œï¼Œæ¯60ç§’æ£€æŸ¥ä¸€æ¬¡\n",
    "            while True:\n",
    "                time.sleep(60)\n",
    "        except KeyboardInterrupt:\n",
    "            logger.info(\"æœåŠ¡è¢«ç”¨æˆ·ä¸­æ–­\")\n",
    "            serve.shutdown()\n",
    "    else:\n",
    "        logger.error(\"æœåŠ¡å¯åŠ¨å¤±è´¥\")\n",
    "        sys.exit(1)\n",
    "\n",
    "# å¦‚æœè¿™ä¸ªæ–‡ä»¶è¢«ç›´æ¥è¿è¡Œï¼ˆè€Œä¸æ˜¯è¢«å¯¼å…¥ï¼‰ï¼Œåˆ™æ‰§è¡Œä¸»å‡½æ•°\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230dc7bd",
   "metadata": {},
   "source": [
    "æ‰§è¡Œè„šæœ¬ start_ray_cluster.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e77b02",
   "metadata": {},
   "source": [
    "```bash\n",
    "#!/bin/bash\n",
    "\n",
    "# è®¾ç½®è„šæœ¬åœ¨é‡åˆ°é”™è¯¯æ—¶ç«‹å³é€€å‡º\n",
    "set -e\n",
    "\n",
    "# å®šä¹‰é›†ç¾¤èŠ‚ç‚¹IPåœ°å€\n",
    "# è¿™äº›IPåœ°å€åº”è¯¥æ ¹æ®å®é™…çš„é›†ç¾¤é…ç½®è¿›è¡Œä¿®æ”¹\n",
    "HEAD_NODE=\"10.60.11.131\"    # å¤´èŠ‚ç‚¹IPåœ°å€\n",
    "WORKER_NODE=\"10.60.240.249\" # å·¥ä½œèŠ‚ç‚¹IPåœ°å€\n",
    "\n",
    "# æ£€æŸ¥å‘½ä»¤è¡Œå‚æ•°æ•°é‡\n",
    "# è¿™ä¸ªè„šæœ¬è‡³å°‘éœ€è¦ä¸€ä¸ªå‚æ•°ï¼ˆæ¨¡å‹è·¯å¾„ï¼‰\n",
    "if [ $# -lt 1 ]; then\n",
    "    echo \"ç”¨æ³•: $0 <æ¨¡å‹è·¯å¾„> [å‰¯æœ¬æ•°] [ç«¯å£]\"\n",
    "    echo \"ç¤ºä¾‹: $0 output/checkpoint-700 2 8000\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# è§£æå‘½ä»¤è¡Œå‚æ•°\n",
    "MODEL_PATH=$1              # ç¬¬ä¸€ä¸ªå‚æ•°ï¼šæ¨¡å‹è·¯å¾„\n",
    "NUM_REPLICAS=${2:-2}       # ç¬¬äºŒä¸ªå‚æ•°ï¼šå‰¯æœ¬æ•°é‡ï¼Œé»˜è®¤ä¸º2\n",
    "PORT=${3:-8000}            # ç¬¬ä¸‰ä¸ªå‚æ•°ï¼šæœåŠ¡ç«¯å£ï¼Œé»˜è®¤ä¸º8000\n",
    "\n",
    "# å°†ç›¸å¯¹è·¯å¾„è½¬æ¢ä¸ºç»å¯¹è·¯å¾„\n",
    "# è¿™ç¡®ä¿äº†æ— è®ºåœ¨å“ªä¸ªç›®å½•æ‰§è¡Œè„šæœ¬ï¼Œè·¯å¾„éƒ½æ˜¯æ­£ç¡®çš„\n",
    "MODEL_PATH=$(realpath \"$MODEL_PATH\")\n",
    "\n",
    "echo \"å¯åŠ¨éªŒè¯æœåŠ¡\"\n",
    "echo \"æ¨¡å‹è·¯å¾„: $MODEL_PATH\"\n",
    "echo \"å‰¯æœ¬æ•°: $NUM_REPLICAS\"\n",
    "echo \"ç«¯å£: $PORT\"\n",
    "\n",
    "# æ£€æŸ¥æ¨¡å‹è·¯å¾„å’Œå¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "# è¿™äº›æ£€æŸ¥ç¡®ä¿æ¨¡å‹æ–‡ä»¶å®Œæ•´ï¼Œé¿å…å¯åŠ¨åæ‰å‘ç°æ–‡ä»¶ç¼ºå¤±\n",
    "if [ ! -d \"$MODEL_PATH\" ]; then\n",
    "    echo \"é”™è¯¯: æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨: $MODEL_PATH\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "if [ ! -f \"$MODEL_PATH/config.json\" ]; then\n",
    "    echo \"é”™è¯¯: æ¨¡å‹é…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $MODEL_PATH/config.json\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "if [ ! -f \"$MODEL_PATH/tokenizer_config.json\" ]; then\n",
    "    echo \"é”™è¯¯: tokenizeré…ç½®æ–‡ä»¶ä¸å­˜åœ¨: $MODEL_PATH/tokenizer_config.json\"\n",
    "    exit 1\n",
    "fi\n",
    "\n",
    "# åœæ­¢ç°æœ‰çš„æœåŠ¡è¿›ç¨‹\n",
    "# è¿™ç¡®ä¿äº†ä¸ä¼šæœ‰ç«¯å£å†²çªæˆ–èµ„æºå†²çª\n",
    "echo \"åœæ­¢ç°æœ‰æœåŠ¡\"\n",
    "# åœ¨æœ¬åœ°åœæ­¢ray_reward_serviceè¿›ç¨‹\n",
    "pkill -f \"ray_reward_service\" 2>/dev/null || true\n",
    "# åœ¨å·¥ä½œèŠ‚ç‚¹åœæ­¢rayè¿›ç¨‹\n",
    "ssh ubuntu@$WORKER_NODE \"pkill -f ray 2>/dev/null || true\" 2>/dev/null || true\n",
    "\n",
    "# å¯åŠ¨Rayé›†ç¾¤\n",
    "echo \"å¯åŠ¨Rayé›†ç¾¤\"\n",
    "# æ¿€æ´»condaç¯å¢ƒ\n",
    "source ~/miniconda3/etc/profile.d/conda.sh\n",
    "conda activate vllm\n",
    "\n",
    "# å¼ºåˆ¶åœæ­¢ç°æœ‰çš„Rayè¿›ç¨‹ï¼Œç„¶åå¯åŠ¨å¤´èŠ‚ç‚¹\n",
    "ray stop --force 2>/dev/null || true\n",
    "ray start --head --port=6379 --dashboard-host=0.0.0.0 --dashboard-port=8265 --num-gpus=4 --num-cpus=24\n",
    "\n",
    "# å¯åŠ¨å·¥ä½œèŠ‚ç‚¹\n",
    "echo \"è¿æ¥å·¥ä½œèŠ‚ç‚¹\"\n",
    "# é€šè¿‡SSHè¿æ¥åˆ°å·¥ä½œèŠ‚ç‚¹å¹¶å¯åŠ¨Ray worker\n",
    "ssh ubuntu@$WORKER_NODE \"\n",
    "    source ~/miniconda3/etc/profile.d/conda.sh\n",
    "    conda activate vllm\n",
    "    ray stop --force 2>/dev/null || true\n",
    "    ray start --address='$HEAD_NODE:6379' --num-gpus=2\n",
    "\" 2>/dev/null || echo \"å·¥ä½œèŠ‚ç‚¹è¿æ¥å¤±è´¥ï¼Œç»§ç»­å•èŠ‚ç‚¹è¿è¡Œ\"\n",
    "\n",
    "# ç­‰å¾…é›†ç¾¤åˆå§‹åŒ–å®Œæˆ\n",
    "sleep 5\n",
    "\n",
    "# æ£€æŸ¥é›†ç¾¤çŠ¶æ€\n",
    "# è¿™ä¸ªå‘½ä»¤ä¼šæ˜¾ç¤ºé›†ç¾¤ä¸­çš„èŠ‚ç‚¹æ•°é‡ã€èµ„æºç­‰ä¿¡æ¯\n",
    "echo \"æ£€æŸ¥é›†ç¾¤çŠ¶æ€\"\n",
    "ray status\n",
    "\n",
    "# å¯åŠ¨æ¨ç†æœåŠ¡\n",
    "echo \"å¯åŠ¨æ¨ç†æœåŠ¡\"\n",
    "# åœ¨åå°å¯åŠ¨Pythonæ¨ç†æœåŠ¡ï¼Œå¹¶å°†è¾“å‡ºé‡å®šå‘åˆ°æ—¥å¿—æ–‡ä»¶\n",
    "python inference/ray_reward_service.py \\\n",
    "    --model_path \"$MODEL_PATH\" \\\n",
    "    --num_replicas \"$NUM_REPLICAS\" \\\n",
    "    --port \"$PORT\" > validation_service.log 2>&1 &\n",
    "\n",
    "# è·å–æœåŠ¡è¿›ç¨‹IDå¹¶ä¿å­˜åˆ°æ–‡ä»¶\n",
    "SERVICE_PID=$!\n",
    "echo $SERVICE_PID > validation_service.pid\n",
    "\n",
    "echo \"æœåŠ¡å¯åŠ¨å®Œæˆ\"\n",
    "echo \"PID: $SERVICE_PID\"\n",
    "echo \"APIåœ°å€: http://localhost:$PORT\"\n",
    "\n",
    "# ç­‰å¾…æœåŠ¡å¯åŠ¨å¹¶æ£€æŸ¥æœåŠ¡çŠ¶æ€\n",
    "echo \"ç­‰å¾…æœåŠ¡å¯åŠ¨\"\n",
    "for i in {1..20}; do\n",
    "    echo \"æ£€æŸ¥æœåŠ¡çŠ¶æ€ ($i/20)\"\n",
    "    \n",
    "    # æ£€æŸ¥æœåŠ¡è¿›ç¨‹æ˜¯å¦è¿˜åœ¨è¿è¡Œ\n",
    "    # kill -0 ç”¨äºæ£€æŸ¥è¿›ç¨‹æ˜¯å¦å­˜åœ¨ï¼Œä¸ä¼šå®é™…ç»ˆæ­¢è¿›ç¨‹\n",
    "    if ! kill -0 $SERVICE_PID 2>/dev/null; then\n",
    "        echo \"é”™è¯¯: æœåŠ¡è¿›ç¨‹å·²é€€å‡º\"\n",
    "        echo \"æŸ¥çœ‹æ—¥å¿—:\"\n",
    "        cat validation_service.log\n",
    "        exit 1\n",
    "    fi\n",
    "    \n",
    "    # ç­‰å¾…ä¸€æ®µæ—¶é—´å†æ£€æŸ¥å¥åº·çŠ¶æ€\n",
    "    # ç»™æœåŠ¡ä¸€äº›æ—¶é—´æ¥å®Œæˆåˆå§‹åŒ–\n",
    "    sleep 10\n",
    "    \n",
    "    # æ£€æŸ¥æœåŠ¡çš„å¥åº·çŠ¶æ€\n",
    "    # é€šè¿‡å‘é€HTTPè¯·æ±‚åˆ°å¥åº·æ£€æŸ¥ç«¯ç‚¹æ¥éªŒè¯æœåŠ¡æ˜¯å¦æ­£å¸¸\n",
    "    if curl -s --connect-timeout 5 --max-time 10 \"http://localhost:$PORT/health\" >/dev/null 2>&1; then\n",
    "        echo \"æœåŠ¡è¿æ¥æ­£å¸¸\"\n",
    "        # è·å–å¹¶æ ¼å¼åŒ–æ˜¾ç¤ºå¥åº·æ£€æŸ¥ç»“æœ\n",
    "        curl -s \"http://localhost:$PORT/health\" | python -m json.tool 2>/dev/null || echo \"å¥åº·æ£€æŸ¥é€šè¿‡\"\n",
    "        break\n",
    "    else\n",
    "        echo \"æœåŠ¡å°šæœªå°±ç»ªï¼Œç»§ç»­ç­‰å¾…...\"\n",
    "        # å¦‚æœè¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•°ï¼ŒæŠ¥å‘Šè¶…æ—¶é”™è¯¯\n",
    "        if [ $i -eq 20 ]; then\n",
    "            echo \"é”™è¯¯: æœåŠ¡å¯åŠ¨è¶…æ—¶\"\n",
    "            echo \"æŸ¥çœ‹æ—¥å¿—:\"\n",
    "            tail -50 validation_service.log\n",
    "            kill $SERVICE_PID 2>/dev/null || true\n",
    "            exit 1\n",
    "        fi\n",
    "    fi\n",
    "done\n",
    "\n",
    "echo \"éªŒè¯æœåŠ¡å·²å°±ç»ª\"\n",
    "echo \"æ—¥å¿—æ–‡ä»¶: validation_service.log\"\n",
    "echo \"åœæ­¢å‘½ä»¤: kill $SERVICE_PID\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd40799",
   "metadata": {},
   "source": [
    "## æ‰§è¡Œå‘½ä»¤"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcaa080e",
   "metadata": {},
   "source": [
    "bash inference/start_ray_cluster.sh /shared/Skywork-Reward-Llama-3.1-8B/ 3 8000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b68ae1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624175720219.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ff2b0b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625113301838.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "193181ad",
   "metadata": {},
   "source": [
    "å¯åŠ¨åGPUæŸ¥çœ‹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc09051",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624164920253.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83d65606",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624164934916.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb6ef07",
   "metadata": {},
   "source": [
    "åœæ­¢å‘½ä»¤ kill $(cat validation_service.pid)  æ³¨æ„è·¯å¾„ /shared/financial_reward_modelä¸‹æ‰§è¡Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74010f8b",
   "metadata": {},
   "source": [
    "debug æµ‹è¯•æ–‡ä»¶ debug_response.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f8aef7",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import requests\n",
    "import json\n",
    "import sys\n",
    "\n",
    "# è®¾ç½®APIæœåŠ¡çš„åœ°å€\n",
    "# è¿™ä¸ªåœ°å€åº”è¯¥ä¸å¯åŠ¨çš„Ray ServeæœåŠ¡åœ°å€ä¸€è‡´\n",
    "api_url = \"http://localhost:8000\"\n",
    "\n",
    "# å®šä¹‰ä¸€ä¸ªç®€å•çš„æµ‹è¯•ç”¨ä¾‹\n",
    "# è¿™ä¸ªæµ‹è¯•ç”¨ä¾‹åŒ…å«äº†å¥–åŠ±æ¨¡å‹æ¨ç†æ‰€éœ€çš„ä¸‰ä¸ªåŸºæœ¬å­—æ®µ\n",
    "simple_test = {\n",
    "    \"question\": \"Hello\",      # ç”¨æˆ·é—®é¢˜\n",
    "    \"chosen\": \"Hi there!\",    # äººç±»åå¥½çš„å›ç­”ï¼ˆåº”è¯¥å¾—åˆ°æ›´é«˜åˆ†æ•°ï¼‰\n",
    "    \"rejected\": \"No.\"         # äººç±»ä¸åå¥½çš„å›ç­”ï¼ˆåº”è¯¥å¾—åˆ°æ›´ä½åˆ†æ•°ï¼‰\n",
    "}\n",
    "\n",
    "print(\"å‘é€ç®€å•æµ‹è¯•è¯·æ±‚...\")\n",
    "try:\n",
    "    # å‘é€POSTè¯·æ±‚åˆ°æ¨ç†æœåŠ¡\n",
    "    # timeout=30è¡¨ç¤º30ç§’è¶…æ—¶\n",
    "    response = requests.post(f\"{api_url}/\", json=simple_test, timeout=30)\n",
    "    print(f\"çŠ¶æ€ç : {response.status_code}\")\n",
    "    print(f\"å“åº”å†…å®¹: {response.text}\")\n",
    "    \n",
    "    # æ£€æŸ¥HTTPçŠ¶æ€ç æ˜¯å¦ä¸º200ï¼ˆæˆåŠŸï¼‰\n",
    "    if response.status_code == 200:\n",
    "        try:\n",
    "            # å°è¯•è§£æJSONå“åº”\n",
    "            result = response.json()\n",
    "            print(\"JSONè§£ææˆåŠŸ:\")\n",
    "            # æ ¼å¼åŒ–è¾“å‡ºJSONç»“æœï¼Œä¾¿äºé˜…è¯»\n",
    "            print(json.dumps(result, indent=2, ensure_ascii=False))\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"JSONè§£æå¤±è´¥: {e}\")\n",
    "    else:\n",
    "        print(f\"HTTPé”™è¯¯: {response.status_code}\")\n",
    "        \n",
    "except Exception as e:\n",
    "    # æ•è·æ‰€æœ‰å¼‚å¸¸ï¼ŒåŒ…æ‹¬ç½‘ç»œè¿æ¥é”™è¯¯ã€è¶…æ—¶ç­‰\n",
    "    print(f\"è¯·æ±‚å¤±è´¥: {e}\")\n",
    "    sys.exit(1)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f54aa6",
   "metadata": {},
   "source": [
    "æ‰§è¡Œå‘½ä»¤ python inference/debug_response.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819f773f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625104816324.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9e2d18b",
   "metadata": {},
   "source": [
    "æ‰¹é‡æµ‹è¯• test_ray_service.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a046fc",
   "metadata": {},
   "source": [
    "```python\n",
    "#!/usr/bin/env python3\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import time\n",
    "import argparse\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import threading\n",
    "from tqdm import tqdm\n",
    "import statistics\n",
    "import random\n",
    "\n",
    "class ModelValidator:\n",
    "    \"\"\"\n",
    "    å¥–åŠ±æ¨¡å‹éªŒè¯å™¨ç±»\n",
    "    \n",
    "    è¿™ä¸ªç±»æ˜¯æ•´ä¸ªéªŒè¯ç³»ç»Ÿçš„æ ¸å¿ƒï¼Œè´Ÿè´£ï¼š\n",
    "    1. è¿æ¥åˆ°Rayæ¨ç†æœåŠ¡\n",
    "    2. åŠ è½½æµ‹è¯•æ•°æ®\n",
    "    3. å¹¶å‘æ‰§è¡Œæ¨ç†è¯·æ±‚\n",
    "    4. ç»Ÿè®¡å’Œåˆ†æç»“æœ\n",
    "    \n",
    "    åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "    - ä½œä¸ºå®¢æˆ·ç«¯ï¼Œå‘Rayæ¨ç†æœåŠ¡å‘é€éªŒè¯è¯·æ±‚\n",
    "    - è¯„ä¼°å¥–åŠ±æ¨¡å‹çš„å‡†ç¡®ç‡å’Œæ€§èƒ½\n",
    "    - ç”Ÿæˆè¯¦ç»†çš„éªŒè¯æŠ¥å‘Š\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, api_url, max_workers=8):\n",
    "        \"\"\"\n",
    "        åˆå§‹åŒ–éªŒè¯å™¨\n",
    "        \n",
    "        å‚æ•°:\n",
    "            api_url: Rayæ¨ç†æœåŠ¡çš„APIåœ°å€\n",
    "            max_workers: æœ€å¤§å¹¶å‘çº¿ç¨‹æ•°ï¼Œç”¨äºå¹¶è¡Œå‘é€è¯·æ±‚\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - è®¾ç½®éªŒè¯å™¨çš„åŸºæœ¬é…ç½®\n",
    "        - åˆå§‹åŒ–HTTPä¼šè¯å’Œç»Ÿè®¡æ•°æ®ç»“æ„\n",
    "        \"\"\"\n",
    "        self.api_url = api_url\n",
    "        self.max_workers = max_workers\n",
    "        # åˆ›å»ºHTTPä¼šè¯ï¼Œå¤ç”¨è¿æ¥ä»¥æé«˜æ€§èƒ½\n",
    "        self.session = requests.Session()\n",
    "        \n",
    "        # åˆå§‹åŒ–ç»Ÿè®¡æ•°æ®ç»“æ„\n",
    "        # è¿™äº›ç»Ÿè®¡æ•°æ®ç”¨äºè·Ÿè¸ªéªŒè¯è¿‡ç¨‹ä¸­çš„å„ç§æŒ‡æ ‡\n",
    "        self.stats = {\n",
    "            'total': 0,                    # æ€»æ ·æœ¬æ•°\n",
    "            'success': 0,                  # æˆåŠŸè¯·æ±‚æ•°\n",
    "            'failed': 0,                   # å¤±è´¥è¯·æ±‚æ•°\n",
    "            'correct': 0,                  # æ­£ç¡®é¢„æµ‹æ•°\n",
    "            'times': [],                   # å“åº”æ—¶é—´åˆ—è¡¨\n",
    "            'preference_strengths': []     # åå¥½å¼ºåº¦åˆ—è¡¨\n",
    "        }\n",
    "        # çº¿ç¨‹é”ï¼Œç”¨äºä¿æŠ¤ç»Ÿè®¡æ•°æ®çš„å¹¶å‘è®¿é—®\n",
    "        self.lock = threading.Lock()\n",
    "    \n",
    "    def test_connection(self):\n",
    "        \"\"\"\n",
    "        æµ‹è¯•ä¸APIæœåŠ¡çš„è¿æ¥\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•é€šè¿‡å‘é€å¥åº·æ£€æŸ¥è¯·æ±‚æ¥éªŒè¯æœåŠ¡æ˜¯å¦å¯ç”¨\n",
    "        \n",
    "        è¿”å›:\n",
    "            True: è¿æ¥æ­£å¸¸\n",
    "            False: è¿æ¥å¤±è´¥\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - åœ¨å¼€å§‹éªŒè¯ä¹‹å‰ç¡®ä¿æœåŠ¡å¯ç”¨\n",
    "        - è·å–æœåŠ¡çš„åŸºæœ¬ä¿¡æ¯ï¼ˆæ¨¡å‹è·¯å¾„ã€è®¾å¤‡ç­‰ï¼‰\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # å‘é€å¥åº·æ£€æŸ¥è¯·æ±‚\n",
    "            # /healthç«¯ç‚¹è¿”å›æœåŠ¡çš„çŠ¶æ€ä¿¡æ¯\n",
    "            response = self.session.get(f\"{self.api_url}/health\", timeout=10)\n",
    "            if response.status_code == 200:\n",
    "                health = response.json()\n",
    "                print(\"APIè¿æ¥æ­£å¸¸\")\n",
    "                print(f\"æ¨¡å‹è·¯å¾„: {health.get('model_path', 'Unknown')}\")\n",
    "                print(f\"è®¾å¤‡: {health.get('device', 'Unknown')}\")\n",
    "                print(f\"èŠ‚ç‚¹ID: {health.get('node_id', 'Unknown')}\")\n",
    "                return True\n",
    "            else:\n",
    "                print(f\"APIå“åº”å¼‚å¸¸: {response.status_code}\")\n",
    "                return False\n",
    "        except Exception as e:\n",
    "            print(f\"è¿æ¥å¤±è´¥: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def load_test_data(self, max_samples=None):\n",
    "        \"\"\"\n",
    "        åŠ è½½æµ‹è¯•æ•°æ®\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•ä»å›ºå®šè·¯å¾„åŠ è½½preferenceæ•°æ®é›†\n",
    "        \n",
    "        å‚æ•°:\n",
    "            max_samples: æœ€å¤§æ ·æœ¬æ•°é‡ï¼Œå¦‚æœæŒ‡å®šåˆ™éšæœºé‡‡æ ·\n",
    "        \n",
    "        è¿”å›:\n",
    "            æµ‹è¯•æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å«questionã€chosenã€rejectedå­—æ®µ\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - æä¾›éªŒè¯æ‰€éœ€çš„æ ‡å‡†æµ‹è¯•æ•°æ®\n",
    "        - æ”¯æŒé‡‡æ ·åŠŸèƒ½ï¼Œå¯ä»¥æ§åˆ¶éªŒè¯è§„æ¨¡\n",
    "        \"\"\"\n",
    "        # å›ºå®šçš„æµ‹è¯•æ•°æ®è·¯å¾„\n",
    "        # è¿™ä¸ªè·¯å¾„æŒ‡å‘é¢„å¤„ç†å¥½çš„preferenceæ•°æ®é›†\n",
    "        test_file = \"/shared/reward_model_data/reward_data/test/preference_dataset.jsonl\"\n",
    "        \n",
    "        # æ£€æŸ¥æµ‹è¯•æ–‡ä»¶æ˜¯å¦å­˜åœ¨\n",
    "        if not os.path.exists(test_file):\n",
    "            print(f\"æµ‹è¯•æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {test_file}\")\n",
    "            return []\n",
    "        \n",
    "        print(f\"åŠ è½½æµ‹è¯•æ•°æ®: {test_file}\")\n",
    "        \n",
    "        data = []\n",
    "        # é€è¡Œè¯»å–JSONLæ–‡ä»¶\n",
    "        # æ¯è¡Œæ˜¯ä¸€ä¸ªJSONå¯¹è±¡ï¼ŒåŒ…å«ä¸€ä¸ªæµ‹è¯•æ ·æœ¬\n",
    "        with open(test_file, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                item = json.loads(line.strip())\n",
    "                # éªŒè¯æ•°æ®æ ¼å¼ï¼Œç¡®ä¿åŒ…å«å¿…éœ€çš„å­—æ®µ\n",
    "                if all(k in item for k in ['question', 'chosen', 'rejected']):\n",
    "                    data.append(item)\n",
    "        \n",
    "        # å¦‚æœæŒ‡å®šäº†æœ€å¤§æ ·æœ¬æ•°ï¼Œè¿›è¡Œéšæœºé‡‡æ ·\n",
    "        if max_samples and len(data) > max_samples:\n",
    "            data = random.sample(data, max_samples)\n",
    "            print(f\"éšæœºé‡‡æ · {max_samples} æ¡æ•°æ®\")\n",
    "        \n",
    "        print(f\"æµ‹è¯•æ•°æ®åŠ è½½å®Œæˆ: {len(data)} æ¡\")\n",
    "        return data\n",
    "    \n",
    "    def single_test(self, item):\n",
    "        \"\"\"\n",
    "        æ‰§è¡Œå•ä¸ªæµ‹è¯•æ ·æœ¬çš„æ¨ç†\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•å‘APIå‘é€å•ä¸ªæ¨ç†è¯·æ±‚å¹¶å¤„ç†å“åº”\n",
    "        \n",
    "        å‚æ•°:\n",
    "            item: åŒ…å«questionã€chosenã€rejectedçš„æµ‹è¯•æ ·æœ¬\n",
    "        \n",
    "        è¿”å›:\n",
    "            åŒ…å«æ¨ç†ç»“æœå’Œç»Ÿè®¡ä¿¡æ¯çš„å­—å…¸\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - è¿™æ˜¯éªŒè¯çš„æ ¸å¿ƒæ–¹æ³•ï¼Œæ¯ä¸ªæµ‹è¯•æ ·æœ¬éƒ½ä¼šè°ƒç”¨è¿™ä¸ªæ–¹æ³•\n",
    "        - è´Ÿè´£å‘é€HTTPè¯·æ±‚ã€è§£æå“åº”ã€è®¡ç®—å‡†ç¡®æ€§\n",
    "        \"\"\"\n",
    "        start_time = time.time()\n",
    "        \n",
    "        try:\n",
    "            # å‘é€POSTè¯·æ±‚åˆ°æ¨ç†æœåŠ¡\n",
    "            # è¯·æ±‚ä½“åŒ…å«questionã€chosenã€rejectedä¸‰ä¸ªå­—æ®µ\n",
    "            response = self.session.post(\n",
    "                f\"{self.api_url}/\",\n",
    "                json={\n",
    "                    \"question\": item[\"question\"],\n",
    "                    \"chosen\": item[\"chosen\"], \n",
    "                    \"rejected\": item[\"rejected\"]\n",
    "                },\n",
    "                timeout=30  # 30ç§’è¶…æ—¶\n",
    "            )\n",
    "            \n",
    "            # è®¡ç®—å“åº”æ—¶é—´\n",
    "            elapsed = time.time() - start_time\n",
    "            \n",
    "            # æ£€æŸ¥HTTPçŠ¶æ€ç \n",
    "            if response.status_code == 200:\n",
    "                result = response.json()\n",
    "                \n",
    "                # æå–æ¨ç†ç»“æœ\n",
    "                chosen_score = result.get(\"chosen_score\", 0)\n",
    "                rejected_score = result.get(\"rejected_score\", 0)\n",
    "                # åˆ¤æ–­é¢„æµ‹æ˜¯å¦æ­£ç¡®\n",
    "                # æ­£ç¡®çš„é¢„æµ‹åº”è¯¥æ˜¯chosen_score > rejected_score\n",
    "                is_correct = chosen_score > rejected_score\n",
    "                # è®¡ç®—åå¥½å¼ºåº¦ï¼ˆåˆ†æ•°å·®çš„ç»å¯¹å€¼ï¼‰\n",
    "                preference_strength = abs(chosen_score - rejected_score)\n",
    "                \n",
    "                # çº¿ç¨‹å®‰å…¨åœ°æ›´æ–°ç»Ÿè®¡æ•°æ®\n",
    "                with self.lock:\n",
    "                    self.stats['success'] += 1\n",
    "                    self.stats['times'].append(elapsed)\n",
    "                    if is_correct:\n",
    "                        self.stats['correct'] += 1\n",
    "                    self.stats['preference_strengths'].append(preference_strength)\n",
    "                \n",
    "                return {\n",
    "                    'success': True,\n",
    "                    'correct': is_correct,\n",
    "                    'time': elapsed,\n",
    "                    'chosen_score': chosen_score,\n",
    "                    'rejected_score': rejected_score,\n",
    "                    'preference_strength': preference_strength\n",
    "                }\n",
    "            else:\n",
    "                # HTTPé”™è¯¯æƒ…å†µ\n",
    "                with self.lock:\n",
    "                    self.stats['failed'] += 1\n",
    "                return {\n",
    "                    'success': False, \n",
    "                    'error': f\"HTTP {response.status_code}\",\n",
    "                    'time': elapsed\n",
    "                }\n",
    "                \n",
    "        except Exception as e:\n",
    "            # å¼‚å¸¸æƒ…å†µï¼ˆç½‘ç»œé”™è¯¯ã€è¶…æ—¶ç­‰ï¼‰\n",
    "            elapsed = time.time() - start_time\n",
    "            with self.lock:\n",
    "                self.stats['failed'] += 1\n",
    "            return {\n",
    "                'success': False,\n",
    "                'error': str(e)[:100],  # é™åˆ¶é”™è¯¯ä¿¡æ¯é•¿åº¦\n",
    "                'time': elapsed\n",
    "            }\n",
    "    \n",
    "    def run_validation(self, test_data):\n",
    "        \"\"\"\n",
    "        è¿è¡Œå®Œæ•´çš„éªŒè¯æµç¨‹\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•æ˜¯éªŒè¯çš„ä¸»è¦å…¥å£ï¼Œè´Ÿè´£å¹¶å‘æ‰§è¡Œæ‰€æœ‰æµ‹è¯•æ ·æœ¬\n",
    "        \n",
    "        å‚æ•°:\n",
    "            test_data: æµ‹è¯•æ•°æ®åˆ—è¡¨\n",
    "        \n",
    "        è¿”å›:\n",
    "            åŒ…å«å®Œæ•´éªŒè¯ç»“æœçš„å­—å…¸\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - åè°ƒæ•´ä¸ªéªŒè¯è¿‡ç¨‹\n",
    "        - ç®¡ç†å¹¶å‘æ‰§è¡Œ\n",
    "        - ç”Ÿæˆæœ€ç»ˆçš„éªŒè¯æŠ¥å‘Š\n",
    "        \"\"\"\n",
    "        print(f\"å¼€å§‹éªŒè¯ï¼Œå…± {len(test_data)} æ¡æ•°æ®\")\n",
    "        print(f\"å¹¶å‘æ•°: {self.max_workers}\")\n",
    "        \n",
    "        self.stats['total'] = len(test_data)\n",
    "        start_time = time.time()\n",
    "        \n",
    "        results = []\n",
    "        \n",
    "        # ä½¿ç”¨çº¿ç¨‹æ± å¹¶å‘æ‰§è¡Œæ¨ç†è¯·æ±‚\n",
    "        # è¿™å¯ä»¥æ˜¾è‘—æé«˜éªŒè¯é€Ÿåº¦\n",
    "        with ThreadPoolExecutor(max_workers=self.max_workers) as executor:\n",
    "            # æäº¤æ‰€æœ‰ä»»åŠ¡åˆ°çº¿ç¨‹æ± \n",
    "            future_to_item = {\n",
    "                executor.submit(self.single_test, item): item \n",
    "                for item in test_data\n",
    "            }\n",
    "            \n",
    "            # ä½¿ç”¨è¿›åº¦æ¡æ˜¾ç¤ºéªŒè¯è¿›åº¦\n",
    "            with tqdm(total=len(test_data), desc=\"éªŒè¯è¿›åº¦\") as pbar:\n",
    "                # ç­‰å¾…ä»»åŠ¡å®Œæˆå¹¶æ”¶é›†ç»“æœ\n",
    "                for future in as_completed(future_to_item):\n",
    "                    result = future.result()\n",
    "                    results.append(result)\n",
    "                    pbar.update(1)\n",
    "                    \n",
    "                    # å®æ—¶æ›´æ–°è¿›åº¦æ¡æ˜¾ç¤ºçš„ç»Ÿè®¡ä¿¡æ¯\n",
    "                    if self.stats['success'] > 0:\n",
    "                        accuracy = self.stats['correct'] / self.stats['success'] * 100\n",
    "                        pbar.set_postfix({\n",
    "                            'accuracy': f\"{accuracy:.1f}%\",\n",
    "                            'success': self.stats['success'],\n",
    "                            'failed': self.stats['failed']\n",
    "                        })\n",
    "        \n",
    "        total_time = time.time() - start_time\n",
    "        # æ‰“å°è¯¦ç»†çš„éªŒè¯æŠ¥å‘Š\n",
    "        self.print_report(results, total_time)\n",
    "        \n",
    "        # è¿”å›æ±‡æ€»ç»“æœ\n",
    "        return {\n",
    "            'total_samples': len(test_data),\n",
    "            'successful_requests': self.stats['success'],\n",
    "            'failed_requests': self.stats['failed'],\n",
    "            'accuracy': self.stats['correct'] / max(self.stats['success'], 1) * 100,\n",
    "            'avg_response_time': statistics.mean(self.stats['times']) if self.stats['times'] else 0,\n",
    "            'avg_preference_strength': statistics.mean(self.stats['preference_strengths']) if self.stats['preference_strengths'] else 0,\n",
    "            'total_time': total_time\n",
    "        }\n",
    "    \n",
    "    def print_report(self, results, total_time):\n",
    "        \"\"\"\n",
    "        æ‰“å°è¯¦ç»†çš„éªŒè¯æŠ¥å‘Š\n",
    "        \n",
    "        è¿™ä¸ªæ–¹æ³•ç”Ÿæˆå¹¶æ˜¾ç¤ºå®Œæ•´çš„éªŒè¯ç»Ÿè®¡æŠ¥å‘Š\n",
    "        \n",
    "        å‚æ•°:\n",
    "            results: æ‰€æœ‰æµ‹è¯•ç»“æœçš„åˆ—è¡¨\n",
    "            total_time: æ€»éªŒè¯æ—¶é—´\n",
    "        \n",
    "        åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "        - æä¾›äººç±»å¯è¯»çš„éªŒè¯ç»“æœ\n",
    "        - æ˜¾ç¤ºå…³é”®çš„æ€§èƒ½å’Œå‡†ç¡®æ€§æŒ‡æ ‡\n",
    "        \"\"\"\n",
    "        print(\"\\néªŒè¯æŠ¥å‘Š\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        # åŸºæœ¬ç»Ÿè®¡ä¿¡æ¯\n",
    "        print(f\"æ€»æ ·æœ¬æ•°: {self.stats['total']}\")\n",
    "        print(f\"æˆåŠŸè¯·æ±‚: {self.stats['success']}\")\n",
    "        print(f\"å¤±è´¥è¯·æ±‚: {self.stats['failed']}\")\n",
    "        print(f\"æˆåŠŸç‡: {self.stats['success']/self.stats['total']*100:.1f}%\")\n",
    "        \n",
    "        # å¦‚æœæœ‰æˆåŠŸçš„è¯·æ±‚ï¼Œæ˜¾ç¤ºè¯¦ç»†ç»Ÿè®¡\n",
    "        if self.stats['success'] > 0:\n",
    "            # è®¡ç®—æ¨¡å‹å‡†ç¡®ç‡\n",
    "            # è¿™æ˜¯æœ€é‡è¦çš„æŒ‡æ ‡ï¼Œè¡¨ç¤ºæ¨¡å‹æ­£ç¡®åˆ¤æ–­chosen > rejectedçš„æ¯”ä¾‹\n",
    "            accuracy = self.stats['correct'] / self.stats['success'] * 100\n",
    "            print(f\"æ¨¡å‹å‡†ç¡®ç‡: {accuracy:.2f}%\")\n",
    "            \n",
    "            # æ€§èƒ½ç»Ÿè®¡\n",
    "            times = self.stats['times']\n",
    "            print(f\"\\næ€§èƒ½ç»Ÿè®¡:\")\n",
    "            print(f\"  å¹³å‡å“åº”æ—¶é—´: {statistics.mean(times):.3f}s\")\n",
    "            print(f\"  æœ€å¿«å“åº”æ—¶é—´: {min(times):.3f}s\")\n",
    "            print(f\"  æœ€æ…¢å“åº”æ—¶é—´: {max(times):.3f}s\")\n",
    "            print(f\"  æ€»è€—æ—¶: {total_time:.2f}s\")\n",
    "            print(f\"  ååé‡: {self.stats['success']/total_time:.1f} è¯·æ±‚/ç§’\")\n",
    "            \n",
    "            # åå¥½å¼ºåº¦ç»Ÿè®¡\n",
    "            # åå¥½å¼ºåº¦åæ˜ æ¨¡å‹å¯¹åˆ¤æ–­çš„ç½®ä¿¡åº¦\n",
    "            if self.stats['preference_strengths']:\n",
    "                strengths = self.stats['preference_strengths']\n",
    "                print(f\"\\nåå¥½å¼ºåº¦ç»Ÿè®¡:\")\n",
    "                print(f\"  å¹³å‡åå¥½å¼ºåº¦: {statistics.mean(strengths):.4f}\")\n",
    "                print(f\"  æœ€å¤§åå¥½å¼ºåº¦: {max(strengths):.4f}\")\n",
    "                print(f\"  æœ€å°åå¥½å¼ºåº¦: {min(strengths):.4f}\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    ä¸»å‡½æ•°ï¼Œç¨‹åºçš„å…¥å£ç‚¹\n",
    "    \n",
    "    è¿™ä¸ªå‡½æ•°è´Ÿè´£ï¼š\n",
    "    1. è§£æå‘½ä»¤è¡Œå‚æ•°\n",
    "    2. åˆ›å»ºéªŒè¯å™¨å®ä¾‹\n",
    "    3. æ‰§è¡ŒéªŒè¯æµç¨‹\n",
    "    4. ä¿å­˜ç»“æœ\n",
    "    \n",
    "    åœ¨æ•´ä¸ªç³»ç»Ÿä¸­çš„ä½œç”¨ï¼š\n",
    "    - è¿™æ˜¯éªŒè¯ç¨‹åºçš„å¯åŠ¨å…¥å£\n",
    "    - åè°ƒæ•´ä¸ªéªŒè¯æµç¨‹çš„æ‰§è¡Œ\n",
    "    \"\"\"\n",
    "    # åˆ›å»ºå‘½ä»¤è¡Œå‚æ•°è§£æå™¨\n",
    "    parser = argparse.ArgumentParser(description=\"å¥–åŠ±æ¨¡å‹éªŒè¯\")\n",
    "    parser.add_argument(\"--api_url\", type=str, default=\"http://localhost:8000\", \n",
    "                       help=\"APIæœåŠ¡åœ°å€\")\n",
    "    parser.add_argument(\"--max_samples\", type=int, default=None, \n",
    "                       help=\"æœ€å¤§æµ‹è¯•æ ·æœ¬æ•°\")\n",
    "    parser.add_argument(\"--max_workers\", type=int, default=8, \n",
    "                       help=\"å¹¶å‘çº¿ç¨‹æ•°\")\n",
    "    \n",
    "    # è§£æå‘½ä»¤è¡Œå‚æ•°\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # åˆ›å»ºéªŒè¯å™¨å®ä¾‹\n",
    "    validator = ModelValidator(args.api_url, args.max_workers)\n",
    "    \n",
    "    # æµ‹è¯•APIè¿æ¥\n",
    "    if not validator.test_connection():\n",
    "        print(\"æ— æ³•è¿æ¥åˆ°APIæœåŠ¡\")\n",
    "        print(\"è¯·ç¡®ä¿RayæœåŠ¡å·²å¯åŠ¨\")\n",
    "        return\n",
    "    \n",
    "    # åŠ è½½æµ‹è¯•æ•°æ®\n",
    "    test_data = validator.load_test_data(args.max_samples)\n",
    "    if not test_data:\n",
    "        print(\"æ— æ³•åŠ è½½æµ‹è¯•æ•°æ®\")\n",
    "        return\n",
    "    \n",
    "    # æ‰§è¡ŒéªŒè¯\n",
    "    results = validator.run_validation(test_data)\n",
    "    \n",
    "    # ä¿å­˜éªŒè¯ç»“æœåˆ°æ–‡ä»¶\n",
    "    result_file = f\"validation_results_{int(time.time())}.json\"\n",
    "    with open(result_file, 'w', encoding='utf-8') as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"éªŒè¯ç»“æœå·²ä¿å­˜åˆ°: {result_file}\")\n",
    "\n",
    "# å¦‚æœè¿™ä¸ªæ–‡ä»¶è¢«ç›´æ¥è¿è¡Œï¼ˆè€Œä¸æ˜¯è¢«å¯¼å…¥ï¼‰ï¼Œåˆ™æ‰§è¡Œä¸»å‡½æ•°\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ac5547",
   "metadata": {},
   "source": [
    "æ‰¹é‡æ‰§è¡Œå‘½ä»¤ python inference/test_ray_service.py --max_samples 1200 --max_workers 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a39837e",
   "metadata": {},
   "source": [
    "åŸç”Ÿæ¨¡å‹ Skywork-Reward-Llama-3.1-8B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44a50c26",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624175814933.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ff2a2a",
   "metadata": {},
   "source": [
    "checkpoint-700\n",
    "\n",
    "python inference/test_ray_service.py --max_samples 1200 --max_workers 12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99ff6a69",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624164441990.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7d3971",
   "metadata": {},
   "source": [
    "bestmodel æ‰§è¡Œ 1200æ¡æµ‹è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b502573",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250624193213400.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf2aaf8",
   "metadata": {},
   "source": [
    "checkpoint-1000 æ‰§è¡Œ 1200æ¡æµ‹è¯•"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a9eb9e3",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625001413129.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a40448",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625001948278.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "658c525f",
   "metadata": {},
   "source": [
    "# 6.æ€»ç»“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dca4dd9b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250625214102392.png\" width=100%></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
