{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe98a9e5-4646-47d0-9445-19bf22ef3a54",
   "metadata": {},
   "source": [
    "# <center>Ch2 法律领域私有数据模型蒸馏 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22522298",
   "metadata": {},
   "source": [
    "# 背景 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe381a03",
   "metadata": {},
   "source": [
    "### 1. 大模型的计算与部署瓶颈\n",
    "- **模型规模爆炸**：随着深度学习的发展，模型参数量急剧增长，导致训练和推理的计算成本极高。\n",
    "- **硬件资源限制**：大模型对GPU、算力需求极大，难以在边缘设备（如手机、IoT设备）或资源受限场景中部署。\n",
    "- **推理速度问题**：大模型的推理延迟高，无法满足实时性要求（如自动驾驶、实时翻译等场景）。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04333b12",
   "metadata": {},
   "source": [
    "### 2. 模型轻量化需求\n",
    "- **移动端与嵌入式场景**：智能终端设备（手机、传感器等）需要轻量级模型以降低功耗和存储占用。\n",
    "- **商业化落地需求**：企业需要低成本、高效率的模型部署方案，大模型的运维成本过高。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75db358",
   "metadata": {},
   "source": [
    "\n",
    "### 3. 学术界与工业界的协同推动\n",
    "- **大模型研究的兴起**：BERT、GPT等预训练模型的成功，促使研究者探索如何压缩其能力。\n",
    "- **实际应用场景扩展**：工业界需要将大模型能力下沉到实际产品中，蒸馏成为关键技术之一。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df1f423",
   "metadata": {},
   "source": [
    "\n",
    "### 4. 数据隐私与训练成本优化\n",
    "- **减少数据依赖**：蒸馏允许学生模型复用教师模型的知识，降低对原始训练数据的依赖（尤其在敏感数据场景）。\n",
    "- **降低训练成本**：直接训练大模型需要海量计算资源，而蒸馏小模型的成本显著降低。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17d9b7f9",
   "metadata": {},
   "source": [
    "# 1.蒸馏概念回顾"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144bec33",
   "metadata": {},
   "source": [
    "### 第一种：响应级蒸馏（Response-based Distillation）\n",
    "\n",
    "这种方式与SFT相似：\n",
    "\n",
    "- **数据形式**：教师模型生成的问答对（文本对）\n",
    "- **训练方式**：学生模型直接学习生成这些文本\n",
    "- **损失函数**：通常是交叉熵损失\n",
    "- **优点**：实现简单，易于部署\n",
    "- **缺点**：丢失了教师模型的不确定性信息\n",
    "\n",
    "这种方法有时被称为\"弱蒸馏\"或\"伪蒸馏\"，因为它只传递了最终答案，而非教师模型的思考过程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ccb3e9",
   "metadata": {},
   "source": [
    "\n",
    "### 第二种：分布级蒸馏（Distribution-based Distillation）\n",
    "\n",
    "这是更完整、更传统意义上的蒸馏：\n",
    "\n",
    "- **数据形式**：教师模型的输出概率分布（logits或token概率）\n",
    "- **训练方式**：学生模型学习模仿整个分布，而非仅有最终输出\n",
    "- **损失函数**：KL散度、MSE等测量分布差异的损失\n",
    "- **优点**：传递更丰富的知识，包括教师模型的\"不确定性\"\n",
    "- **缺点**：实现更复杂，需要保存更多数据\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c932d0",
   "metadata": {},
   "source": [
    "\n",
    "### 还有第三种：特征级蒸馏（Feature-based Distillation）\n",
    "\n",
    "\n",
    "- **数据形式**：教师模型的中间层激活值、注意力分布等\n",
    "- **训练方式**：学生模型尝试匹配这些内部表示\n",
    "- **损失函数**：特征匹配损失、注意力匹配损失等\n",
    "- **优点**：传递更深层次的知识，更好的泛化能力\n",
    "- **缺点**：通常需要模型架构上的兼容性，实现复杂度高\n",
    "\n",
    "### 实际应用中的组合使用\n",
    "\n",
    "在真实应用中，这些方法常常被组合使用：\n",
    "\n",
    "```json\n",
    "总损失 = α·响应损失 + β·分布损失 + γ·特征损失\n",
    "```\n",
    "\n",
    "其中α、β、γ是权重系数，根据具体任务调整。\n",
    "\n",
    "### 具体示例说明\n",
    "\n",
    "假设有问题\"今天天气怎么样？\"：\n",
    "\n",
    "1. **响应级蒸馏**：学生只学习生成\"今天是晴天\"这个答案文本\n",
    "2. **分布级蒸馏**：学生学习教师的token概率，例如\"晴天\"73%，\"多云\"20%，\"下雨\"7%\n",
    "3. **特征级蒸馏**：学生还学习教师处理这个问题时内部注意力如何分配，哪些特征被激活等\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abfc768",
   "metadata": {},
   "source": [
    "# 2.蒸馏流程"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2649d",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250512221519078.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fe97437",
   "metadata": {},
   "source": [
    "蒸馏过程就是学生模型像教师模型学习数据产生的过程 。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6fde02d",
   "metadata": {},
   "source": [
    "## 2.1 综合蒸馏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7b0e65",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250512221557906.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3556cf0e",
   "metadata": {},
   "source": [
    "\n",
    "### 1. 仅使用问题（只有输入）\n",
    "\n",
    "**适用场景:**\n",
    "- 教师模型在目标领域已经非常强大，几乎不需要参考标准答案\n",
    "- 目标是让学生模型完全模仿教师模型的行为，包括其缺陷\n",
    "- 数据集中没有高质量的标准答案\n",
    "- 任务是开放性的，没有唯一正确答案\n",
    "\n",
    "**好处:**\n",
    "- 最简化的数据准备流程，减少数据处理复杂度\n",
    "- 避免了标准答案可能带来的限制，保留教师模型的创造性\n",
    "- 数据获取成本低，不需要人工标注答案\n",
    "- 训练过程简单直接，学生完全学习教师的输出\n",
    "\n",
    "**坏处:**\n",
    "- 完全继承教师模型的错误和偏见，无法修正\n",
    "- 如果教师模型在目标领域能力不足，学生模型将同样受限\n",
    "- 无法利用已有的高质量标准答案提升性能\n",
    "- 难以针对特定领域进行定向优化\n",
    "- 无法确保输出的专业准确性，特别是在法律、医疗等严格领域\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4afc1d",
   "metadata": {},
   "source": [
    "\n",
    "### 2. 输入+输出全量使用\n",
    "\n",
    "**适用场景:**\n",
    "- 教师模型需要看到完整问答对来生成更好的内部表示\n",
    "- 任务涉及复杂的上下文理解，需要答案来完善理解\n",
    "- 教师模型在领域知识上有所欠缺，需要借助标准答案引导\n",
    "- 希望保留教师模型的通用能力同时提升特定领域能力\n",
    "\n",
    "**好处:**\n",
    "- 教师模型能生成更高质量的特征表示和概率分布\n",
    "- 可以捕获问题和答案之间的关系模式\n",
    "- 增强教师模型对专业领域的理解\n",
    "- 在不直接使用标准答案监督的情况下仍能提高输出质量\n",
    "\n",
    "**坏处:**\n",
    "- 输入序列变长，增加计算资源消耗\n",
    "- 可能导致注意力分散，模型关注非关键信息\n",
    "- 数据处理复杂度增加，需要完整的问答对\n",
    "- 如果标准答案质量不高，可能引入噪声\n",
    "- 间接学习方式效率可能低于直接监督\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ee739f",
   "metadata": {},
   "source": [
    "\n",
    "### 3. 使用问题进行约束\n",
    "\n",
    "**适用场景:**\n",
    "- 需要限制模型输出在特定范围内\n",
    "- 任务有明确的输入限制和期望输出格式\n",
    "- 希望模型专注于特定类型的问题\n",
    "- 应用于需要高度一致性回答的场景\n",
    "\n",
    "**好处:**\n",
    "- 提高模型在特定任务上的精确性\n",
    "- 减少不相关回答的可能性\n",
    "- 使最终模型更加专注于目标领域\n",
    "- 提高推理效率，避免不必要的计算\n",
    "\n",
    "**坏处:**\n",
    "- 可能限制模型的创造性和灵活性\n",
    "- 过度约束可能导致过拟合特定问题模式\n",
    "- 难以处理边缘情况和未见过的问题类型\n",
    "- 实施复杂，需要设计适当的约束机制\n",
    "- 可能降低模型对开放性问题的处理能力"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cea7c12f",
   "metadata": {},
   "source": [
    "\n",
    "### 4. 引入混合损失评估\n",
    "\n",
    "**适用场景:**\n",
    "- 教师模型与标准答案质量差异明显\n",
    "- 有高质量的标准答案可供参考\n",
    "- 需要平衡教师模型知识和标准答案指导\n",
    "- 针对需要高精度回答的专业领域(法律、医疗等)\n",
    "\n",
    "**好处:**\n",
    "- 同时从教师模型和标准答案中获取知识\n",
    "- 减少教师模型可能的错误传播\n",
    "- 提高学生模型在特定领域的准确性\n",
    "- 保留教师模型的推理能力同时确保输出质量\n",
    "\n",
    "**坏处:**\n",
    "- 实现技术复杂，需要设计多种损失函数\n",
    "- 超参数调整难度高，不同损失的权重敏感\n",
    "- 计算开销大，需要同时计算多个损失项\n",
    "- 可能导致训练不稳定，不同目标相互冲突\n",
    "- 需要高质量的标准答案，否则可能引入额外噪声\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d34b82b",
   "metadata": {},
   "source": [
    "## 2.2 分步蒸馏"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307ca7ab",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250512221539051.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda6aa4b",
   "metadata": {},
   "source": [
    "### 基本流程\n",
    "\n",
    "1. **教师模型微调阶段**:\n",
    "   - 选择合适的预训练大模型作为基础教师模型\n",
    "   - 准备领域专业数据集，包含高质量的问答对\n",
    "   - 使用SFT(监督微调)技术对教师模型进行领域适应\n",
    "   - 可选择全参数微调或参数高效微调(如LoRA、QLoRA等)\n",
    "   - 评估微调后的教师模型在目标领域的表现\n",
    "\n",
    "2. **知识蒸馏阶段**:\n",
    "   - 准备蒸馏数据集(可以与微调数据集相同或不同)\n",
    "   - 设计蒸馏损失函数(响应级、分布级、特征级)\n",
    "   - 学生模型学习微调后教师模型的输出和内部表示\n",
    "   - 进行蒸馏训练，可能包含多种损失组合\n",
    "   - 评估和优化学生模型性能\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa76aa09",
   "metadata": {},
   "source": [
    "### 适用场景\n",
    "\n",
    "这种\"先微调后蒸馏\"的方法特别适合以下场景:\n",
    "\n",
    "1. **专业领域应用**:\n",
    "   - 法律、医疗、金融等需要高度专业知识的领域\n",
    "   - 科学研究、工程技术等专业术语丰富的领域\n",
    "   - 特定行业客服、咨询系统等垂直应用\n",
    "\n",
    "2. **原始教师模型领域能力不足**:\n",
    "   - 通用大模型对特定领域知识覆盖不足\n",
    "   - 模型需要学习特定行业术语和表达方式\n",
    "   - 需要纠正模型在特定领域的错误认知\n",
    "\n",
    "3. **有高质量领域数据可用**:\n",
    "   - 拥有大量标注良好的领域专业数据\n",
    "   - 有专家可以验证和改进训练数据质量\n",
    "   - 有明确的领域知识体系和标准\n",
    "\n",
    "4. **资源允许两阶段训练**:\n",
    "   - 有足够的计算资源支持大模型微调\n",
    "   - 有充足的时间完成完整的训练流程\n",
    "   - 对最终模型质量要求高，愿意投入更多资源\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e5162a8",
   "metadata": {},
   "source": [
    "\n",
    "## 优点\n",
    "\n",
    "1. **显著提升领域能力**:\n",
    "   - 微调使教师模型获得深度的专业领域知识\n",
    "   - 蒸馏能有效传递这些专业知识到小模型\n",
    "   - 最终学生模型在目标领域表现优于直接蒸馏\n",
    "\n",
    "2. **避免错误知识传递**:\n",
    "   - 微调过程可以纠正原始大模型的领域错误\n",
    "   - 学生模型学习的是已经\"净化\"的知识\n",
    "   - 减少原始模型偏见和错误的传播\n",
    "\n",
    "3. **更高的知识传递效率**:\n",
    "   - 教师模型具备更精准的领域表示能力\n",
    "   - 蒸馏过程中的知识传递更加聚焦和高效\n",
    "   - 学生模型可以用更少的参数捕获关键知识\n",
    "\n",
    "4. **定制化能力强**:\n",
    "   - 可以针对特定应用场景定制模型能力\n",
    "   - 灵活调整微调和蒸馏侧重点\n",
    "   - 更容易满足特定业务需求\n",
    "\n",
    "5. **可控性与可解释性更强**:\n",
    "   - 两阶段过程提供更多检查点和调整机会\n",
    "   - 可以分析微调效果，针对性改进\n",
    "   - 蒸馏过程更透明，容易识别问题\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97c1a407",
   "metadata": {},
   "source": [
    "\n",
    "## 缺点\n",
    "\n",
    "1. **资源消耗大**:\n",
    "   - 需要两阶段训练，计算资源需求高\n",
    "   - 大模型微调通常需要多GPU/TPU设备\n",
    "   - 整体训练时间长，开发周期延长\n",
    "\n",
    "2. **数据需求高**:\n",
    "   - 需要高质量的领域专业数据\n",
    "   - 数据准备和清洗成本高\n",
    "   - 可能需要领域专家参与数据评估\n",
    "\n",
    "3. **过度专精风险**:\n",
    "   - 微调可能导致教师模型过度专注于特定领域\n",
    "   - 可能丧失部分通用能力和创造性\n",
    "   - 学生模型可能继承这种过度专精倾向\n",
    "\n",
    "4. **调参复杂度高**:\n",
    "   - 微调和蒸馏各有一套超参数需要调整\n",
    "   - 两个过程的最优参数可能互相影响\n",
    "   - 需要更多实验来找到最佳配置\n",
    "\n",
    "5. **错误累积可能**:\n",
    "   - 如果微调方向有误，蒸馏会放大这些错误\n",
    "   - 两阶段都可能引入新的错误\n",
    "   - 调试更复杂，错误来源难以定位"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435944e2",
   "metadata": {},
   "source": [
    "## 2.3 蒸馏层级详解"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd6939f",
   "metadata": {},
   "source": [
    "### 1. 分词与词嵌入层 (Tokenization & Embedding Layer)\n",
    "\n",
    "**官方名称**：Embedding Layer\n",
    "\n",
    "**形象比喻**：**\"翻译官\"** - 将人类语言翻译成机器理解的数字向量\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：原始文本 \"人工智能正在改变世界\"\n",
    "- **处理**：\n",
    "  - 文本被分词器切分为token IDs: [101, 3209, 1744, 7305, 4638, 720, 1767, 1399, 782, 102]\n",
    "  - 每个ID通过查表操作映射为固定维度的向量\n",
    "- **输出**：嵌入矩阵 [seq_len, embedding_dim]，例如 [10, 768]\n",
    "- **数据变化**：从离散token转为连续向量表示，编码了词汇语义信息\n",
    "\n",
    "**形象解释**：\n",
    "- 词嵌入层就像一本巨大的\"词典\"，包含5万多个单词(词表大小)\n",
    "- 每个单词在这本词典中都有一个768维的\"定义\"(或\"身份证\")\n",
    "- 当\"人工智能\"这个短语进入模型时，分词器先把它切成适合查词典的单位\n",
    "- 然后查词典，将每个单位转换成768维的向量，就像把文字翻译成了\"数学语言\"\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 在特征级蒸馏中很少直接使用，因为这是基础输入层\n",
    "- 有时学生模型和教师模型使用不同的词表，需要特殊处理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a2bf657",
   "metadata": {},
   "source": [
    "\n",
    "### 2. 位置编码层 (Positional Encoding Layer)\n",
    "\n",
    "**官方名称**：Positional Encoding Layer\n",
    "\n",
    "**形象比喻**：**\"地址标签员\"** - 给每个词贴上位置标签\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：嵌入向量 [batch_size, seq_len, 768]\n",
    "- **处理**：\n",
    "  - 生成位置编码(可以是预先计算的正弦/余弦函数，或可学习的参数)\n",
    "  - 将位置编码与词嵌入向量相加\n",
    "- **输出**：位置编码后的嵌入向量 [batch_size, seq_len, 768]\n",
    "- **数据变化**：向量中融入了位置信息，使模型能识别词序\n",
    "\n",
    "**形象解释**：\n",
    "- 没有位置信息，模型只知道句子中有哪些词，但不知道它们的顺序\n",
    "- 位置编码像是给每个词加上了邮政编码：\"第1位的词\"、\"第2位的词\"\n",
    "- 这种\"标记\"融入了每个词的768维向量，而不是单独保存\n",
    "- 就像在每个词的\"身份证\"上额外盖了一个表明其位置的章\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 类似嵌入层，很少在蒸馏中直接对位置编码进行操作\n",
    "- 但它会影响后续所有层的表示，间接影响特征级蒸馏\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490a62ce",
   "metadata": {},
   "source": [
    "\n",
    "### 3. Transformer编码层 (Transformer Encoder Layers)\n",
    "\n",
    "#### 3.1 自注意力子层 (Self-Attention Sublayer)\n",
    "\n",
    "**官方名称**：Multi-Head Self-Attention Layer\n",
    "\n",
    "**形象比喻**：**\"上下文关联器\"** - 让每个词\"看到\"并关联其他相关词\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：上一层输出 [batch_size, seq_len, 768]\n",
    "- **处理**：\n",
    "  - 生成查询(Q)/键(K)/值(V)矩阵：每个都是 [batch_size, seq_len, 768]\n",
    "  - 计算注意力分数：Q·K^T / sqrt(d_k) → [batch_size, seq_len, seq_len]\n",
    "  - 应用softmax获得注意力权重\n",
    "  - 加权汇总：权重与V相乘得到 [batch_size, seq_len, 768]\n",
    "- **输出**：注意力输出 [batch_size, seq_len, 768]\n",
    "\n",
    "**形象解释**：\n",
    "- 自注意力就像\"词与词之间开会\"，每个词都能发言和倾听\n",
    "- 在\"人工智能正在改变世界\"中，\"改变\"一词会特别关注\"世界\"，因为它们有强关联\n",
    "- 多头注意力相当于同时举行8个不同主题的小组讨论，每组关注不同角度\n",
    "- 注意力权重就像会议中的\"发言权重表\"，显示谁在跟谁交流及其重要程度\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 属于特征级蒸馏的关键层\n",
    "- 注意力权重矩阵 [batch_size, num_heads, seq_len, seq_len] 有时单独作为蒸馏目标\n",
    "- 如：让学生模型学习教师模型在\"改变\"和\"世界\"之间建立的强关联模式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d7b992",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.2 前馈网络子层 (Feed-Forward Network Sublayer)\n",
    "\n",
    "**官方名称**：Position-wise Feed-Forward Network (FFN)\n",
    "\n",
    "**形象比喻**：**\"信息加工站\"** - 深入处理每个位置的信息\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：注意力层输出 [batch_size, seq_len, 768]\n",
    "- **处理**：\n",
    "  - 第一个线性变换：768 → 3072维 (扩展)\n",
    "  - 激活函数(GELU)添加非线性\n",
    "  - 第二个线性变换：3072 → 768维 (压缩回原维度)\n",
    "- **输出**：FFN输出 [batch_size, seq_len, 768]\n",
    "\n",
    "**形象解释**：\n",
    "- 如果注意力层是\"开会收集信息\"，前馈网络就是\"独自思考消化信息\"\n",
    "- 先将信息展开(768→3072)，像是把笔记本展开成大海报，有更多空间思考\n",
    "- 通过激活函数处理，就像用荧光笔标记重点，增加思考深度\n",
    "- 再将信息压缩回原尺寸(3072→768)，把思考结果整理成简洁笔记\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 属于特征级蒸馏目标\n",
    "- FFN输出通常作为整个Transformer层输出的一部分被蒸馏\n",
    "- 教师模型FFN输出可能是4096维，学生模型是2048维，需要特征映射\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1e92f6",
   "metadata": {},
   "source": [
    "\n",
    "#### 3.3 残差连接与层归一化 (Residual Connection & Layer Normalization)\n",
    "\n",
    "**官方名称**：Residual Connection & Layer Normalization\n",
    "\n",
    "**形象比喻**：**\"信息保鲜器\"** - 确保重要信息不会在传递中丢失\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：原始输入X和子层输出SubLayer(X)\n",
    "- **处理**：\n",
    "  - 残差连接：X + SubLayer(X)\n",
    "  - 层归一化：统计均值和方差，进行归一化处理\n",
    "- **输出**：标准化的Transformer层输出 [batch_size, seq_len, 768]\n",
    "\n",
    "**形象解释**：\n",
    "- 残差连接像是\"备份通道\"，确保原始信息不会完全丢失\n",
    "- 就像一边听新课(子层输出)，一边保留旧笔记(原始输入)\n",
    "- 层归一化像是\"统一格式\"，将大小不一的数值调整到相似范围\n",
    "- 这就像把不同颜色深浅的照片调整到标准亮度，便于后续处理\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 层归一化后的输出是特征级蒸馏的重要目标\n",
    "- 这些输出就是通常所说的\"隐藏状态\"(hidden states)\n",
    "- 具有稳定的统计特性，便于跨模型传递知识\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d12e8d0",
   "metadata": {},
   "source": [
    "\n",
    "### 4. LM Head层 (Language Model Head)\n",
    "\n",
    "**官方名称**：LM Head / Output Layer\n",
    "\n",
    "**形象比喻**：**\"词汇预测器\"** - 将机器理解转换回人类语言的可能性\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：最终Transformer层输出 [batch_size, seq_len, 768]\n",
    "- **处理**：线性变换将隐藏表示映射到词表大小\n",
    "- **输出**：logits [batch_size, seq_len, vocab_size]，例如 [batch_size, seq_len, 50000]\n",
    "\n",
    "**形象解释**：\n",
    "- LM Head就像一个\"翻译官的反向工作\"\n",
    "- 从768维的\"机器理解\"转换回50000个可能的词汇\n",
    "- 如果Transformer层理解了\"王后很____\"，LM Head会给出所有可能填空词的分数\n",
    "- \"聪明\"可能得9.2分，\"美丽\"得8.7分，\"强大\"得8.5分...\n",
    "- 这些原始分数(logits)就像\"投票数\"，尚未归一化为概率\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 是分布级蒸馏的核心作用层\n",
    "- logits直接反映模型的预测分布，包含更丰富的知识\n",
    "- 通过温度参数调整可以控制知识的\"软硬程度\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7279cad5",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Softmax层 (Softmax Layer)\n",
    "\n",
    "**官方名称**：Softmax Layer/函数\n",
    "\n",
    "**形象比喻**：**\"概率分配器\"** - 将原始分数转换为概率分布\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：LM Head输出的logits [batch_size, seq_len, vocab_size]\n",
    "- **处理**：应用softmax函数将logits转换为概率\n",
    "- **输出**：token概率分布 [batch_size, seq_len, vocab_size]\n",
    "- **数据变化**：从原始分数(-∞到+∞)转换为概率(0到1，总和为1)\n",
    "\n",
    "**形象解释**：\n",
    "- Softmax就像\"选举票数转化为席位分配\"\n",
    "- 原始logits可能是：{\"改变\":12.5, \"影响\":10.2, \"塑造\":8.7}\n",
    "- Softmax后变成：{\"改变\":0.70, \"影响\":0.25, \"塑造\":0.05}\n",
    "- 这一步使原始\"投票分数\"变成了标准化的\"获胜概率\"\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 是分布级蒸馏的后半部分\n",
    "- 通常会使用温度参数调整概率分布的平滑度\n",
    "- 高温度(如T=2.0)会产生更平滑的分布，传递更多关于次优选择的信息\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d623f1",
   "metadata": {},
   "source": [
    "\n",
    "### 6. 解码/生成层 (Decoding/Generation Layer)\n",
    "\n",
    "**官方名称**：Decoder/Generator\n",
    "\n",
    "**形象比喻**：**\"决策者\"** - 根据概率分布做出实际选择\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：Softmax层输出的概率分布\n",
    "- **处理**：\n",
    "  - 贪婪解码(选择最高概率token)\n",
    "  - 或beam search(保持多个可能路径)\n",
    "  - 或采样(按概率随机选择)\n",
    "- **输出**：选定的token ID序列 [batch_size, seq_len]\n",
    "- **数据变化**：从概率分布收敛到具体token选择\n",
    "\n",
    "**形象解释**：\n",
    "- 解码层就像\"最终拍板的决策者\"\n",
    "- 面对{\"改变\":0.70, \"影响\":0.25, \"塑造\":0.05}的概率分布：\n",
    "  - 贪婪解码会直接选择\"改变\"(最高概率)\n",
    "  - 温度采样可能根据概率随机选择，有时会选\"影响\"\n",
    "  - beam search会同时考虑多个选择，看后续发展再决定\n",
    "- 这一步将\"可能性分布\"转变为\"确定性选择\"\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 与响应级蒸馏直接相关\n",
    "- 生成策略(贪婪、beam search或采样)会影响最终文本输出\n",
    "- 学生模型需要学习教师模型的生成策略和风格\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ee2bde2",
   "metadata": {},
   "source": [
    "\n",
    "### 7. 文本输出层 (Text Output Layer)\n",
    "\n",
    "**官方名称**：Tokenizer Decoder/Text Generator\n",
    "\n",
    "**形象比喻**：**\"翻译官的终极任务\"** - 将机器内部表示转回人类可读文本\n",
    "\n",
    "**详细描述**：\n",
    "- **输入**：解码层输出的token ID序列\n",
    "- **处理**：将ID序列通过分词器转换回文本\n",
    "- **输出**：最终生成的自然语言文本\n",
    "- **数据变化**：从数字ID序列回到原始自然语言\n",
    "\n",
    "**形象解释**：\n",
    "- 这就像将\"密码\"解码回正常人类语言\n",
    "- 从[3209, 1744, 7305, 4638, 720, 1767, 1399]这样的数字序列\n",
    "- 变回\"人工智能正在改变世界\"这样的自然文本\n",
    "- 是整个\"翻译\"过程的最后一步，完成从人类→机器→人类的循环\n",
    "\n",
    "**蒸馏相关性**：\n",
    "- 是响应级蒸馏的核心比较对象\n",
    "- 最终文本输出是响应级蒸馏直接比较的目标\n",
    "- 衡量教师模型和学生模型生成文本的相似度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf5464",
   "metadata": {},
   "source": [
    "\n",
    "## 2.4 三种蒸馏方法与层级对应详解\n",
    "\n",
    "### 1. 特征级蒸馏 (Feature-level Distillation)\n",
    "\n",
    "**对应层级**：\n",
    "- 主要作用于**Transformer各编码层的隐藏状态输出**\n",
    "- 核心是隐藏状态(hidden states)，也就是每个Transformer层的完整输出\n",
    "\n",
    "**形象比喻**：**\"学徒模仿师傅的思考过程\"**\n",
    "\n",
    "**详细描述**：\n",
    "- **具体层级**：每个Transformer块的输出，通常是层归一化后的结果\n",
    "- **技术对应**：\n",
    "```python\n",
    "  # 教师模型第12层输出\n",
    "  teacher_layer12 = teacher_outputs.hidden_states[12]  # [batch, seq, 1024]\n",
    "  # 学生模型第6层输出\n",
    "  student_layer6 = student_outputs.hidden_states[6]    # [batch, seq, 512]\n",
    "  # 通过特征映射器对齐维度\n",
    "  mapped_teacher = feature_mapper(teacher_layer12)     # [batch, seq, 512]\n",
    "  # 计算损失\n",
    "  loss = F.mse_loss(student_layer6, mapped_teacher)\n",
    " ```\n",
    "\n",
    "**形象工作过程**：\n",
    "1. 教师模型(\"大师\")的第12层看到\"人工智能正在改变世界\"时，产生了一个1024维的\"理解笔记\"\n",
    "2. 这个\"笔记\"包含了\"人工智能\"如何与\"改变世界\"关联的深刻理解\n",
    "3. 学生模型(\"学徒\")的第6层尝试产生类似的理解，但它的\"笔记本\"只有512维\n",
    "4. 特征映射器就像一个\"笔记压缩工具\"，将大师的1024维笔记压缩成512维\n",
    "5. 学徒努力使自己的笔记与压缩后的大师笔记一致，从而学习大师的思考方式\n",
    "\n",
    "**具体变化示例**：\n",
    "- 教师第12层处理\"人工智能\"：\n",
    "  - 识别这是科技领域的核心概念\n",
    "  - 建立与\"计算机\"、\"算法\"、\"学习\"等概念的关联\n",
    "  - 这些复杂关系编码在1024维向量中\n",
    "- 通过特征映射压缩到512维：\n",
    "  - 保留核心语义关联\n",
    "  - 可能牺牲一些细微关联强度的精确度\n",
    "- 学生第6层学习这种压缩后的理解模式\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2733c912",
   "metadata": {},
   "source": [
    "\n",
    "### 2. 分布级蒸馏 (Distribution-level Distillation)\n",
    "\n",
    "**对应层级**：\n",
    "- 主要作用于**LM Head层输出的logits**\n",
    "- 具体是每个token位置上的词表预测分数\n",
    "\n",
    "**形象比喻**：**\"学习大师的决策偏好\"**\n",
    "\n",
    "**详细描述**：\n",
    "- **具体层级**：LM Head输出的原始logits，未经softmax转换\n",
    "- **技术对应**：\n",
    "```python\n",
    "  # 获取两个模型在词表空间的原始预测分数\n",
    "  teacher_logits = teacher_outputs.logits  # [batch, seq, 50000]\n",
    "  student_logits = student_outputs.logits  # [batch, seq, 50000]\n",
    "  \n",
    "  # 使用温度参数软化分布\n",
    "  temperature = 2.0\n",
    "  soft_teacher = F.softmax(teacher_logits / temperature, dim=-1)\n",
    "  soft_student = F.log_softmax(student_logits / temperature, dim=-1)\n",
    "  \n",
    "  # 计算KL散度损失\n",
    "  kl_loss = F.kl_div(soft_student, soft_teacher, reduction='batchmean') * (temperature**2)\n",
    "```\n",
    "\n",
    "**形象工作过程**：\n",
    "1. 教师模型预测\"人工智能将____未来\"的下一个词时，给出所有可能词的评分：\n",
    "   - \"改变\"：9.2分\n",
    "   - \"影响\"：8.7分\n",
    "   - \"塑造\"：8.1分\n",
    "   - \"决定\"：7.5分\n",
    "   - ...其他数万个词各有分数\n",
    "2. 温度参数(T=2.0)使这些分数差异变得更平滑：\n",
    "   - \"改变\"：60%\n",
    "   - \"影响\"：25%\n",
    "   - \"塑造\"：10%\n",
    "   - \"决定\"：5%\n",
    "3. 学生模型学习这种\"犹豫模式\"，而不仅仅是最高分的词\n",
    "4. 这就像学徒不仅学习大师最终选择了什么词，还学习大师对各种选择的倾向性\n",
    "\n",
    "**具体变化示例**：\n",
    "- 教师模型面对\"人工智能将___未来\"：\n",
    "  - LM Head输出50000个分数\n",
    "  - 最高几个是与\"改变/影响/塑造\"相关的词\n",
    "- 使用温度调整后：\n",
    "  - 原本悬殊的分数差距被平滑\n",
    "  - 学生模型可以学习到更细微的词汇偏好\n",
    "- 学生模型不仅学习预测\"改变\"，还学习何时考虑用\"影响\"或\"塑造\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c1e711",
   "metadata": {},
   "source": [
    "\n",
    "### 3. 响应级蒸馏 (Response-level Distillation)\n",
    "\n",
    "**对应层级**：\n",
    "- 主要作用于**解码/生成层**和**文本输出层**\n",
    "- 关注从token概率到最终文本的整个生成过程\n",
    "\n",
    "**形象比喻**：**\"学习大师的最终作品风格\"**\n",
    "\n",
    "**详细描述**：\n",
    "- **具体层级**：从Softmax后的概率分布到最终生成的文本\n",
    "- **技术对应**：\n",
    "```python\n",
    "  # 使用相同的输入进行生成\n",
    "  input_text = \"请解释人工智能的未来\"\n",
    "  input_ids = tokenizer.encode(input_text, return_tensors=\"pt\")\n",
    "  \n",
    "  # 教师模型生成\n",
    "  teacher_outputs = teacher_model.generate(\n",
    "      input_ids,\n",
    "      max_length=200,\n",
    "      num_beams=4,  # 使用beam search\n",
    "      temperature=0.7  # 控制生成多样性\n",
    "  )\n",
    "  teacher_text = tokenizer.decode(teacher_outputs[0])\n",
    "  \n",
    "  # 学生模型生成\n",
    "  student_outputs = student_model.generate(\n",
    "      input_ids,\n",
    "      max_length=200,\n",
    "      num_beams=4,\n",
    "      temperature=0.7\n",
    "  )\n",
    "  student_text = tokenizer.decode(student_outputs[0])\n",
    "  \n",
    "  # 计算文本相似度\n",
    "  from rouge import Rouge\n",
    "  rouge = Rouge()\n",
    "  scores = rouge.get_scores(student_text, teacher_text)\n",
    "  response_loss = 1.0 - scores[0]['rouge-l']['f']  # 使用ROUGE-L作为相似度度量\n",
    "```\n",
    "\n",
    "**形象工作过程**：\n",
    "1. 教师模型和学生模型接收相同的问题：\"请解释人工智能的未来\"\n",
    "2. 教师模型通过其生成过程产生连贯文本：\n",
    "   \"人工智能技术将深刻改变各行各业，从医疗保健到交通运输...\"\n",
    "3. 学生模型也产生自己的回答：\n",
    "   \"人工智能将影响多个领域，包括医疗和交通...\"\n",
    "4. 响应级蒸馏直接比较这两段文本的相似度\n",
    "5. 调整学生模型参数，使其生成的文本更接近教师模型的风格和内容\n",
    "\n",
    "**具体变化示例**：\n",
    "- 教师模型可能倾向于使用更专业的术语和更完整的句子结构\n",
    "- 学生模型通过响应级蒸馏学习这些文体特点\n",
    "- 即使内部表示不同，最终目标是生成相似的文本\n",
    "- 这就像学习一位作家的写作风格，而不是他的思考过程\n",
    "\n",
    "\n",
    "### 三种蒸馏方法的协同作用\n",
    "\n",
    "完整的蒸馏流程应该覆盖模型的全部层级和处理步骤：\n",
    "\n",
    "1. **特征级蒸馏** → Transformer隐藏层\n",
    "   - 学习内部表示和思考过程\n",
    "   - 确保基础语义理解能力的传递\n",
    "\n",
    "2. **分布级蒸馏** → LM Head + Softmax层\n",
    "   - 学习词汇预测的概率分布\n",
    "   - 传递关于次优选择的知识\n",
    "\n",
    "3. **响应级蒸馏** → 解码/生成 + 文本输出层\n",
    "   - 学习最终文本的生成风格\n",
    "   - 确保用户体验的一致性\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5a5ee3",
   "metadata": {},
   "source": [
    "## 2.5 混合蒸馏 (Mixed Distillation)\n",
    "\n",
    "**定义**：同时使用多种蒸馏方法（响应级、分布级、特征级），通过加权组合多个损失函数进行联合优化。\n",
    "\n",
    "**\"多渠道同步学习\"** - 就像学徒同时通过观察大师的笔记、决策过程和最终作品来学习。\n",
    "\n",
    "**具体实现**：\n",
    "```python\n",
    "total_loss = α·response_loss + β·distribution_loss + γ·feature_loss\n",
    "```\n",
    "\n",
    "**优势**：\n",
    "- 全面传递知识，不遗漏任何层面的信息\n",
    "- 可以弥补单一蒸馏方法的不足\n",
    "- 学生模型能同时学习内部表示和外部行为\n",
    "- 适合需要全方位复制教师模型能力的场景\n",
    "\n",
    "**劣势**：\n",
    "- 实现复杂，需要平衡多个损失函数\n",
    "- 超参数调整难度大，各损失权重敏感\n",
    "- 可能导致训练不稳定，各目标相互干扰\n",
    "- 计算开销大，需要计算多个损失项\n",
    "\n",
    "**适用场景**：\n",
    "- 高质量通用模型开发，需要保留教师模型全部能力\n",
    "- 有充足计算资源且对最终质量要求高的情况\n",
    "- 教师和学生模型架构相似但规模不同\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3278b8ef",
   "metadata": {},
   "source": [
    "\n",
    "## 2.6 渐进式蒸馏  \n",
    "\n",
    "**定义**：分阶段进行蒸馏，在训练过程中逐步调整策略、目标或方法，通常从简单到复杂。\n",
    "\n",
    "**\"阶梯式学习\"** - 像是学徒先学习基础技能，再逐步掌握更复杂的技艺。\n",
    "\n",
    "**两种主要方向**：\n",
    "\n",
    "### 1. 从特征级到响应级 \n",
    "- **阶段顺序**：特征级 → 分布级 → 响应级\n",
    "- **形象描述**：先学习思考方式，再学习表达方式\n",
    "- **实现方式**：\n",
    "```python\n",
    " # 阶段1: 特征级蒸馏为主\n",
    "  if epoch < epochs/3:\n",
    "      loss = 0.8*feature_loss + 0.2*distribution_loss\n",
    "  # 阶段2: 分布级蒸馏为主\n",
    "  elif epoch < 2*epochs/3:\n",
    "      loss = 0.3*feature_loss + 0.6*distribution_loss + 0.1*response_loss\n",
    "  # 阶段3: 响应级蒸馏为主\n",
    "  else:\n",
    "      loss = 0.1*feature_loss + 0.4*distribution_loss + 0.5*response_loss\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7183fb",
   "metadata": {},
   "source": [
    "\n",
    "### 2. 从响应级到特征级 \n",
    "- **阶段顺序**：响应级 → 分布级 → 特征级\n",
    "- **形象描述**：先学习模仿输出，再逐步理解内部原理\n",
    "- **实现方式**：\n",
    "```python\n",
    "  # 阶段1: 响应级蒸馏为主\n",
    "  if epoch < epochs/3:\n",
    "      loss = 0.8*response_loss + 0.2*distribution_loss\n",
    "  # 阶段2: 分布级蒸馏为主\n",
    "  elif epoch < 2*epochs/3:\n",
    "      loss = 0.5*response_loss + 0.4*distribution_loss + 0.1*feature_loss\n",
    "  # 阶段3: 特征级蒸馏为主\n",
    "  else:\n",
    "      loss = 0.2*response_loss + 0.3*distribution_loss + 0.5*feature_loss\n",
    "```\n",
    "\n",
    "**优势**：\n",
    "- 训练更稳定，避免多目标冲突\n",
    "- 符合人类学习的渐进过程\n",
    "- 可以更精细地控制知识传递\n",
    "- 减少学生模型在初期面临的困难\n",
    "\n",
    "**劣势**：\n",
    "- 训练时间更长，需要多个阶段\n",
    "- 阶段转换可能导致性能波动\n",
    "- 需要更细致的调参和监控\n",
    "- 顺序选择不当可能影响最终效果\n",
    "\n",
    "**适用场景**：\n",
    "- 教师和学生模型差异较大时\n",
    "- 有足够训练时间追求最佳效果\n",
    "- 特定领域知识需要逐步传递\n",
    "- 学生模型学习能力有限需要循序渐进\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3b0327",
   "metadata": {},
   "source": [
    "\n",
    "## 2.7 各方法对比与选择指南\n",
    "\n",
    "### 混合蒸馏 vs 渐进式蒸馏\n",
    "\n",
    "**混合蒸馏**:\n",
    "- **特点**：同时多方向学习，并行传递知识\n",
    "- **优势**：知识传递全面，不遗漏关键点\n",
    "- **劣势**：训练可能不稳定，目标冲突\n",
    "- **适合场景**：学生模型容量充足，差异不大\n",
    "\n",
    "**渐进式蒸馏**:\n",
    "- **特点**：分阶段学习，重点逐步转移\n",
    "- **优势**：训练更稳定，避免目标冲突\n",
    "- **劣势**：训练时间长，阶段过渡敏感\n",
    "- **适合场景**：学生模型容量有限，需要循序渐进\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34364d0",
   "metadata": {},
   "source": [
    "\n",
    "## 2.8 混合渐进式蒸馏 \n",
    "\n",
    "**定义**：结合混合蒸馏和渐进式蒸馏，不仅同时使用多种蒸馏方法，还随着训练进程动态调整各方法的权重。\n",
    "\n",
    "**形象比喻**：**\"动态多渠道学习\"** - 学徒在学习过程中，根据掌握程度动态调整学习各方面技能的注意力分配。\n",
    "\n",
    "**实现示例**：\n",
    "```python\n",
    "# 计算当前训练进度\n",
    "progress = current_step / total_steps\n",
    "\n",
    "# 根据进度动态调整权重\n",
    "feature_weight = max(0.7 - progress*0.5, 0.2)  # 从0.7逐渐降至0.2\n",
    "distribution_weight = 0.3                       # 保持稳定\n",
    "response_weight = min(0.0 + progress*0.5, 0.5)  # 从0.0逐渐增至0.5\n",
    "\n",
    "# 计算加权损失\n",
    "loss = feature_weight*feature_loss + distribution_weight*distribution_loss + response_weight*response_loss\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7ae7d2",
   "metadata": {},
   "source": [
    "## 2.9 场景应用建议\n",
    "\n",
    "### 大型通用模型蒸馏 (如70B→7B)\n",
    "**推荐**：混合渐进式蒸馏，从特征级到响应级\n",
    "- **阶段1**：90%特征级，10%分布级，0%响应级\n",
    "- **阶段2**：50%特征级，40%分布级，10%响应级\n",
    "- **阶段3**：20%特征级，50%分布级，30%响应级\n",
    "- **理由**：规模差距大，需要先建立坚实基础表示，再优化输出\n",
    "\n",
    "### 专业领域模型蒸馏 (如法律/医疗模型)\n",
    "**推荐**：混合渐进式蒸馏，从特征级到响应级，但保持分布级权重较高\n",
    "- **阶段1**：70%特征级，30%分布级，0%响应级\n",
    "- **阶段2**：30%特征级，60%分布级，10%响应级\n",
    "- **阶段3**：10%特征级，60%分布级，30%响应级\n",
    "- **理由**：专业领域需要准确的词汇分布和内部表示，分布级蒸馏权重应保持较高\n",
    "\n",
    "\n",
    "### 资源受限场景 (小团队/有限算力)\n",
    "**推荐**：简化的混合蒸馏，固定权重\n",
    "- **固定权重**：30%特征级，50%分布级，20%响应级\n",
    "- **简化策略**：只选择关键层进行特征级蒸馏\n",
    "- **理由**：简化训练流程，避免复杂的阶段转换，平衡各方面能力\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337636e",
   "metadata": {},
   "source": [
    "# 3.蒸馏数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ceeb336",
   "metadata": {},
   "source": [
    "## 3.1 数据引导思维模式平衡"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7f0d28",
   "metadata": {},
   "source": [
    "想象你有两位教师：一位是数学教授，总是一步步详细推导；另一位是百科全书专家，直接给出简洁答案。现在你想让一个学生同时学会这两种回答方式。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e5a77e",
   "metadata": {},
   "source": [
    "## 为什么单一数据类型不够？\n",
    "\n",
    "### 如果只用CoT（推理）数据：\n",
    "\n",
    "想象你只向学生展示数学教授的教学：\n",
    "\n",
    "```\n",
    "问题：12 × 15 是多少？\n",
    "思考：我可以拆分计算。\n",
    "12 × 10 = 120\n",
    "12 × 5 = 60\n",
    "120 + 60 = 180\n",
    "所以答案是180。\n",
    "```\n",
    "\n",
    "**结果会怎样？**\n",
    "学生会学到：**对每个问题都必须展示步骤**。\n",
    "\n",
    "当有人问\"今天星期几？\"时，学生可能回答：\n",
    "```\n",
    "思考：今天是2023年10月20日。\n",
    "一周有7天。\n",
    "10月1日是星期日。\n",
    "从10月1日到10月20日有19天。\n",
    "19 ÷ 7 = 2余5。\n",
    "所以今天是星期五。\n",
    "```\n",
    "\n",
    "这种回答方式对简单问题显得**过度复杂且浪费时间**。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52272782",
   "metadata": {},
   "source": [
    "\n",
    "### 如果只用常规SFT（直接回答）数据：\n",
    "\n",
    "想象你只向学生展示百科全书专家的教学：\n",
    "\n",
    "```\n",
    "问题：为什么天空是蓝色的？\n",
    "答案：因为空气分子散射阳光中的蓝色波长。\n",
    "```\n",
    "\n",
    "**结果会怎样？**\n",
    "学生会学到：**所有问题都直接给出结论**。\n",
    "\n",
    "当遇到复杂问题时，如\"评估全球暖化的长期经济影响\"，学生可能只给出简单结论：\n",
    "```\n",
    "全球暖化的长期经济影响预计为负面的，可能导致全球GDP下降5-20%。\n",
    "```\n",
    "\n",
    "这种回答**缺乏推理支持**，无法建立可信度，也不展示思考过程。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba4216",
   "metadata": {},
   "source": [
    "\n",
    "### CoT数据与常规SFT数据的混合必要性\n",
    "\n",
    "1. **能力全面传递**：\n",
    "   - CoT数据（包含推理过程）让教师模型展示推理能力\n",
    "   - 常规SFT数据（直接回答）帮助学生模型学习简洁输出能力\n",
    "\n",
    "2. **平衡推理与效率**：\n",
    "   - 纯CoT数据会使学生模型总是生成冗长推理，即使简单问题\n",
    "   - 纯常规SFT会使学生无法学习复杂推理能力\n",
    "   \n",
    "3. **适应不同问题类型**：\n",
    "   - 简单问题适合直接回答\n",
    "   - 复杂问题需要推理过程\n",
    "   - 混合数据帮助模型学会判断何时使用推理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6338602",
   "metadata": {},
   "source": [
    "\n",
    "## 3.2 混合数据的好处\n",
    "\n",
    "1. **推理能力的灵活应用**：\n",
    "   - 学生模型学会何时展开推理，何时直接回答\n",
    "   - 避免对所有问题都使用相同模式回答\n",
    "\n",
    "2. **更好的泛化能力**：\n",
    "   - 不同类型数据增强模型对各种场景的适应性\n",
    "   - 防止模型过度拟合单一回答方式\n",
    "\n",
    "3. **更平衡的输出控制**：\n",
    "   - 学习判断推理过程需要多详细\n",
    "   - 理解何时可以省略中间步骤\n",
    "\n",
    "4. **用户体验优化**：\n",
    "   - 简单问题给出简洁回答，提高效率\n",
    "   - 复杂问题展示推理过程，增强可信度\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ddae4d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 1. 学习\"何时推理\"的判断能力\n",
    "\n",
    "混合数据教会模型识别**哪类问题需要推理**：\n",
    "\n",
    "```\n",
    "简单问题：巴黎是哪个国家的首都？\n",
    "教师回答：法国。\n",
    "\n",
    "复杂问题：如何评估一个公司的财务健康状况？\n",
    "教师回答：评估公司财务健康需要分析几个关键指标：\n",
    "1. 流动比率：检查短期偿债能力...\n",
    "2. 资产负债率：评估长期财务风险...\n",
    "[详细推理过程]\n",
    "综合以上分析，可以得出该公司财务状况的结论。\n",
    "```\n",
    "\n",
    "通过这种混合示例，学生模型学会判断：\n",
    "- 事实性问题 → 直接回答\n",
    "- 分析性问题 → 展开推理\n",
    "\n",
    "### 2. 学习领域特定的推理需求\n",
    "\n",
    "不同领域问题需要不同推理深度：\n",
    "\n",
    "```\n",
    "法律问题：这个合同条款有效吗？\n",
    "教师回答：[详细法律分析，引用判例和法规]\n",
    "\n",
    "日常问题：今天适合户外活动吗？\n",
    "教师回答：天气预报显示今天有雨，所以不适合户外活动。\n",
    "```\n",
    "\n",
    "混合数据让模型学会：\n",
    "- 专业/关键领域 → 需要详细推理\n",
    "- 日常/简单咨询 → 简洁实用回答足够\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e7c40c",
   "metadata": {},
   "source": [
    "\n",
    "## 3.3 混合方式建议\n",
    "\n",
    "### 1. 梯度混合法\n",
    "\n",
    "根据问题复杂度渐进混合，而非简单二分：\n",
    "\n",
    "- **一步回答**：最简单的直接答案 (25%)\n",
    "- **简单推理**：1-2步简单推理 (35%)\n",
    "- **中等推理**：3-5步中等推理 (25%)\n",
    "- **深度推理**：6步以上详细推理 (15%)\n",
    "\n",
    "这种分布能更好地模拟现实中问题的复杂度分布。\n",
    "\n",
    "### 2. 领域适应混合\n",
    "\n",
    "根据不同领域调整混合比例：\n",
    "\n",
    "- **数学/逻辑领域**：80% CoT + 20% 直接回答\n",
    "- **常识/事实领域**：30% CoT + 70% 直接回答\n",
    "- **分析/评估领域**：60% CoT + 40% 直接回答\n",
    "- **建议/推荐领域**：50% CoT + 50% 直接回答\n",
    "\n",
    "### 3. 目标用户导向混合\n",
    "\n",
    "根据最终用户调整：\n",
    "\n",
    "- **专业用户**：详细推理占比更高 (65-75% CoT)\n",
    "- **普通用户**：简洁回答占比更高 (40-50% CoT)\n",
    "- **教育场景**：梯度分布，兼顾简单和复杂推理\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f52a75",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### 示例：法律咨询混合数据集\n",
    "```\n",
    "// CoT样本\n",
    "问题：我租的公寓有漏水问题，房东不修，我可以扣房租吗？\n",
    "分析：\n",
    "1. 首先，需要确认租赁合同中关于维修责任的条款。\n",
    "2. 大多数租赁法规定，房东有责任维持房屋的适居性。\n",
    "3. 漏水问题可能影响适居性，属于房东的维修责任范围。\n",
    "4. 在通知房东后，如果房东仍不维修，许多司法管辖区允许：\n",
    "   a) 自行修理并扣除合理费用\n",
    "   b) 在严重情况下扣留部分房租\n",
    "5. 但必须遵循正确的法律程序，如书面通知和合理时间等。\n",
    "结论：可能可以扣房租，但需遵循当地法规规定的正确程序，建议先发出书面通知，给予合理时间，并保留所有通信记录。\n",
    "\n",
    "// 直接回答样本\n",
    "问题：美国总统任期是几年？\n",
    "答案：美国总统任期是4年。\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31653e48",
   "metadata": {},
   "source": [
    "## 3.4 数据来源"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f7b7cf2",
   "metadata": {},
   "source": [
    "人民法院案例库 https://rmfyalk.court.gov.cn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d5ed5f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425171349158.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2130953c",
   "metadata": {},
   "source": [
    "http://cail.cipsc.org.cn/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec31b76",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425171545771.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93def45c",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425171646974.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf78b56a",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425171712211.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "206e2879",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425171747412.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996de5ff",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425171854323.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2f1895",
   "metadata": {},
   "source": [
    "https://github.com/LawRefBook/Laws/tree/master"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "656fce0b",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425175701207.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d5ebd6",
   "metadata": {},
   "source": [
    "综合数据集下载 https://github.com/thunlp/CAIL?tab=readme-ov-file   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f6b0be",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250513152140721.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "762e5091",
   "metadata": {},
   "source": [
    "restDate 数据样例 {\"meta\": {\"relevant_articles\": [\"234\"], \"term_of_imprisonment\": {\"life_imprisonment\": false, \"death_penalty\": false, \"imprisonment\": 18}, \"punish_of_money\": 0, \"criminals\": [\"陈某\"], \"accusation\": [\"故意伤害\"]}, \"fact\": \"淄博市张店区人民检察院指控，2013年10月21日8时许，被告人张某、张2某、陈某受栾某（已判刑）指使，对刘某实施殴打致刘某伤情构成轻伤二级。被告人陈某的行为构成××，公诉机关并向本院移送了相关证据，请求本院依照《中华人民共和国刑法》××××的规定，追究被告人陈某的刑事责任。\\r\\n\"}  \n",
    "\n",
    "exercise_contest data_train.json 样例\n",
    "{\"fact\": \"天水市麦积区人民检察院指控称，2014年3月17日19时30分许，被告人王XX与王X在天水市麦积区花牛镇罗家沟租住房内酒后因琐事发生争吵，后王X打电话叫来其子王某，王某与王XX发生争吵，争吵后王X和王某回到社棠镇下曲村李某家的小卖部，王XX持菜刀追至李某小卖部质问王X并用刀砍王X，王某在阻挡及夺刀过程中被刀割伤。经天水市麦积区公安司法鉴定中心鉴定：王某双手部软组织创累计达18.2CM属轻伤二级。公诉机关就其指控提供了相应证据，认为被告人王XX的行为触犯了《中华人民共和国刑法》××××之规定，构成××罪。建议判处被告人王XX一年至两年××。\", \"meta\": {\"relevant_articles\": [234], \"accusation\": [\"故意伤害\"], \"punish_of_money\": 0, \"criminals\": [\"王XX\"], \"term_of_imprisonment\": {\"death_penalty\": false, \"imprisonment\": 18, \"life_imprisonment\": false}}}   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7abdb2",
   "metadata": {},
   "source": [
    "法律问答数据集   https://www.heywhale.com/mw/dataset/5e953ca8e7ec38002d02fca7/file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e90420",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425174820138.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ee3656",
   "metadata": {},
   "source": [
    "内容包括856项罪名知识图谱, 基于280万罪名训练库的罪名预测,基于20W法务问答对的13类问题分类与法律资讯问答功能  \n",
    " https://github.com/liuhuanyong/CrimeKgAssitant"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "675dc285",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425170837601.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e799099",
   "metadata": {},
   "source": [
    "{ \"_id\" : { \"$oid\" : \"5be5530d831b9724178d9d97\" }, \"crime_big\" : \"危害国家安全罪\", \"crime_small\" : \"分裂国家罪\", \"crime_link\" : \"http://china.findlaw.cn/zuiming/1_57.html\", \"gainian\" : [ \"所谓分裂国家罪，是指组织、策划、实施分裂国家、破坏国家统一，或者与境外的机构、组织、个人相勾结，组织、策划、实施分裂国家、破坏国家统一的行为。本罪只能由直接故意构成，即行为人明知自己的行为会造成分裂国家、破坏国家统一的结果，并积极追求这种结果发生。背叛国家罪在主观方面既可以由直接故意构成，也可以由间接故意构成，即行为人明知自己的行为会发生分裂国家、破坏国家统一的危害结果，并且希望或者放任这种结果发生。\" ], \"tezheng\" : [ \"分裂国家罪的客体要件\", \"本罪侵犯的客体是人民民主专政的政权和社会主义制度。\", \"分裂国家罪的客观要件\", \"本罪在客观方面表现为组织、策划、实施分裂国家、破坏国家统一的行为。所谓组织，是指为分裂国家而安排分散的人使之具有一定的系统性和整体性。组织既包括预备过程中的组织，也包括实施过程中的组织。所谓策划。是指为分裂国家而暗中密谋、策划，实际上是处于一种犯罪预备的状态。所谓实施，是指已经着手，个人或有组织地将策划的内容付诸行动。组织、策划、实施是分裂国家行为的不同形式及发展阶段，都属于法律明确规定的程度不同的实行行为。所谓分裂国家，是指破坏多民族国家的统一，其表现形式主要有两种:一是挑拨民族关系，制造民族动乱，搞民族分裂，破坏各民族的团结和国家的统一;二是搞地方割据，另立伪政府，抗拒中央的领导，破坏国家的统一。破坏国家统一是分裂国家的一种特殊形式或结果，分裂国家则是破坏国家统一的行为手段。分裂国家的手段多种多样，不论此种行为是否造成危害结果，只要行为人具有组织、策划、实施分裂国家、破坏国家统一的活动事实，就构成犯罪。\", \"分裂国家罪的主体要件\", \"本罪的主体是一般主体，凡达到法定刑事责任年龄、具有刑事责任能力的自然人均可成为本罪主体。但在实际中，实施这种行为的，一般是那些在中央和地方窃据党、政、军重要职位的野心家、阴谋家和反动的民族主义者。\", \"分裂国家罪的主观要件\", \"本罪在主观方面表现为故意，即明知组织、策划、实施分裂国家、破坏国家统一而希望或放任结果的发生。\" ], \"rending\" : [ \"(一)分裂国家罪与背叛国家罪的界限\", \"分裂国家罪与背叛国家罪在构成要件及其表现形式上存在着许多相似甚至相同之处，如它们侵犯的同类客体都是国家安全，其直接客体都牵涉到国家的领土完整与安全;它们在客观方面都可能与境外的机构、组织或者个人勾结，并且都以法定危害行为的实行而不以发生危害国家安全的结果作为犯罪成立的要件;它们在主观方面都是出于直接故意，并且这种故意都是就危害行为本身的态度而言的。但他们也具有原则性的不同：\", \"(1)就犯罪侵犯的直接客体而言，本罪侵犯的直接客体是国家的统一，而背叛国家罪侵犯的直接客体则是国民对其国家的效忠义务。虽然这两种犯罪都涉及到对国家领土完整的危害，但本罪对国家领土的危害，不是将我国的一部分领土分离出去，领土和国家的主权与安全并没有落入外国之手，而是制造地方“独立”的割据局面，这实质上是以破坏国家统一的方式危害国家安全，就此而言，分裂国家罪属于“内忧”;而背叛国家罪对国家领土的危害，则是勾结外国，或者与境外的机构、组织、个人相勾结，背离自己效忠国家的义务而向外国出卖国家主权、出让国家领土，或者策划外国向我国发动战争，侵占我国领土，这实质上是以出卖国家主权、出让国家领土或者破坏国家领土安全的方式而危害国家。就此而言，背叛国家罪属于“外患”。\", \"(2)就犯罪的客观方面而言，这两种犯罪也有两点不同：首先，本罪不要求将“勾结外国”或者“与境外的机构、组织、个人相勾结”作为要件，即行为人是否勾结外国，或者是否与境外的机构、组织、个人相勾结，并不影响本罪的成立。而背叛国家罪缺乏“勾结外国”或者“与境外的机构、组织、个人相勾结”则无以成立犯罪;其次，在犯罪的行为表现方式和内容上，本罪是通过将中华人民共和国的一部分领土分离出去，脱离中央政府的领导，制造地方“独立”的割据局面而危害国家的领土完整，是以对国家统一和完整的侵害而危害国家安全。而背叛国家罪则是通过勾结外国，或者与境外的机构、组织、个人相勾结，以对国家主权、领土完整和安全的侵害而危害国家安全。\", \"(3)就犯罪主体而言，本罪属于一般主体，即只要年满16周岁、具有刑事责任能力，不管是中国公民，还是外国人、无国籍人，都可以成立本罪。并且，本罪只能由多数人构成，属必要共犯;而背叛国家罪的犯罪主体只能是年满16周岁、具有刑事责任能力的中国公民，并且单独的个人仍然可以构成本罪。\", \"(4)就主观故意的内容而言，本罪的行为人具有分裂国家、破坏国家统一的直接故意，即认识到自己的行为是分裂国家、破坏国家统一而积极实施;而背叛国家罪的行为人则具有危害国家主权、领土完整与安全的直接故意，即认识到自己的行为是勾结外国，或者与境外的机构、组织、个人相勾结而危害国家主权、领土完整和安全而积极实施。\", \"(二)分裂国家罪与煽动分裂国家罪的界限\", \"作为均以分裂国家为其最终目的的犯罪行为，煽动分裂国家罪是指以语言、文字、图画或者其他方式，鼓动、刺激、怂恿、引诱、激励他人实施分裂国家、破坏国家统一的行为，它与分裂国家罪在表现形式上有许多相似甚至相同之处，如它们侵犯的同类客体都是国家安全，其直接客体都是国家的统一;它们都以法定危害行为的实行而不以为危害国家安全的结果作为犯罪成立的要件;它们在主观方面都是出于直接故意，并且这种故意都是就危害行为本身而非其行为结果的态度而言的;它们的最终目的都是分裂国家、破坏国家统一。从行为之间的关系而言，煽动分裂国家的行为属于分裂国家的教唆或者帮助行为，如果刑法不另行设立煽动分裂国家罪，其煽动行为得以分裂国家罪的共犯论处，但既然刑法已将其规定为一种独立的犯罪行为，它与分裂国家罪即具有原则性的不同：\", \"(1)就客观方面的行为方式而言，本罪是指组织、策划、实施分裂国家、破坏国家统一，或者与境外的机构、组织、个人相勾结，组织、策划、实施分裂国家、破坏国家统一;而煽动分裂国家罪的行为方式系通过语言、文字、图象、网络或者其他方式煽动他人实施分裂国家、破坏国家统一，使没有分裂国家意图的人产生分裂国家的犯罪决意，或者刺激、助长、坚定其已产生的分裂国家的犯罪决意。煽动者并不需要亲自实施分裂国家的行为，被煽动者是否接受煽动从而实施分裂国家、破坏国家统一的行为，并不影响煽动分裂国家罪的成立。同时，此处的“煽动”应当排除分裂国家罪中的“组织”、“策划”行为中所包容的“煽动”内容，因为有时候的组织、策划分裂国家的行为也是以煽动分裂国家的行为为内容的。\", \"(2)就犯罪主体而言，分裂国家罪既包括首要分子和罪行重大者，又包括积极参加者和其他参加者;而煽动分裂国家罪仅仅包括首要分子和罪行重大者，并不处罚其他参加者，甚至积极参加者亦不构成煽动分裂国家罪。这是因为，煽动分裂国家罪仅仅是分裂国家罪的教唆或者帮助行为，如果属于首要分子和罪行重大者，应当予以刑事处罚;如果系其他参加者，则由于其社会危害性尚未达到应受刑罚处罚的程度，因而刑法不予干涉。\", \"(3)就故意的内容而言，本罪的行为人具有分裂国家、破坏国家统一的直接故意，即认识到自己的行为是组织、策划、实施分裂国家、破坏国家统一并积极而为;而煽动分裂国家罪的行为人所具有的仅仅是煽动他人分裂国家的直接故意，即认识到自己的行为是在煽动他人分裂国家而积极实施，并无具体的分裂国家的法定行为，即认识到自己的行为是在引起他人实施分裂国家的具体行为，并且希望和积极促成该行为的完成。\" ], \"chufa\" : [ \"根据《刑法》第103、113条的规定，犯本罪的处理：\", \"1、对首要分子或者罪行重大的，处无期徒刑或者10年以上有期徒刑;\", \"2、对于积极参加的，处3年以上10年以下有期徒刑;\", \"3、对其他参加的，处3年以下有期徒刑、拘役、管制或者剥夺政治权利;\", \"4、对国家和人民危害特别严重、情节特别恶劣的，可以判处死刑。本罪可以并处没收财产。\" ], \"fatiao\" : [ \"[刑法条文]\", \"第一百零二条勾结外国，危害中华人民共和国的主权、领土完整和安全的，处无期徒刑或者十年以上有期徒刑。\", \"与境外机构、组织、个人相勾结，犯前款罪的，依照前款的规定处罚。\", \"第一百零三条组织、策划、实施分裂国家、破坏国家统一的，对首要分子或者罪行重大的，处无期徒刑或者十年以上有期徒刑;对积极参加的，处三年以上十年以下有期徒刑;对其他参加的，处三年以下有期徒刑、拘役、管制或者剥夺政治权利。\", \"煽动分裂国家、破坏国家统一的，处五年以下有期徒刑、拘役、管制或者剥夺政治权利;首要分子或者罪行重大的，处五年以上有期徒刑。\", \"第一百零六条与境外机构、组织、个人相勾结，实施本章第一百零三条、第一百零四条、第一百零五条规定之罪的，依照各该条的规定从重处罚。\", \"第一百一十三条本章上述危害国家安全罪行中，除第一百零三条第二款、第一百零五条、第一百零七条、第一百零九条外，对国家和人民危害特别严重、情节特别恶劣的，可以判处死刑。\", \"犯本章之罪的，可以并处没收财产。\" ], \"jieshi\" : [ \"[司法解释]\", \"最高人民法院、最高人民检空院《关于办理组织和利用邪教组织犯罪案件具体应用法律若干问题的解释》(1999、10、20法释099们19号)\", \"第一条刑法第三百条中的“邪教组织”，是指冒用宗教、气功或者其他名义建立，神化首要分子，利用制造、散布迷信邪说等手段蛊惑、蒙骗他人，发展、控制成员，危害社会的非法组织。\", \"第七条组织和利用邪教组织，组织、策划、实施、煽动分裂国家、破坏国家统一或者颠覆国家政权、推翻社会主义制度的，分别依照刑法第一百零三条、第一百零五条、第一百一十三条的规定定罪处罚。\", \"第八条对于邪教组织和组织、利用邪教组织破坏法律实施的犯罪分子，以各种手段非法聚敛的财物，用于犯罪的工具、宣传品等，应当依法追缴、没收。\", \"第九条对组织和利用邪教组织进行犯罪活动的组织、策划、指挥者和屡教不改的积极参加者，依照刑法和本解释的规定追究刑事责任;对有自首、立功表现的，可以依法从轻、减轻或者免除处罚。对于受蒙蔽、胁迫参加邪教组织并已退出和不再参加邪教组织活动的人员，不作为犯罪处理。\", \"《刑法》第一百零六条与境外机构、组织、个人相勾结，实施本章第一百零三条、第一百零四条、第一百零五条规定之罪的，依照各该条的规定从重处罚。\", \"《国家安全法》第二十五条在境外受胁迫或者受诱骗参加敌对组织，从事危害中华人民共和国国家安全的活动，及时向中华人民共和国驻外机构说明情况的，或者入境后，直接或者通过所在组织及时向\", \"国家安全机关或者公安机关如实说明情况的，不予追究。\" ], \"bianhu\" : [] }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409b1a2f",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250427105824422.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07dc01f",
   "metadata": {},
   "source": [
    "样例数据 { \"_id\" : { \"$oid\" : \"5be66fd7831b972eb70270c4\" }, \"question\" : \"才刚刚入股应该怎么样退股呢！怎样才对自己有利益呢\", \"answers\" : [ \"要看具体的协议约定。\", \"要看具体的公司章程，公司的话，一般很难退，只能转让\", \"法律上只能股权转让，不存在随意退股的说法\" ], \"category\" : \"公司法\" }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7db80f5e",
   "metadata": {},
   "source": [
    "法律问答对可以二次构建 https://aistudio.baidu.com/datasetdetail/89457"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ada98bb",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250425190010772.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef08fdfd",
   "metadata": {},
   "source": [
    "数据样例数据全部为单独json文件 {\"answer\": \"你好，你可以与你老婆先协议离婚，协议不成可以到法院去起诉离婚。\", \"candidate_answer\": [\"你可以与你老婆先协议离婚，协议不成可以到法院去起诉离婚\", \"那就起诉，可以***咨询我\", \"可以起诉\"], \"cause\": \"婚姻家庭\", \"question\": \"我想离婚了，我老婆不愿意生孩子我觉得没意思\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0acad79",
   "metadata": {},
   "source": [
    "## 3.5 COT数据处理"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c70a1f9",
   "metadata": {},
   "source": [
    "优先处理CAIL_2018_ALL_DATA数据集，将案例转换成问题，当前使用的是deepseekv3，大家可以根据自己的需求进行调整。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "794eb90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json  # 用于处理JSON数据\n",
    "import os  # 用于文件系统操作\n",
    "import re  # 用于正则表达式匹配\n",
    "import time  # 用于计时和延迟\n",
    "import threading  # 用于多线程操作\n",
    "import datetime  # 用于日期时间处理\n",
    "from concurrent.futures import ThreadPoolExecutor  # 用于并行执行任务\n",
    "from typing import Dict, Any, Optional  # 用于类型注解\n",
    "from tqdm.notebook import tqdm  # 用于在Jupyter notebook中显示进度条\n",
    "from openai import OpenAI  # OpenAI API客户端\n",
    "\n",
    "# 全局配置变量\n",
    "INPUT_FILE_PATH = None  # 输入文件路径，包含原始法律案例数据\n",
    "OUTPUT_FILE_PATH = None  # 输出文件路径，用于保存生成的CoT数据\n",
    "API_KEY = None  # OpenAI API密钥\n",
    "MAX_SAMPLES = None  # 最大处理样本数量\n",
    "MAX_WORKERS = None  # 最大并行线程数\n",
    "client = None  # OpenAI客户端实例\n",
    "\n",
    "# 创建写入文件的锁，用于多线程安全写入文件\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "# 定义全局计数器，用于统计处理状态\n",
    "processed = 0  # 已处理案例总数\n",
    "successful = 0  # 成功生成CoT数据的案例数\n",
    "\n",
    "# 新增参数，用于控制处理特定范围的数据\n",
    "START_INDEX = 0  # 起始索引，从哪个案例开始处理\n",
    "END_INDEX = None  # 结束索引，处理到哪个案例结束，None表示处理到末尾\n",
    "\n",
    "def generate_legal_cot(case_data: Dict[str, Any]) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    使用DeepSeek模型生成完整的法律CoT分析\n",
    "    \n",
    "    参数:\n",
    "        case_data: 包含案例信息的字典\n",
    "        \n",
    "    返回:\n",
    "        成功时返回包含input(问题)和output(思考过程和答案)的字典\n",
    "        失败时返回None\n",
    "    \"\"\"\n",
    "    global client  # 使用全局OpenAI客户端\n",
    "    \n",
    "    try:\n",
    "        # 提取案例元数据\n",
    "        meta = case_data.get(\"meta\", {})  # 获取元数据，默认为空字典\n",
    "        criminals = \", \".join(meta.get(\"criminals\", []))  # 拼接被告人列表\n",
    "        accusation = \", \".join(meta.get(\"accusation\", []))  # 拼接指控罪名\n",
    "        articles = \", \".join(meta.get(\"relevant_articles\", []))  # 拼接相关法条\n",
    "        fact = case_data.get(\"fact\", \"\")  # 获取案件事实描述\n",
    "        \n",
    "        # 获取刑期信息\n",
    "        imprisonment_info = meta.get(\"term_of_imprisonment\", {})\n",
    "        imprisonment = imprisonment_info.get(\"imprisonment\", 0)  # 获取有期徒刑月数\n",
    "        life_imprisonment = imprisonment_info.get(\"life_imprisonment\", False)  # 是否无期徒刑\n",
    "        death_penalty = imprisonment_info.get(\"death_penalty\", False)  # 是否死刑\n",
    "        \n",
    "        # 格式化刑期信息为可读文本\n",
    "        if life_imprisonment:\n",
    "            sentence = \"无期徒刑\"\n",
    "        elif death_penalty:\n",
    "            sentence = \"死刑\"\n",
    "        else:\n",
    "            sentence = f\"{imprisonment}个月有期徒刑\"\n",
    "        \n",
    "        # 构建提示词，指导DeepSeek模型生成CoT数据\n",
    "        # 提示词包含案件信息、任务要求和质量标准\n",
    "        prompt = f\"\"\"你是中国最优秀的刑事法律专家，需要将以下案例转换为\"思维链\"(Chain-of-Thought)推理格式的教学案例。\n",
    "        \n",
    "【案件信息】\n",
    "被告人: {criminals}\n",
    "指控罪名: {accusation}\n",
    "相关法条: 第{articles}条\n",
    "判决结果: {sentence}\n",
    "罚金: {meta.get('punish_of_money', 0)}元\n",
    "\n",
    "【案件事实】\n",
    "{fact}\n",
    "\n",
    "请执行以下任务：\n",
    "\n",
    "1. 首先，必须依据案件事实{fact}生成一个详细的法律问题，作为思维链数据的输入部分，问题生成后追加@@@字符。\n",
    "   - 问题必须包含案件的主要事实、被告人身份和主要行为\n",
    "   - 问题中需要根据明确提及涉案金额、犯罪手段、时间地点等关键信息\n",
    "   - 问题应当明确提出关于罪名认定和量刑适当性的法律疑问\n",
    "   - 确保问题足够详细，以支持后续思考过程的全部推理\n",
    "   - 确保问题生成后必须追加@@@字符\n",
    "\n",
    "2. 然后，生成严格基于问题中提及信息的思考过程，必须放在<think>和</think>标签之间。\n",
    "   - 思考过程只能使用问题中明确提及的信息进行分析，不得引入上边生成问题中未包含的事实\n",
    "   - 必须按照以下结构进行分析：\n",
    "     1. 犯罪构成要件分析（客观要件(行为、结果、因果关系等)和主观要件(犯罪故意或过失)）\n",
    "     2. 相关法条适用分析\n",
    "     3. 量刑情节分析（包括从轻、从重情节）\n",
    "     4. 判决适当性评价\n",
    "   - 每一步分析必须有明确依据，避免模糊推断\n",
    "\n",
    "3. 最后，给出对问题的明确解答，直接放在思考标签之后。\n",
    "   - 解答必须包含对罪名认定的明确结论\n",
    "   - 必须明确说明判决是否适当及理由\n",
    "   - 答案应包含案件关键特征，如犯罪性质、情节和法律依据\n",
    "\n",
    "质量要求：\n",
    "- 确保思考过程和结论仅使用问题中提供的信息\n",
    "- 问题、思考过程和答案必须在内容上完全一致，不能出现互相矛盾的说法\n",
    "- 避免在思考过程中使用问题中没有的信息填补逻辑空白\n",
    "- 如果案件信息不足以支持某项结论，应在思考中指出而非自行补充假设信息\"\"\"\n",
    "\n",
    "        # 调用DeepSeek API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",  # 使用deepseek-chat模型\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],  # 提供提示词\n",
    "            temperature=0.7  # 控制生成文本的随机性\n",
    "        )\n",
    "        \n",
    "        # 获取API返回的文本内容\n",
    "        full_response = response.choices[0].message.content.strip()\n",
    "        \n",
    "        # 解析生成的内容\n",
    "        # 首先按照@@@分割问题和其他内容\n",
    "        parts = full_response.split(\"@@@\", 1)\n",
    "        \n",
    "        if len(parts) >= 2:\n",
    "            # 如果成功分割，前部分为问题，后部分为思考和答案\n",
    "            question = parts[0].strip()\n",
    "            remaining = parts[1].strip()\n",
    "        else:\n",
    "            # 如果未能按@@@分割，使用简单策略提取问题\n",
    "            question = full_response[:200].strip()  # 取前200字符作为问题\n",
    "            remaining = full_response\n",
    "        \n",
    "        # 提取思考过程和最终答案\n",
    "        # 使用正则表达式匹配<think>标签内的内容\n",
    "        think_pattern = r\"<think>(.*?)</think>\"\n",
    "        think_match = re.search(think_pattern, remaining, re.DOTALL)\n",
    "        \n",
    "        if think_match:\n",
    "            # 如果找到思考标签\n",
    "            think_content = think_match.group(1).strip()  # 提取标签内的思考内容\n",
    "            \n",
    "            # 提取思考标签外的内容作为答案\n",
    "            remaining_parts = re.split(r\"<think>.*?</think>\", remaining, flags=re.DOTALL)\n",
    "            answer_parts = [part for part in remaining_parts if part.strip()]\n",
    "            \n",
    "            if answer_parts:\n",
    "                # 拼接所有答案部分\n",
    "                answer = \"\\n\".join(answer_parts).strip()\n",
    "            else:\n",
    "                # 如果没有标签外内容，生成一个简短答案\n",
    "                answer = \"基于以上分析，被告人的行为构成了所指控的罪名，判决合理。\"\n",
    "        else:\n",
    "            # 如果没有找到思考标签，尝试智能拆分内容\n",
    "            parts = remaining.split(\"\\n\\n\")\n",
    "            if len(parts) >= 2:\n",
    "                # 将内容按空行分割，取前80%作为思考，后20%作为答案\n",
    "                split_point = int(len(parts) * 0.8)\n",
    "                think_content = \"\\n\\n\".join(parts[:split_point]).strip()\n",
    "                answer = \"\\n\\n\".join(parts[split_point:]).strip()\n",
    "            else:\n",
    "                # 如果无法按段落分割，简单按字符长度比例拆分\n",
    "                split_point = int(len(remaining) * 0.8)\n",
    "                think_content = remaining[:split_point].strip()\n",
    "                answer = remaining[split_point:].strip()\n",
    "        \n",
    "        # 清理可能的markdown格式和多余空行\n",
    "        # 移除问题和答案开头的标题符号(#)\n",
    "        question = re.sub(r'^[#]+\\s*', '', question)\n",
    "        answer = re.sub(r'^[#]+\\s*', '', answer)\n",
    "        \n",
    "        # 确保问题内容充足且以问号结尾\n",
    "        if not (question.endswith('?') or question.endswith('？')):\n",
    "            if '?' in question or '？' in question:\n",
    "                # 找到第一个问号所在句子作为问题\n",
    "                pattern = r'([^.!?。！？]*[?？])'\n",
    "                match = re.search(pattern, question)\n",
    "                if match:\n",
    "                    question = match.group(0).strip()\n",
    "            else:\n",
    "                # 如果没有问号，添加一个\n",
    "                question += \"？\"\n",
    "        \n",
    "        # 构建最终输出格式\n",
    "        output = f\"<think>{think_content}</think>\\n\\n{answer}\"\n",
    "        \n",
    "        # 移除多余空行，保持最多两个连续空行\n",
    "        output = re.sub(r'\\n{3,}', '\\n\\n', output)\n",
    "        \n",
    "        # 返回最终的问题-思考-答案字典\n",
    "        return {\n",
    "            \"input\": question,  # 问题作为输入\n",
    "            \"output\": output    # 思考和答案作为输出\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        # 异常处理\n",
    "        print(f\"\\n生成COT数据时出错: {str(e)}\")\n",
    "        time.sleep(1)  # 简单延迟，避免连续错误请求\n",
    "        return None  # 返回None表示处理失败\n",
    "\n",
    "def process_case(case, pbar=None):\n",
    "    \"\"\"\n",
    "    处理单个案例并更新进度\n",
    "    \n",
    "    参数:\n",
    "        case: 案例数据\n",
    "        pbar: 进度条对象，用于显示进度\n",
    "        \n",
    "    返回:\n",
    "        布尔值，表示处理是否成功\n",
    "    \"\"\"\n",
    "    global processed, successful  # 使用全局计数器\n",
    "    \n",
    "    # 调用函数生成CoT数据\n",
    "    result = generate_legal_cot(case)\n",
    "    \n",
    "    if result:\n",
    "        # 如果成功生成CoT数据\n",
    "        # 安全写入文件，使用锁确保多线程安全\n",
    "        with file_lock:\n",
    "            with open(OUTPUT_FILE_PATH, 'a', encoding='utf-8') as f:\n",
    "                # 写入JSON行\n",
    "                f.write(json.dumps(result, ensure_ascii=False) + '\\n')\n",
    "                f.flush()  # 立即写入磁盘\n",
    "        \n",
    "        # 更新计数器\n",
    "        with file_lock:\n",
    "            processed += 1  # 已处理计数+1\n",
    "            successful += 1  # 成功计数+1\n",
    "            \n",
    "            # 更新进度条\n",
    "            if pbar:\n",
    "                pbar.update(1)  # 进度条前进一步\n",
    "                pbar.set_postfix(成功=successful)  # 显示成功数量\n",
    "    else:\n",
    "        # 处理失败时只更新已处理计数\n",
    "        with file_lock:\n",
    "            processed += 1\n",
    "            if pbar:\n",
    "                pbar.update(1)\n",
    "                pbar.set_postfix(成功=successful)\n",
    "    \n",
    "    # 返回处理结果，True表示成功，False表示失败\n",
    "    return result is not None\n",
    "\n",
    "def generate_legal_cot_dataset(start_index=0, end_index=None):\n",
    "    \"\"\"\n",
    "    主函数：处理法律案例数据集\n",
    "    \n",
    "    参数:\n",
    "        start_index: 起始索引，从哪个案例开始处理\n",
    "        end_index: 结束索引，处理到哪个案例结束\n",
    "        \n",
    "    返回:\n",
    "        成功生成的CoT数据数量\n",
    "    \"\"\"\n",
    "    global client, processed, successful  # 使用全局变量\n",
    "    \n",
    "    # 重置计数器\n",
    "    processed = 0\n",
    "    successful = 0\n",
    "    \n",
    "    # 记录开始时间，用于计算总耗时\n",
    "    start_time = time.time()\n",
    "    print(f\"开始处理: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    \n",
    "    # 初始化OpenAI客户端\n",
    "    if client is None:\n",
    "        client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")  # 使用DeepSeek的API端点\n",
    "    \n",
    "    # 准备输出文件，创建一个空文件（如果文件已存在，会被清空）\n",
    "    with open(OUTPUT_FILE_PATH, 'w', encoding='utf-8'):\n",
    "        pass\n",
    "    \n",
    "    # 加载数据\n",
    "    all_cases = []\n",
    "    try:\n",
    "        with open(INPUT_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "            # 逐行读取JSONL格式文件\n",
    "            for line in f:\n",
    "                if line.strip():  # 跳过空行\n",
    "                    try:\n",
    "                        case = json.loads(line.strip())  # 解析JSON\n",
    "                        all_cases.append(case)  # 添加到案例列表\n",
    "                    except:\n",
    "                        continue  # 忽略解析失败的行\n",
    "    except Exception as e:\n",
    "        print(f\"加载数据出错: {str(e)}\")\n",
    "        return 0  # 返回0表示没有成功处理任何数据\n",
    "    \n",
    "    # 显示加载的案例总数\n",
    "    total_cases = len(all_cases)\n",
    "    print(f\"加载完成: 共 {total_cases} 条案例\")\n",
    "    \n",
    "    # 准备要处理的样本\n",
    "    if MAX_SAMPLES and MAX_SAMPLES < (end_index or total_cases) - START_INDEX:\n",
    "        # 当设定了最大样本数且小于指定范围时，在范围内均匀抽样\n",
    "        range_size = (end_index or total_cases) - START_INDEX\n",
    "        step = range_size / MAX_SAMPLES\n",
    "        indices = [START_INDEX + int(i * step) for i in range(MAX_SAMPLES)]\n",
    "        selected_cases = [all_cases[i] for i in indices if i < total_cases]\n",
    "    else:\n",
    "        # 否则使用指定范围内的所有样本\n",
    "        selected_cases = all_cases[START_INDEX:end_index]\n",
    "    \n",
    "    # 创建进度条 - 尝试使用notebook版本，如果失败使用标准版本\n",
    "    try:\n",
    "        pbar = tqdm(total=len(selected_cases), desc=\"生成COT数据\", unit=\"案例\")\n",
    "    except:\n",
    "        from tqdm import tqdm as std_tqdm\n",
    "        pbar = std_tqdm(total=len(selected_cases), desc=\"生成COT数据\", unit=\"案例\")\n",
    "    \n",
    "    # 并行处理案例\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        # 提交所有任务到线程池\n",
    "        futures = [executor.submit(process_case, case, pbar) for case in selected_cases]\n",
    "        \n",
    "        # 等待所有任务完成\n",
    "        for future in futures:\n",
    "            try:\n",
    "                future.result()  # 获取任务结果（会抛出任务中的异常）\n",
    "            except Exception as e:\n",
    "                print(f\"\\n任务执行失败: {str(e)}\")\n",
    "    \n",
    "    # 关闭进度条\n",
    "    pbar.close()\n",
    "    \n",
    "    # 计算总耗时\n",
    "    elapsed_time = time.time() - start_time\n",
    "    hours, remainder = divmod(elapsed_time, 3600)  # 转换为小时和剩余秒数\n",
    "    minutes, seconds = divmod(remainder, 60)  # 转换为分钟和秒数\n",
    "    \n",
    "    # 打印处理结果统计\n",
    "    print(f\"\\n处理完成!\")\n",
    "    print(f\"成功生成: {successful}/{len(selected_cases)} 条CoT数据\")\n",
    "    print(f\"总耗时: {int(hours)}小时 {int(minutes)}分钟 {seconds:.2f}秒\")\n",
    "    print(f\"平均速度: {successful/elapsed_time:.2f} 条/秒\")\n",
    "    \n",
    "    # 返回成功处理的数量\n",
    "    return successful\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b350ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理: 2025-04-28 07:38:59\n",
      "加载完成: 共 748203 条案例\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbe9fc8bffa5443caa8c98d9c114e381",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "生成COT数据:   0%|          | 0/10000 [00:00<?, ?案例/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 设置参数\n",
    "input_file = \"/root/autodl-tmp/muyan/data/cot/rest_data.json\"\n",
    "output_file = \"/root/autodl-tmp/muyan/data/cot/rest_data_cot_1w.jsonl\"\n",
    "api_key = \"sk-30e07bdc63ee42e1981344d92c9\"  # 你的DeepSeek API密钥\n",
    "max_samples = 10000  # 要处理的案例数量\n",
    "max_workers = 100   # 并行线程数\n",
    "\n",
    "# 更新全局参数\n",
    "INPUT_FILE_PATH = input_file\n",
    "OUTPUT_FILE_PATH = output_file\n",
    "API_KEY = api_key\n",
    "MAX_SAMPLES = max_samples\n",
    "MAX_WORKERS = max_workers\n",
    "client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "\n",
    "# 执行数据生成\n",
    "generate_legal_cot_dataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03271416",
   "metadata": {},
   "source": [
    "```json\n",
    "数据输出样例： \n",
    "\n",
    "{\"input\": \"1. 法律问题生成：\\n根据襄阳市樊城区人民检察院指控，2015年6月5日8时许，被告人努某乙与一名抱小孩的新疆女子（身份待查）在襄阳市火车站地下通道处，通过尾随被害人喻某某并由该女子从其右裤兜窃取价值4180元的金色苹果6手机后转移给努某乙。在此情况下：\\n（1）努某乙的行为是否符合刑法第264条盗窃罪的构成要件？\\n（2）涉案金额达到\\\"数额较大\\\"标准时，法院判处5个月有期徒刑并处罚金2000元的量刑是否适当？\", \"output\": \"<think>1. 犯罪构成要件分析\\n   - 客观要件：\\n     * 行为：存在秘密窃取行为（新疆女子实施扒窃）和赃物转移行为（手机转交努某乙）\\n     * 结果：造成被害人4180元财产损失\\n     * 因果关系：扒窃行为直接导致财物脱离被害人控制\\n   - 主观要件：\\n     * 共同犯罪故意可推定（两人尾随配合、赃物即时转移）\\n     * 对盗窃行为及结果持希望或放任态度\\n\\n2. 法条适用分析\\n   - 刑法第264条要求：\\n     * 盗窃公私财物数额较大（湖北2015年标准为2000元以上）\\n     * 本案金额4180元已达标\\n   - 扒窃属于特殊盗窃形态，无需数额要求即构成犯罪\\n\\n3. 量刑情节分析\\n   - 从重情节：\\n     * 公共场所实施犯罪（火车站地下通道）\\n     * 结伙作案（两人配合）\\n   - 从轻情节：\\n     * 无证据显示暴力抗拒抓捕等加重情节\\n     * 涉案金额刚超过\\\"数额较大\\\"标准\\n\\n4. 判决适当性评价\\n   - 法定刑幅度：3年以下有期徒刑、拘役或管制\\n   - 量刑基准：湖北实施细则规定数额较大起点刑为6个月\\n   - 调整因素：\\n     * 认罪态度等情节未提及（无法评价）\\n     * 实际判决（5个月）低于基准刑但仍在幅度内</think>\\n\\n2. 思考过程：\\n\\n3. 结论：\\n被告人努某乙构成盗窃罪既遂，符合刑法第264条规定。判决认定罪名正确，量刑适当：①犯罪金额刚超追诉标准；②虽在公共场所结伙作案，但未使用破坏性手段且数额相对较小；③5个月刑期低于但接近基准刑，罚金数额符合司法解释对\\\"一千元以上盗窃数额二倍以下\\\"的规定。\"}\n",
    "{\"input\": \"问题生成：\\n被告人张某在2014年2月至2015年4月期间，先后在馆陶县215省道房寨路口北一粮食收购点、金凤市场忠杰物流门市前及物流园小区内，多次盗窃125摩托车共计4辆，总价值4100元。检察机关提供了证人证言、被告人供述及失主证言等证据。根据《中华人民共和国刑法》第264条，张某的行为是否构成盗窃罪？涉案金额4100元是否达到\\\"数额较大\\\"标准？法院判处7个月有期徒刑并处罚金1000元的量刑是否适当？\", \"output\": \"<think>1. 犯罪构成要件分析\\n   - 客观要件：\\n     * 行为：张某实施了多次秘密窃取摩托车的行为（3个不同地点盗窃4辆）\\n     * 结果：造成他人财产损失（总价值4100元）\\n     * 因果关系：盗窃行为直接导致财物损失\\n   - 主观要件：\\n     * 具有非法占有目的（持续多次实施盗窃）\\n     * 明知是他人财物仍故意窃取\\n\\n2. 相关法条适用分析\\n   - 根据《刑法》第264条：\\n     * 盗窃公私财物\\\"数额较大\\\"构成盗窃罪\\n     * 需确认4100元是否达到当地\\\"数额较大\\\"标准（问题中未提供具体数额标准，但根据司法实践，多数地区1000-3000元即达到该标准）\\n\\n3. 量刑情节分析\\n   - 从重情节：\\n     * 多次实施盗窃（符合\\\"多次盗窃\\\"的加重情节）\\n     * 跨时间段持续作案（2014.2-2015.4）\\n   - 从轻情节：\\n     * 问题中未显示自首、立功等情节\\n     * 如实供述可从轻（根据\\\"被告人供述\\\"证据推断）\\n\\n4. 判决适当性评价\\n   - 法定刑幅度：盗窃数额较大处3年以下有期徒刑、拘役或管制\\n   - 量刑考量：\\n     * 7个月有期徒刑在法定幅度内\\n     * 罚金1000元与涉案金额比例适当（约25%）\\n     * 未显示量刑畸轻或畸重情形</think>\\n\\n解答：被告人张某的行为完全符合盗窃罪的构成要件，其多次秘密窃取摩托车总价值4100元，已达到\\\"数额较大\\\"标准，应依据《刑法》第264条定罪。法院判处7个月有期徒刑并处罚金1000元的量刑适当，理由包括：①在法定刑幅度内量刑；②考虑了多次盗窃的加重情节；③罚金与犯罪金额比例合理。案件关键特征为跨时段多次盗窃、目标明确（摩托车）、犯罪总额达到追诉标准。\"}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b009ff",
   "metadata": {},
   "source": [
    "### 处理第二份COT数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1877b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import threading\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from typing import Dict, Any, Optional\n",
    "from tqdm import tqdm\n",
    "from openai import OpenAI\n",
    "\n",
    "# 全局配置变量\n",
    "INPUT_FILE_PATH = None\n",
    "OUTPUT_FILE_PATH = None\n",
    "API_KEY = None\n",
    "MAX_SAMPLES = None\n",
    "MAX_WORKERS = None\n",
    "client = None\n",
    "\n",
    "# 创建写入文件的锁\n",
    "file_lock = threading.Lock()\n",
    "\n",
    "def generate_case_cot(case_data: Dict[str, Any]) -> Optional[Dict[str, str]]:\n",
    "    \"\"\"生成法律案例的CoT数据\"\"\"\n",
    "    global client\n",
    "    \n",
    "    try:\n",
    "        # 提取案例数据\n",
    "        meta = case_data.get(\"meta\", {})\n",
    "        criminals = \", \".join(meta.get(\"criminals\", []))\n",
    "        accusation = \", \".join(meta.get(\"accusation\", []))\n",
    "        articles = \", \".join(meta.get(\"relevant_articles\", []))\n",
    "        fact = case_data.get(\"fact\", \"\")\n",
    "        \n",
    "        # 获取刑期信息\n",
    "        imprisonment_info = meta.get(\"term_of_imprisonment\", {})\n",
    "        imprisonment = imprisonment_info.get(\"imprisonment\", 0)\n",
    "        life_imprisonment = imprisonment_info.get(\"life_imprisonment\", False)\n",
    "        death_penalty = imprisonment_info.get(\"death_penalty\", False)\n",
    "        \n",
    "        if life_imprisonment:\n",
    "            sentence = \"无期徒刑\"\n",
    "        elif death_penalty:\n",
    "            sentence = \"死刑\"\n",
    "        else:\n",
    "            sentence = f\"{imprisonment}个月有期徒刑\"\n",
    "        \n",
    "        # 构建专业的法律提示词\n",
    "        system_prompt = \"\"\"你是中国最优秀的刑事法律专家，具有扎实的法学理论功底和丰富的司法实践经验。\n",
    "请针对提供的案例，生成一个详细的法律分析：\n",
    "\n",
    "1. 首先，基于案例事实，生成一个完整的问题，该问题需要包含案件关键事实；\n",
    "2. 然后，提供深入的法律思考过程（放在<think>标签内），分析应当包括:\n",
    "   - 案件事实梳理\n",
    "   - 相关法律条款解读\n",
    "   - 犯罪构成要件分析\n",
    "   - 量刑情节考量\n",
    "   - 类似案例参考(如有)\n",
    "3. 最后，给出简明扼要但专业全面的结论。\n",
    "\n",
    "注意：生成的问题必须完整展示案件的主要事实，确保后续分析有足够的事实基础。不要使用markdown格式。\"\"\"\n",
    "\n",
    "        user_prompt = f\"\"\"【案件信息】\n",
    "被告人: {criminals}\n",
    "指控罪名: {accusation}\n",
    "相关法条: 第{articles}条\n",
    "判决结果: {sentence}\n",
    "罚金: {meta.get('punish_of_money', 0)}元\n",
    "\n",
    "【案件事实】\n",
    "{fact}\"\"\"\n",
    "\n",
    "        # 调用DeepSeek API\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"deepseek-chat\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": user_prompt}\n",
    "            ],\n",
    "            temperature=0.7,\n",
    "            max_tokens=4000\n",
    "        )\n",
    "        \n",
    "        full_response = response.choices[0].message.content\n",
    "        \n",
    "        # 提取问题、思考过程和答案\n",
    "        # 首先尝试分离问题和剩余部分\n",
    "        parts = full_response.split(\"\\n\\n\", 1)\n",
    "        \n",
    "        if len(parts) < 2:\n",
    "            # 如果无法分离，使用更多内容构建问题\n",
    "            question = create_comprehensive_question(fact, criminals, accusation, articles)\n",
    "            remaining = full_response\n",
    "        else:\n",
    "            # 检查问题是否足够详细\n",
    "            question = parts[0].strip()\n",
    "            # 移除可能的markdown格式\n",
    "            question = re.sub(r'^###\\s*', '', question)\n",
    "            question = re.sub(r'^法律问题：\\s*', '', question)\n",
    "            \n",
    "            # 如果问题内容不够详细，重新构建\n",
    "            if len(question.split()) < 20 and len(fact) > 100:\n",
    "                question = create_comprehensive_question(fact, criminals, accusation, articles)\n",
    "            \n",
    "            remaining = parts[1].strip()\n",
    "        \n",
    "        # 然后提取思考过程和结论\n",
    "        think_pattern = r\"<think>(.*?)</think>\"\n",
    "        think_matches = re.search(think_pattern, remaining, re.DOTALL)\n",
    "        \n",
    "        if not think_matches:\n",
    "            # 如果没有找到<think>标签，尝试识别思考和结论\n",
    "            lines = remaining.split(\"\\n\")\n",
    "            \n",
    "            # 寻找可能的分隔点\n",
    "            split_idx = None\n",
    "            for i, line in enumerate(lines):\n",
    "                if line.strip().startswith(\"结论\") or line.strip().startswith(\"综上\") or \"综合以上分析\" in line:\n",
    "                    split_idx = i\n",
    "                    break\n",
    "            \n",
    "            if split_idx is None and len(lines) > 5:\n",
    "                # 如果没有找到明确分隔点，取前80%为思考\n",
    "                split_idx = int(len(lines) * 0.8)\n",
    "            \n",
    "            if split_idx is not None:\n",
    "                think_content = \"\\n\".join(lines[:split_idx]).strip()\n",
    "                conclusion = \"\\n\".join(lines[split_idx:]).strip()\n",
    "            else:\n",
    "                # 实在没有明确分隔，按比例拆分\n",
    "                split_point = int(len(remaining) * 0.8)\n",
    "                think_content = remaining[:split_point].strip()\n",
    "                conclusion = remaining[split_point:].strip()\n",
    "                \n",
    "            # 重新组装为正确格式\n",
    "            output = f\"<think>{think_content}</think>\\n{conclusion}\"\n",
    "        else:\n",
    "            # 找到了<think>标签\n",
    "            think_content = think_matches.group(1).strip()\n",
    "            conclusion = re.sub(think_pattern, \"\", remaining, flags=re.DOTALL).strip()\n",
    "            # 移除可能的markdown格式\n",
    "            conclusion = re.sub(r'^###\\s*', '', conclusion)\n",
    "            conclusion = re.sub(r'^结论：\\s*', '', conclusion)\n",
    "            output = f\"<think>{think_content}</think>\\n{conclusion}\"\n",
    "        \n",
    "        # 移除输出中的markdown标记和多余空行\n",
    "        output = re.sub(r'#{1,6}\\s+', '', output)\n",
    "        output = re.sub(r'\\n{3,}', '\\n\\n', output)\n",
    "        \n",
    "        return {\n",
    "            \"input\": question,\n",
    "            \"output\": output\n",
    "        }\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"生成CoT数据时出错: {str(e)}\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # 尝试生成基本回答\n",
    "        try:\n",
    "            basic_question = create_comprehensive_question(fact, criminals, accusation, articles)\n",
    "            basic_output = f\"<think>由于API调用出错，无法生成详细思考</think>\\n无法基于现有信息给出分析。\"\n",
    "            return {\n",
    "                \"input\": basic_question, \n",
    "                \"output\": basic_output\n",
    "            }\n",
    "        except:\n",
    "            return None\n",
    "\n",
    "def create_comprehensive_question(fact, criminals, accusation, articles):\n",
    "    \"\"\"创建包含完整案件信息的问题\"\"\"\n",
    "    # 提取案件要点\n",
    "    fact_summary = fact[:200] + \"...\" if len(fact) > 200 else fact\n",
    "    \n",
    "    # 构建详细问题\n",
    "    question = f\"被告人{criminals}因{extract_key_fact(fact)}，被指控犯有{accusation}。根据《刑法》第{articles}条，分析其行为是否构成{accusation}？请结合案件事实进行详细分析，并评估量刑是否适当。\\n\\n案件详情：{fact_summary}\"\n",
    "    \n",
    "    return question\n",
    "\n",
    "def extract_key_fact(fact_text):\n",
    "    \"\"\"从案件事实中提取关键信息\"\"\"\n",
    "    # 简单提取前30个字符作为关键事实概述\n",
    "    if len(fact_text) <= 30:\n",
    "        return fact_text\n",
    "    \n",
    "    # 尝试提取第一个完整句子\n",
    "    sentences = re.split(r'[。！？；]', fact_text)\n",
    "    if sentences and len(sentences[0]) > 5:\n",
    "        if len(sentences[0]) <= 30:\n",
    "            return sentences[0]\n",
    "        return sentences[0][:30] + \"...\"\n",
    "    \n",
    "    return fact_text[:30] + \"...\"\n",
    "\n",
    "def process_case(case_data):\n",
    "    \"\"\"处理单个案例并写入文件\"\"\"\n",
    "    result = generate_case_cot(case_data)\n",
    "    if result:\n",
    "        with file_lock:\n",
    "            with open(OUTPUT_FILE_PATH, 'a', encoding='utf-8') as f:\n",
    "                f.write(json.dumps(result, ensure_ascii=False) + \"\\n\")\n",
    "                f.flush()\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def generate_legal_cot_dataset():\n",
    "    \"\"\"主函数：处理法律案例数据集\"\"\"\n",
    "    global client\n",
    "    \n",
    "    print(f\"正在初始化...\")\n",
    "    \n",
    "    # 初始化必要的组件\n",
    "    if client is None:\n",
    "        client = OpenAI(api_key=API_KEY, base_url=\"https://api.deepseek.com\")\n",
    "    \n",
    "    # 确保输出文件存在且为空\n",
    "    with open(OUTPUT_FILE_PATH, 'w', encoding='utf-8'):\n",
    "        pass\n",
    "    \n",
    "    print(f\"正在加载案例数据...\")\n",
    "    \n",
    "    # 加载所有案例\n",
    "    all_cases = []\n",
    "    with open(INPUT_FILE_PATH, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                try:\n",
    "                    case = json.loads(line)\n",
    "                    all_cases.append(case)\n",
    "                except:\n",
    "                    continue\n",
    "    \n",
    "    total_cases = len(all_cases)\n",
    "    print(f\"共加载 {total_cases} 条案例\")\n",
    "    \n",
    "    # 均匀抽取指定数量的样本\n",
    "    if MAX_SAMPLES and MAX_SAMPLES < total_cases:\n",
    "        step = total_cases / MAX_SAMPLES\n",
    "        indices = [int(i * step) for i in range(MAX_SAMPLES)]\n",
    "        selected_cases = [all_cases[i] for i in indices]\n",
    "    else:\n",
    "        selected_cases = all_cases\n",
    "    \n",
    "    print(f\"将处理 {len(selected_cases)} 条案例\")\n",
    "    \n",
    "    # 进度跟踪\n",
    "    processed = 0\n",
    "    successful = 0\n",
    "    \n",
    "    # 使用简单的进度显示\n",
    "    print(\"[开始处理]\")\n",
    "    \n",
    "    # 定义处理函数\n",
    "    def process_with_progress(case):\n",
    "        nonlocal processed, successful\n",
    "        result = process_case(case)\n",
    "        with file_lock:\n",
    "            nonlocal processed, successful\n",
    "            processed += 1\n",
    "            if result:\n",
    "                successful += 1\n",
    "            \n",
    "            # 简单进度显示\n",
    "            percent = (processed / len(selected_cases)) * 100\n",
    "            print(f\"\\r进度: {processed}/{len(selected_cases)} [{percent:.1f}%] - 成功: {successful}\", end=\"\")\n",
    "    \n",
    "    # 使用线程池并行处理\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:\n",
    "        executor.map(process_with_progress, selected_cases)\n",
    "    \n",
    "    print(f\"\\n处理完成! 成功生成 {successful}/{len(selected_cases)} 条CoT数据\")\n",
    "    return successful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dcc796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始处理文件: /root/autodl-tmp/muyan/data/cot/kg_crime.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "生成CoT数据: 100%|██████████| 856/856 [5:49:42<00:00, 24.51s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CoT数据集生成完成，共处理 856 条记录，保存到: /root/autodl-tmp/muyan/data/cot/cot_dataset_all.jsonl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "856"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 设置参数\n",
    "input_file = \"/root/autodl-tmp/muyan/data/cot/kg_crime.json\"  # 修改为你的原始jsonl文件路径\n",
    "output_file = \"/root/autodl-tmp/muyan/data/cot/cot_dataset_all.jsonl\"  # 保存CoT数据集的路径\n",
    "api_key = \"sk-30e07bdc635344d92c9\"  # 替换为你的DeepSeek API密钥\n",
    "max_samples = None  # 设置为你想处理的样本数量，如果要处理全部数据则设为None\n",
    "\n",
    "# 生成CoT数据集\n",
    "generate_cot_dataset(input_file, output_file, api_key, max_samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48637996",
   "metadata": {},
   "source": [
    "```json\n",
    "原始数据\n",
    "\n",
    "{ \"_id\" : { \"$oid\" : \"5be55309831b9724178d9d96\" }, \"crime_big\" : \"危害国家安全罪\", \"crime_small\" : \"背叛国家罪\", \"crime_link\" : \"http://china.findlaw.cn/zuiming/1_55.html\", \"gainian\" : [ \"背叛国家罪是指勾结外国或者境外机构、组织、个人，危害中华人民共和国的主权、领土完整和安全的行为。\", \"推荐阅读：分裂国家罪与背叛国家罪区别\" ], \"tezheng\" : [ \"背叛国家罪的客体要件\", \"本罪侵犯的客体是中华人民共和国、领土完整和安全。客观方面表现为勾结外国，危害国家主权、领土完整和安全的行为，如果勾结的是境外的机构、组织或个人实施背叛国家的行为，也按照本罪处罚;犯罪主体只能是中国公民，而且通常是具有一定政治地位，掌握了国家重要政治权力或者窃据了社会重要职务的人;主观方面是直接故意。\", \"主权，是指国家独立自主地处理自己内外事务、管理自己国家的权力。它是国家最重要的属性，是国家固有的在国内的最高权力和在国际上的独立权力。这种权力是不可分割和不可让与的，不受外来干预和不从属于外来意志。\", \"领土是构成国家的基本要素之一，是国家赖以存在的物质条件。所谓领土完整，是指国家领土不能被分裂，更不能被侵占。\", \"国家安全是国家存在的基本条件，是国家稳定发展的基本条件。国家的主权、领土完整和安全是国家独立的标志，是进行社会主义现代化建设的根本保证。这一客体的重要性，表明背叛国家罪是危害国家的最危险的犯罪。\", \"背叛国家罪的客观要件\", \"本罪在客观方面表现为勾结外国或者境外机构、组织、个人，危害国家主权、领土完整和安全的行为。\", \"勾结外国或者境外机构、组织、个人。背叛国家的犯罪分子，为了破坏祖国的独立、主权、领土完整和安全，出卖民族利益，总要千方百计地寻找外国主子或境外敌对势力作靠山;而外国或境外敌对势力要对中华人民共和国搞颠覆活动，也要千方百计地从我国内部寻找中意的代理人，充当内奸。这样一来他们必然相互勾结，狼狈为奸，以期达到他们共同危害我国主权、领土完整和安全的目的。这里所说的外国，是指对我国怀有侵略、控制、颠覆野心的外国政府，也指外国敌视和破坏我国社会主义制度的政党、政治集团以及其他敌对势力，包括外国机构、组织和个人。外国机构，是指外国的官方机构，如政府、军队以及其他国家机关设置的机构，也包括外国驻我国的使、领馆及办事处等。外国组织，是指外国的政党、社会团体及其他企事业单位等。通常所说的组织包括机构，但危害国家安全的行为背后往往有某一国国家的政府、军队或者其他官方组织机构的支持、操纵，所以对外国机构加以强调十分必要。外国个人，是指外国公民、无国籍人以及外籍华人等。\", \"境外犯罪\", \"境外与外国并不相同，是指中华人民共和国领域以外或者领域以内中华人民共和国政府尚未实施行政管辖的地域，包括尚未回到祖国怀抱的台湾省(香港于1997年7月1日回归、澳门于1999年12月31日回归)。所谓境外机构、组织，是指回归之前的台湾和外国的机构、组织及其在中华人民共和国境内设立的分支(代表)机构和分支组织。如外国的政府、军队以及其他国家机关在中国境内设置的机构、社团以及其他企事业组织，也包括外国驻华使、领馆，办事处，以及商社、新闻机构等。所谓境外个人，是指居住在外国和回归之前的台湾地区的人，以及居住在中华人民共和国境内不具有中华人民共和国国籍的人。这里所说的居住，不论是否取得永久居住权或长期居住权，还是短期居住，都应视为居住。这里的勾结，根据《国家安全法实施细则》第7条规定，是指境内机构、组织、个人实施的下列危害国家安全的行为:(1)与外国、境外机构、组织、个人共同策划或者进行危害国家安全活动的;(2)接受外国、境外机构、组织、个人的资助或者指使，进行危害国家安全活动的;(3)与外国、境外机构、组织、个人建立联系，取得支持、帮助，进行危害国家安全活动的。勾结，有公开的，但更多的是进行秘密接触，联系交往，通谋策划，共同进行危害国家安全的行为。这里的勾结，既有国内的组织和个人与国外机构、组织、个人主动挂勾联系、投靠、接受其资助、指使，寻求支持、帮助，也有国外机构、组织、个人多方与我国国内的组织和个人联络挂勾，提供各种资助、帮助。其共同目的是进行危害我国国家的主权、领土完整和安全的活动。\", \"危害中华人民共和国的主权、领土完整和安全。即暗中秘密策划危害中华人民共和国的主权、领土完整和安全的活动。如谋划签订卖国条约，与敌国通谋向我国发动侵略战争，在我国组织傀儡政府，进行颠覆活动等。\", \"上述两个特征是紧密相连、不可分割的。勾结外国、境外机构、组织、个人是阴谋危害中华人民共和国的主权、领土完整和安全的前提和手段;危害中华人民共和国的主权、领土完整和安全是勾结外国、境外机构、组织、个人的特定内容和直接目的。背叛国家罪的构成，并不要求在实际上已经造成危害祖国主权、领土完整和安全的结果，而是只要行为人的行为具备上述两个特征，即有勾结外国、境外机构、组织、个人，意在危害中华人民共和国主权、领土完整和安全的活动，即可构成。如果行为人虽与外国、境外机构、组织、个人相勾结，但策划的不是上述内容，则不构成本罪。\", \"背叛国家罪的主体要件\", \"本罪的主体只能是具有中华人民共和国国籍的人，即中国公民。外国人不能成为本罪的主体，但可以成为本罪的共犯。能够成为本罪主体的中国公民，主要是那些混入我党、政、军机关内部，窃据要职、掌握重要权力的人或者有重大政治影响的人。普通公民一般情况下很难危害到国家的主权、领土完整和安全，但由于本法并未规定本罪主体必须具有特殊身份，普通公民也可以成为本罪的主体。\", \"背叛国家罪的主观要件\", \"本罪在主观方面表现为故意，即明知自己勾结外国、境外机构、组织、个人实施的行为危害中国的主权、领土完整和安全，而希望或者放任这种危害后果的发生。本法将1979年刑法第91条中的阴谋一词删去，将行为人与外国进行密谋策划这种事实上的犯罪预备行为(犯罪行为的一部分)包含于勾结外国，危害国家的主权、领土完整和安全的活动之中。因此，只要行为人实施了勾结外国，危害中华人民共和国的主权、领土完整和安全的行为，不管处于策划阶段，还是边策划边实施，都不影响构成本罪。\", \"其他背叛国家罪的知识\" ], \"rending\" : [ \"(一)本罪与颠覆国家政权罪的界限\", \"这两个罪的行为方式是相同的,都包含组织,策划,实施的行为,但它们的直接客体是不同的,本罪侵犯的是国家的统一,后罪侵犯的是人民民主专政的政权和社会主义制度.另外,它们的主观方面也是不同的,本罪的目的是分裂统一的多民族国家,后罪的目的是颠覆人民民主专政和推翻社会主义制度.分裂国家的行为与颠覆政权的行为是不尽相同的,国家被分裂,但政权依然存在的现象,是屡见不鲜的.反过来说,政权被颠覆了而国家没有分裂的现象也是屡见不鲜的.\", \"(二)本罪与背叛国家罪的界限\", \"背叛国家罪危害的是国家的主权,领土完整和安全,这一客体的涉及面远比本罪的客体广泛的多.本罪侵犯的是国家的统一,国家主权和安全没有落入外国人之手,因而与勾结外国,使国家主权和安全落人外国之手的背叛国家罪是不同的.但是国家统一这个概念,并不完全等于领土完整.国家没有统一,也可能领土完整;国家统一了,也可能领土不完整.因为国家统一是对内而言的,领土完整是对外而言的.另外在客观行为方面,两罪也是不同的.本罪不以勾结外国为要件,后罪则正好相反.总之,本罪与后罪的关系是内乱与外患的关系.\", \"欢迎阅读其他被判国家罪知识\" ], \"chufa\" : [ \"犯本罪的，处无期徒刑或者十年以上有期徒刑。根据本法第56条和第113条的规定，犯本罪的，应当附加剥夺政治权利，可以并处没收财产。对国家和人民危害特别严重、情节特别恶劣的，可以判处死刑。\", \"犯背叛国家罪而对国家和人民危害特别严重、情节特别恶劣，是本罪的加重处罚事由。这里的对国家和人民危害特别严重、情节特别恶劣，是指造成国家主权、领土完整和安全严重损害的后果或者引起国内严重动乱。\", \"更多背叛国家罪相关知识\" ], \"fatiao\" : [ \"[刑法条文]\", \"第一百零二条勾结外国，危害中华人民共和国的主权、领土完整和安全的，处无期徒刑或者十年以上有期徒刑。\", \"与境外机构、组织、个人相勾结，犯前款罪的，依照前款的规定处罚。\", \"第一百一十三条本章上述危害国家安全罪行中，除第一百零三条第二款、第一百零五条、第一百零七条、第、百零九条外，对国家和人民危害特别严重、情节特别恶劣的，可以判处死刑。犯本章之罪的，可以并处没收财产。\", \"第五十六条对于危害国家安全的犯罪分子应当附加剥夺政治权利;独立适用剥夺政治权利的，依照本法分则的规定。\", \"第五十四条剥夺政治权利是剥夺下列权利：\", \"(一)选举权和被选举权;\", \"(二)言论、出版、集会、结社、游行、示威自由的权利;\", \"(三)担任国家机关职务的权利;\", \"(四)担任国有公司、企业、事业单位和人民团体领导职务的权利。\", \"第五十五条剥夺政治权利的期限，除本法第五十七条规定外，为一年以上五年以下。\", \"判处管制附加剥夺政治权利的，剥夺政治权利的期限与管制的期限相等，同时执行。\", \"第五十七条对于被判处死刑、无期徒刑的犯罪分子，应当剥夺政治权利终身。\", \"在死刑缓期执行减为有期徒刑或者无期徒刑减为有期徒刑的时候，应当把附加剥夺政治权利的期限改为三年以上十年以下。\", \"背叛国家罪其他相关知识\" ], \"jieshi\" : [], \"bianhu\" : [] }\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afea5b5",
   "metadata": {},
   "source": [
    "```json\n",
    "清洗后输出 \n",
    "\n",
    "{\"input\": \"问题：某省高级政府官员甲与外国情报机构秘密接触，向其提供我国军事部署信息，并策划在边境地区制造动乱以配合外国军事行动。甲的行为构成何种犯罪？应当如何量刑？\", \"output\": \"<think>1. 罪名定性分析：\\n- 客体要件：甲的行为直接危害我国主权、领土完整和安全，符合背叛国家罪保护的客体要求。军事部署属于国家安全核心机密，边境动乱策划直接威胁领土完整。\\n- 客观方面：甲实施了\\\"勾结外国\\\"的具体行为（与外国情报机构接触），并实施了\\\"危害国家安全\\\"的具体行为（提供军事机密、策划动乱），完全符合刑法第102条规定的客观构成要件。\\n- 主体要件：甲作为省级高级官员，属于\\\"掌握重要权力\\\"的中国公民，符合本罪特殊主体要求。\\n- 主观方面：甲明知其行为会危害国家安全仍积极实施，具有直接故意。\\n\\n2. 加重情节认定：\\n- 提供的军事部署信息属于国家核心机密\\n- 策划配合外国军事行动可能造成实际武装冲突\\n- 省级官员身份具有特殊危害性\\n符合刑法第113条\\\"对国家和人民危害特别严重、情节特别恶劣\\\"的情形。\\n\\n3. 量刑考量：\\n- 主刑：根据犯罪情节可适用死刑（需报最高法院核准）\\n- 附加刑：必须附加剥夺政治权利终身（刑法第56、57条）\\n- 财产刑：可以并处没收个人全部财产（刑法第113条）\\n\\n4. 共犯问题：\\n外国情报人员虽不构成本罪主体，但可作为共犯处理，需通过外交或国际刑事司法合作途径追究。</think>\\n答案：甲的行为构成背叛国家罪。根据《中华人民共和国刑法》相关规定：\\n\\n[核心法条]\\n第一百零二条：勾结外国，危害中华人民共和国的主权、领土完整和安全的，处无期徒刑或者十年以上有期徒刑。与境外机构、组织、个人相勾结，犯前款罪的，依照前款的规定处罚。\\n\\n第一百一十三条：对国家和人民危害特别严重、情节特别恶劣的，可以判处死刑。犯本章之罪的，可以并处没收财产。\\n\\n第五十六条：对于危害国家安全的犯罪分子应当附加剥夺政治权利。\\n\\n具体处罚建议：\\n1. 主刑：考虑其省级官员身份、提供军事机密的行为性质及策划武装动乱的严重后果，应判处死刑。\\n2. 附加刑：附加剥夺政治权利终身，依据刑法第54条剥夺其四项政治权利。\\n3. 财产刑：并处没收个人全部财产。\\n\\n本案属于典型的背叛国家罪加重情形，其行为已实际威胁国家军事安全和领土完整，应当依法从严惩处。需注意的是，死刑判决须依法报请最高人民法院核准。\"}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca240da",
   "metadata": {},
   "source": [
    "### COT数据合并与清洗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "048c96dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理文件: /root/autodl-tmp/muyan/data/cot/rest_data_cot_1w.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e74a56ca36e42e8bcdff689976d253d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "读取 rest_data_cot_1w.jsonl: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 /root/autodl-tmp/muyan/data/cot/rest_data_cot_1w.jsonl 中提取了 10000 条数据\n",
      "处理文件: /root/autodl-tmp/muyan/data/cot/rest_data_cot_2w.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e29828ef53c4b099676a7a506e80fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "读取 rest_data_cot_2w.jsonl: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 /root/autodl-tmp/muyan/data/cot/rest_data_cot_2w.jsonl 中提取了 17677 条数据\n",
      "处理文件: /root/autodl-tmp/muyan/data/cot/kg_crime_all.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9bf6443b129480e88b1d7647297e303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "读取 kg_crime_all.jsonl: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 /root/autodl-tmp/muyan/data/cot/kg_crime_all.jsonl 中提取了 856 条数据\n",
      "合并完成，总共 28533 条数据\n",
      "输出文件: /root/autodl-tmp/muyan/data/cot/merged_all_cot_data.jsonl\n",
      "\n",
      "=== 数据长度统计 ===\n",
      "输入长度统计:\n",
      "count    28533.000000\n",
      "mean       212.985841\n",
      "std         84.491155\n",
      "min          0.000000\n",
      "25%        177.000000\n",
      "50%        216.000000\n",
      "75%        263.000000\n",
      "max        703.000000\n",
      "Name: input_length, dtype: float64\n",
      "\n",
      "输出长度统计:\n",
      "count    28533.000000\n",
      "mean       837.057617\n",
      "std        120.948980\n",
      "min        461.000000\n",
      "25%        751.000000\n",
      "50%        829.000000\n",
      "75%        917.000000\n",
      "max       1481.000000\n",
      "Name: output_length, dtype: float64\n",
      "\n",
      "包含<think>标签的数据: 28533/28533 (100.00%)\n",
      "\n",
      "思维过程长度统计:\n",
      "count    28533.000000\n",
      "mean       655.512389\n",
      "std        105.254668\n",
      "min        289.000000\n",
      "25%        583.000000\n",
      "50%        657.000000\n",
      "75%        727.000000\n",
      "max       1152.000000\n",
      "dtype: float64\n",
      "\n",
      "答案部分长度统计:\n",
      "count    28533.000000\n",
      "mean       166.545228\n",
      "std         62.378208\n",
      "min         30.000000\n",
      "25%        123.000000\n",
      "50%        151.000000\n",
      "75%        196.000000\n",
      "max       1083.000000\n",
      "dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 23383 (\\N{CJK UNIFIED IDEOGRAPH-5B57}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 31526 (\\N{CJK UNIFIED IDEOGRAPH-7B26}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 38271 (\\N{CJK UNIFIED IDEOGRAPH-957F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 39057 (\\N{CJK UNIFIED IDEOGRAPH-9891}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 36755 (\\N{CJK UNIFIED IDEOGRAPH-8F93}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 20837 (\\N{CJK UNIFIED IDEOGRAPH-5165}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:122: UserWarning: Glyph 20986 (\\N{CJK UNIFIED IDEOGRAPH-51FA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 39057 (\\N{CJK UNIFIED IDEOGRAPH-9891}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 36755 (\\N{CJK UNIFIED IDEOGRAPH-8F93}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20837 (\\N{CJK UNIFIED IDEOGRAPH-5165}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 38271 (\\N{CJK UNIFIED IDEOGRAPH-957F}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 23383 (\\N{CJK UNIFIED IDEOGRAPH-5B57}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 31526 (\\N{CJK UNIFIED IDEOGRAPH-7B26}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20986 (\\N{CJK UNIFIED IDEOGRAPH-51FA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 23383 (\\N{CJK UNIFIED IDEOGRAPH-5B57}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 31526 (\\N{CJK UNIFIED IDEOGRAPH-7B26}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 38271 (\\N{CJK UNIFIED IDEOGRAPH-957F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 39057 (\\N{CJK UNIFIED IDEOGRAPH-9891}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 24605 (\\N{CJK UNIFIED IDEOGRAPH-601D}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 32500 (\\N{CJK UNIFIED IDEOGRAPH-7EF4}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 36807 (\\N{CJK UNIFIED IDEOGRAPH-8FC7}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 31243 (\\N{CJK UNIFIED IDEOGRAPH-7A0B}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 31572 (\\N{CJK UNIFIED IDEOGRAPH-7B54}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 26696 (\\N{CJK UNIFIED IDEOGRAPH-6848}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_70027/2426976489.py:141: UserWarning: Glyph 37096 (\\N{CJK UNIFIED IDEOGRAPH-90E8}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24605 (\\N{CJK UNIFIED IDEOGRAPH-601D}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 32500 (\\N{CJK UNIFIED IDEOGRAPH-7EF4}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 36807 (\\N{CJK UNIFIED IDEOGRAPH-8FC7}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 31243 (\\N{CJK UNIFIED IDEOGRAPH-7A0B}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 31572 (\\N{CJK UNIFIED IDEOGRAPH-7B54}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 26696 (\\N{CJK UNIFIED IDEOGRAPH-6848}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 37096 (\\N{CJK UNIFIED IDEOGRAPH-90E8}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABdEAAAJOCAYAAABYwk4SAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAThlJREFUeJzt3X+UVtV9L/73AM4A6oBgmJEKhMRWRcEfqDiJWoyUEVk2qbS3KlFsSKjewUZolZAYLmATvNr4IwlqbFDSW6zRuxKToFVR4686KBInKqZUDSm2MkMbhRGjw6/n+0e+PNeJHBQFhoHXa62z1pyzP8959nbOMPu8PbOfilKpVAoAAAAAAPAuXTq6AwAAAAAAsLsSogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAU6NbRHQBg+y1btizHHHNMKisrt9q+fv36PPPMM+9Z84tf/CJvv/32XlX38Y9/fKvtAACwvczLP3ideTnQmQjRATqhUqmUE044IY8//vhW20888cT3XbO31QEAwI5iXv7B6wA6E8u5AAAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFOjW0R0A4INZvHhxevfuvdW2devWve+avbEOAAB2FPPyD14H0FlUlEqlUkd3AgAAAAAAdkeWcwEAAAAAgAJCdAAAAAAAKCBEBwAAAACAAj5Y9H3YvHlzXn311ey///6pqKjo6O4AANDJlUqlvPHGG+nfv3+6dPFcy/YwNwcAYEd5v/NyIfr78Oqrr2bAgAEd3Q0AAPYwr7zySg4++OCO7kanYm4OAMCO9l7zciH6+7D//vsn+e1/zOrq6g7uDQAAnV1ra2sGDBhQnmfy/pmbAwCwo7zfebkQ/X3Y8mei1dXVJuoAAOwwliPZfubmAADsaO81L7cAIwAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAU6NbRHQCgvYnzl2xX/bwLjt9JPQEA9iTmGAAAH4wn0QEAAAAAoIAQHQAAAAAACljOBWAv40+5AQAAAN4/T6IDAAAAAEABIToAAAAAABSwnAtAJ7e9y7MAAAAA8P55Eh0AAAAAAAoI0QEAAAAAoIDlXAB2MsutAAAAAHRenkQHAAAAAIACQnQAAAAAACggRAcAAAAAgAJCdAAAAAAAKCBEBwAAAACAAkJ0AAAAAAAoIEQHAAAAAIACQnQAAAAAACggRAcAAAAAgAJCdAAAAAAAKCBEBwAAAACAAh0aoj/66KM588wz079//1RUVOSuu+5q115RUbHV7eqrry7XfPSjH31X+5VXXtnuPM8++2xOPvnkdO/ePQMGDMhVV121K4YHAAAAAEAn16Eh+ptvvpmjjjoqc+fO3Wr7qlWr2m233HJLKioqMm7cuHZ1s2fPbld38cUXl9taW1szevToDBo0KEuXLs3VV1+dmTNn5uabb96pYwMAAAAAoPPr1pFvPmbMmIwZM6awvba2tt3+j370o5x66qn52Mc+1u74/vvv/67aLRYsWJD169fnlltuSWVlZY444og0NTXlmmuuyaRJkz78IAAAAAAA2GN1mjXRW1pacvfdd2fixInvarvyyivTt2/fHHPMMbn66quzcePGcltjY2NOOeWUVFZWlo/V19dn+fLlef3113dJ3wEAAAAA6Jw69En07fG9730v+++/f84666x2x//qr/4qxx57bPr06ZMnnngi06dPz6pVq3LNNdckSZqbmzN48OB2r6mpqSm3HXDAAe96r7a2trS1tZX3W1tbd/RwAAAAAADoBDpNiH7LLbdk/Pjx6d69e7vjU6dOLX89bNiwVFZW5i//8i8zZ86cVFVVfaD3mjNnTmbNmvWh+gsAAAAAQOfXKZZzeeyxx7J8+fJ8/vOff8/aESNGZOPGjfnVr36V5Lfrqre0tLSr2bJftI769OnTs3bt2vL2yiuvfLgBAAAAAADQKXWKEH3evHkZPnx4jjrqqPesbWpqSpcuXdKvX78kSV1dXR599NFs2LChXLNo0aIceuihW13KJUmqqqpSXV3dbgMAAAAAYO/ToSH6unXr0tTUlKampiTJihUr0tTUlJUrV5ZrWltbc+edd271KfTGxsZcd911+fnPf55f/vKXWbBgQaZMmZLPfvaz5YD83HPPTWVlZSZOnJhly5bl+9//fq6//vp2y8AAAAAAAMDWdOia6E8//XROPfXU8v6WYHvChAmZP39+kuT2229PqVTKOeec867XV1VV5fbbb8/MmTPT1taWwYMHZ8qUKe0C8l69euX+++9PQ0NDhg8fngMPPDAzZszIpEmTdu7gAAAAAADo9Do0RB85cmRKpdI2ayZNmlQYeB977LFZvHjxe77PsGHD8thjj32gPgIAAAAAsPfq0BAdoDOaOH9JR3cBAAAAgF2kU3ywKAAAAAAAdAQhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAgW4d3QEAdm8T5y/Zrvp5Fxy/k3oCAAAAsOt5Eh0AAPZyM2fOTEVFRbvtsMMOK7e//fbbaWhoSN++fbPffvtl3LhxaWlpaXeOlStXZuzYsenZs2f69euXSy+9NBs3bmxX8/DDD+fYY49NVVVVDjnkkMyfP39XDA8AAD4UIToAAJAjjjgiq1atKm+PP/54uW3KlCn5yU9+kjvvvDOPPPJIXn311Zx11lnl9k2bNmXs2LFZv359nnjiiXzve9/L/PnzM2PGjHLNihUrMnbs2Jx66qlpamrKJZdcks9//vO57777duk4AQBge1nOBQAASLdu3VJbW/uu42vXrs28efNy22235VOf+lSS5NZbb83hhx+exYsX58QTT8z999+fF154IQ888EBqampy9NFH54orrsi0adMyc+bMVFZW5qabbsrgwYPzjW98I0ly+OGH5/HHH8+1116b+vr6XTpWAADYHp5EBwAA8uKLL6Z///752Mc+lvHjx2flypVJkqVLl2bDhg0ZNWpUufawww7LwIED09jYmCRpbGzM0KFDU1NTU66pr69Pa2trli1bVq555zm21Gw5BwAA7K48iQ4AAHu5ESNGZP78+Tn00EOzatWqzJo1KyeffHKef/75NDc3p7KyMr179273mpqamjQ3NydJmpub2wXoW9q3tG2rprW1NW+99VZ69Oix1b61tbWlra2tvN/a2vqhxgoAANtLiA4AAHu5MWPGlL8eNmxYRowYkUGDBuWOO+4oDLd3lTlz5mTWrFkd2gcAAPZulnMBAADa6d27d/7gD/4gL730Umpra7N+/fqsWbOmXU1LS0t5DfXa2tq0tLS8q31L27ZqqqurtxnUT58+PWvXri1vr7zyyocdHgAAbBchOgAA0M66devy8ssv56CDDsrw4cOzzz775MEHHyy3L1++PCtXrkxdXV2SpK6uLs8991xWr15drlm0aFGqq6szZMiQcs07z7GlZss5ilRVVaW6urrdBgAAu5IQHQAA9nJ/8zd/k0ceeSS/+tWv8sQTT+RP/uRP0rVr15xzzjnp1atXJk6cmKlTp+anP/1pli5dmr/4i79IXV1dTjzxxCTJ6NGjM2TIkJx33nn5+c9/nvvuuy+XX355GhoaUlVVlSS58MIL88tf/jKXXXZZ/vVf/zU33HBD7rjjjkyZMqUjhw4AAO/JmugAALCX+4//+I+cc845+fWvf52PfOQjOemkk7J48eJ85CMfSZJce+216dKlS8aNG5e2trbU19fnhhtuKL++a9euWbhwYS666KLU1dVl3333zYQJEzJ79uxyzeDBg3P33XdnypQpuf7663PwwQfnu9/9burr63f5eAEAYHsI0QEAYC93++23b7O9e/fumTt3bubOnVtYM2jQoNxzzz3bPM/IkSPzzDPPfKA+AgBAR7GcCwAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABTo1tEdAOhoE+cv6eguAAAAALCb8iQ6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAU6NbRHQAAAGD3M3H+ku2qn3fB8TupJwAAHcuT6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAU6NER/9NFHc+aZZ6Z///6pqKjIXXfd1a79ggsuSEVFRbvt9NNPb1fz2muvZfz48amurk7v3r0zceLErFu3rl3Ns88+m5NPPjndu3fPgAEDctVVV+3soQEAAAAAsAfo0BD9zTffzFFHHZW5c+cW1px++ulZtWpVefunf/qndu3jx4/PsmXLsmjRoixcuDCPPvpoJk2aVG5vbW3N6NGjM2jQoCxdujRXX311Zs6cmZtvvnmnjQsAAAAAgD1Dt4588zFjxmTMmDHbrKmqqkptbe1W237xi1/k3nvvzZIlS3LcccclSb71rW/ljDPOyN/93d+lf//+WbBgQdavX59bbrkllZWVOeKII9LU1JRrrrmmXdgOAAAAAAC/a7dfE/3hhx9Ov379cuihh+aiiy7Kr3/963JbY2NjevfuXQ7Qk2TUqFHp0qVLnnzyyXLNKaecksrKynJNfX19li9fntdff33XDQQAAAAAgE6nQ59Efy+nn356zjrrrAwePDgvv/xyvvzlL2fMmDFpbGxM165d09zcnH79+rV7Tbdu3dKnT580NzcnSZqbmzN48OB2NTU1NeW2Aw444F3v29bWlra2tvJ+a2vrjh4aAAAAAACdwG4dop999tnlr4cOHZphw4bl4x//eB5++OGcdtppO+1958yZk1mzZu208wMAAAAA0Dns9su5vNPHPvaxHHjggXnppZeSJLW1tVm9enW7mo0bN+a1114rr6NeW1ublpaWdjVb9ovWWp8+fXrWrl1b3l555ZUdPRQAAAAAADqB3fpJ9N/1H//xH/n1r3+dgw46KElSV1eXNWvWZOnSpRk+fHiS5KGHHsrmzZszYsSIcs1XvvKVbNiwIfvss0+SZNGiRTn00EO3upRL8tsPM62qqtoFIwLY80ycv2S76uddcPxO6gkAAADAh9ehT6KvW7cuTU1NaWpqSpKsWLEiTU1NWblyZdatW5dLL700ixcvzq9+9as8+OCD+fSnP51DDjkk9fX1SZLDDz88p59+er7whS/kqaeeyr/8y79k8uTJOfvss9O/f/8kybnnnpvKyspMnDgxy5Yty/e///1cf/31mTp1akcNGwAAAACATqJDQ/Snn346xxxzTI455pgkydSpU3PMMcdkxowZ6dq1a5599tn88R//cf7gD/4gEydOzPDhw/PYY4+1e0p8wYIFOeyww3LaaafljDPOyEknnZSbb7653N6rV6/cf//9WbFiRYYPH56//uu/zowZMzJp0qRdPl4AAAAAADqXDl3OZeTIkSmVSoXt991333ueo0+fPrntttu2WTNs2LA89thj290/AAAAAAD2bp3qg0UBAAAAAGBXEqIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAECBbh3dAQD2bhPnL9mu+nkXHL+TegIAAADwbp5EBwAAAACAAkJ0AAAAAAAoYDkXYI+zvcuDAAAAAEART6IDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAU6NbRHQDYlonzl3R0FwAAAADYi3kSHQAAAAAACgjRAQAAAACggBAdAAAAAAAKCNEBAAAAAKCAEB0AAAAAAAoI0QEAAAAAoIAQHQAAAAAACgjRAQCAdq688spUVFTkkksuKR97++2309DQkL59+2a//fbLuHHj0tLS0u51K1euzNixY9OzZ8/069cvl156aTZu3Niu5uGHH86xxx6bqqqqHHLIIZk/f/4uGBEAAHxwQnQAAKBsyZIl+c53vpNhw4a1Oz5lypT85Cc/yZ133plHHnkkr776as4666xy+6ZNmzJ27NisX78+TzzxRL73ve9l/vz5mTFjRrlmxYoVGTt2bE499dQ0NTXlkksuyec///ncd999u2x8AACwvYToAABAkmTdunUZP358/v7v/z4HHHBA+fjatWszb968XHPNNfnUpz6V4cOH59Zbb80TTzyRxYsXJ0nuv//+vPDCC/nHf/zHHH300RkzZkyuuOKKzJ07N+vXr0+S3HTTTRk8eHC+8Y1v5PDDD8/kyZPzp3/6p7n22ms7ZLwAAPB+CNEBAIAkSUNDQ8aOHZtRo0a1O7506dJs2LCh3fHDDjssAwcOTGNjY5KksbExQ4cOTU1NTbmmvr4+ra2tWbZsWbnmd89dX19fPsfWtLW1pbW1td0GAAC7UreO7gAAANDxbr/99vzsZz/LkiVL3tXW3NycysrK9O7du93xmpqaNDc3l2veGaBvad/Stq2a1tbWvPXWW+nRo8e73nvOnDmZNWvWBx4XAAB8WJ5EBwCAvdwrr7ySL37xi1mwYEG6d+/e0d1pZ/r06Vm7dm15e+WVVzq6SwAA7GWE6AAAsJdbunRpVq9enWOPPTbdunVLt27d8sgjj+Sb3/xmunXrlpqamqxfvz5r1qxp97qWlpbU1tYmSWpra9PS0vKu9i1t26qprq7e6lPoSVJVVZXq6up2GwAA7EpCdAAA2Muddtppee6559LU1FTejjvuuIwfP7789T777JMHH3yw/Jrly5dn5cqVqaurS5LU1dXlueeey+rVq8s1ixYtSnV1dYYMGVKueec5ttRsOQcAAOyOrIkOAAB7uf333z9HHnlku2P77rtv+vbtWz4+ceLETJ06NX369El1dXUuvvji1NXV5cQTT0ySjB49OkOGDMl5552Xq666Ks3Nzbn88svT0NCQqqqqJMmFF16Yb3/727nsssvyuc99Lg899FDuuOOO3H333bt2wAAAsB2E6AAAwHu69tpr06VLl4wbNy5tbW2pr6/PDTfcUG7v2rVrFi5cmIsuuih1dXXZd999M2HChMyePbtcM3jw4Nx9992ZMmVKrr/++hx88MH57ne/m/r6+o4YEgAAvC9CdAAA4F0efvjhdvvdu3fP3LlzM3fu3MLXDBo0KPfcc882zzty5Mg888wzO6KLAACwS1gTHQAAAAAACgjRAQAAAACggBAdAAAAAAAKCNEBAAAAAKCAEB0AAAAAAAp0aIj+6KOP5swzz0z//v1TUVGRu+66q9y2YcOGTJs2LUOHDs2+++6b/v375/zzz8+rr77a7hwf/ehHU1FR0W678sor29U8++yzOfnkk9O9e/cMGDAgV1111a4YHgAAAAAAnVyHhuhvvvlmjjrqqMydO/ddbb/5zW/ys5/9LF/96lfzs5/9LD/4wQ+yfPny/PEf//G7amfPnp1Vq1aVt4svvrjc1tramtGjR2fQoEFZunRprr766sycOTM333zzTh0bAAAAAACdX7eOfPMxY8ZkzJgxW23r1atXFi1a1O7Yt7/97ZxwwglZuXJlBg4cWD6+//77p7a2dqvnWbBgQdavX59bbrkllZWVOeKII9LU1JRrrrkmkyZN2nGDAQAAAABgj9OhIfr2Wrt2bSoqKtK7d+92x6+88spcccUVGThwYM4999xMmTIl3br9dmiNjY055ZRTUllZWa6vr6/P//7f/zuvv/56DjjggF05BAAAgB1i4vwlHd0FAIC9QqcJ0d9+++1MmzYt55xzTqqrq8vH/+qv/irHHnts+vTpkyeeeCLTp0/PqlWrcs011yRJmpubM3jw4HbnqqmpKbdtLURva2tLW1tbeb+1tXVnDAkAAAAAgN1cpwjRN2zYkP/xP/5HSqVSbrzxxnZtU6dOLX89bNiwVFZW5i//8i8zZ86cVFVVfaD3mzNnTmbNmvWh+gwAAAAAQOe324foWwL0f//3f89DDz3U7in0rRkxYkQ2btyYX/3qVzn00ENTW1ublpaWdjVb9ovWUZ8+fXq7cL61tTUDBgz4kCMBEn92DAAAAEDn0qWjO7AtWwL0F198MQ888ED69u37nq9pampKly5d0q9fvyRJXV1dHn300WzYsKFcs2jRohx66KGF66FXVVWlurq63QYAAAAAwN6nQ59EX7duXV566aXy/ooVK9LU1JQ+ffrkoIMOyp/+6Z/mZz/7WRYuXJhNmzalubk5SdKnT59UVlamsbExTz75ZE499dTsv//+aWxszJQpU/LZz362HJCfe+65mTVrViZOnJhp06bl+eefz/XXX59rr722Q8YMAAAAAEDn0aEh+tNPP51TTz21vL9lCZUJEyZk5syZ+fGPf5wkOfroo9u97qc//WlGjhyZqqqq3H777Zk5c2ba2toyePDgTJkypd1SLL169cr999+fhoaGDB8+PAceeGBmzJiRSZMm7fwBAgAAAADQqXVoiD5y5MiUSqXC9m21Jcmxxx6bxYsXv+f7DBs2LI899th29w8AAAAAgL3bbr0mOgAAAAAAdCQhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAgW4d3QEAAAA6v4nzl2xX/bwLjt9JPQEA2LE8iQ4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFunV0BwBge0ycv2S76uddcPxO6gkAAACwN/AkOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAgQ4N0R999NGceeaZ6d+/fyoqKnLXXXe1ay+VSpkxY0YOOuig9OjRI6NGjcqLL77Yrua1117L+PHjU11dnd69e2fixIlZt25du5pnn302J598crp3754BAwbkqquu2tlDAwAAAABgD9ChIfqbb76Zo446KnPnzt1q+1VXXZVvfvObuemmm/Lkk09m3333TX19fd5+++1yzfjx47Ns2bIsWrQoCxcuzKOPPppJkyaV21tbWzN69OgMGjQoS5cuzdVXX52ZM2fm5ptv3unjAwAAAACgc+vWkW8+ZsyYjBkzZqttpVIp1113XS6//PJ8+tOfTpL8wz/8Q2pqanLXXXfl7LPPzi9+8Yvce++9WbJkSY477rgkybe+9a2cccYZ+bu/+7v0798/CxYsyPr163PLLbeksrIyRxxxRJqamnLNNde0C9uBD2bi/CUd3QUAAAAA2Gl22zXRV6xYkebm5owaNap8rFevXhkxYkQaGxuTJI2Njendu3c5QE+SUaNGpUuXLnnyySfLNaecckoqKyvLNfX19Vm+fHlef/31XTQaAAAAAAA6o902RG9ubk6S1NTUtDteU1NTbmtubk6/fv3atXfr1i19+vRpV7O1c7zzPX5XW1tbWltb220AALCnuvHGGzNs2LBUV1enuro6dXV1+ed//udy+9tvv52Ghob07ds3++23X8aNG5eWlpZ251i5cmXGjh2bnj17pl+/frn00kuzcePGdjUPP/xwjj322FRVVeWQQw7J/Pnzd8XwAADgQ9ltQ/SONGfOnPTq1au8DRgwoKO7BAAAO83BBx+cK6+8MkuXLs3TTz+dT33qU/n0pz+dZcuWJUmmTJmSn/zkJ7nzzjvzyCOP5NVXX81ZZ51Vfv2mTZsyduzYrF+/Pk888US+973vZf78+ZkxY0a5ZsWKFRk7dmxOPfXUNDU15ZJLLsnnP//53Hfffbt8vAAAsD22a030DRs2pFQqve/6Ll26pFu3D7bsem1tbZKkpaUlBx10UPl4S0tLjj766HLN6tWr271u48aNee2118qvr62tfddTMlv2t9T8runTp2fq1Knl/dbWVkE6AAC7jR09Lz/zzDPb7X/ta1/LjTfemMWLF+fggw/OvHnzctttt+VTn/pUkuTWW2/N4YcfnsWLF+fEE0/M/fffnxdeeCEPPPBAampqcvTRR+eKK67ItGnTMnPmzFRWVuamm27K4MGD841vfCNJcvjhh+fxxx/Ptddem/r6+g/wXwEAAHaN7Uq4jzjiiBx88MHvOWGvqKhIqVTKm2++maeeeuoDdWzw4MGpra3Ngw8+WA7NW1tb8+STT+aiiy5KktTV1WXNmjVZunRphg8fniR56KGHsnnz5owYMaJc85WvfCUbNmzIPvvskyRZtGhRDj300BxwwAFbfe+qqqpUVVV9oH4DAMDOtjPn5Zs2bcqdd96ZN998M3V1dVm6dGk2bNjQ7rOKDjvssAwcODCNjY058cQT09jYmKFDh7ZbRrG+vj4XXXRRli1blmOOOSaNjY3tzrGl5pJLLnn/AwcAgA6wXSH6vvvum4ceeuh91x9//PHbbF+3bl1eeuml8v6KFSvS1NSUPn36ZODAgbnkkkvyt3/7t/n93//9DB48OF/96lfTv3//fOYzn0ny26dXTj/99HzhC1/ITTfdlA0bNmTy5Mk5++yz079//yTJueeem1mzZmXixImZNm1ann/++Vx//fW59tprt2foAACw29jR8/Ikee6551JXV5e33347++23X374wx9myJAhaWpqSmVlZXr37t2u/nc/q+i9PoeoqKa1tTVvvfVWevTosdV+tbW1pa2trbzv84oAANjVtitEr6io2K6Tv1f9008/nVNPPbW8v2UJlQkTJmT+/Pm57LLL8uabb2bSpElZs2ZNTjrppNx7773p3r17+TULFizI5MmTc9ppp6VLly4ZN25cvvnNb5bbe/Xqlfvvvz8NDQ0ZPnx4DjzwwMyYMSOTJk3arrEAAMDuYkfPy5Pk0EMPTVNTU9auXZv/+3//byZMmJBHHnnkg3Zxh5kzZ05mzZrV0d0AAGAv9sEWLN9BRo4cuc0/Qa2oqMjs2bMze/bswpo+ffrktttu2+b7DBs2LI899tgH7icAAOzpKisrc8ghhyRJhg8fniVLluT666/Pn//5n2f9+vVZs2ZNu6fRW1pa2n0O0e8uF/O7n0NU9FlF1dXVhU+hJz6vCACAjtelozsAAADsfjZv3py2trYMHz48++yzTx588MFy2/Lly7Ny5crU1dUl+e3nED333HNZvXp1uWbRokWprq7OkCFDyjXvPMeWmi3nKFJVVZXq6up2GwAA7Eod+iQ6AADQ8aZPn54xY8Zk4MCBeeONN3Lbbbfl4Ycfzn333ZdevXpl4sSJmTp1avr06ZPq6upcfPHFqaury4knnpgkGT16dIYMGZLzzjsvV111VZqbm3P55ZenoaEhVVVVSZILL7ww3/72t3PZZZflc5/7XB566KHccccdufvuuzty6AAA8J62K0SvrKzMJz7xifddf+CBB253hwAAgG3b0fPy1atX5/zzz8+qVavSq1evDBs2LPfdd1/+6I/+KEly7bXXlj9/qK2tLfX19bnhhhvKr+/atWsWLlyYiy66KHV1ddl3330zYcKEdssyDh48OHfffXemTJmS66+/PgcffHC++93vpr6+fjtHDwAAu9Z2hegnnHBC/uu//ut9129ZUxEAANhxdvS8fN68edts7969e+bOnZu5c+cW1gwaNCj33HPPNs8zcuTIPPPMM9usAQCA3c12heiPPvpofvzjH2/zw0Df6c/+7M9yxRVXfKCOAQAAW2deDgAAu852hegVFRUZOHDg+65/v5N6AADg/TMvBwCAXafL9hRXVFRs18m3tx4AAHhv5uUAALDrbFeIDgAAAAAAexMhOgAAAAAAFNiuNdHfeuutzJ49+33VWncRAAB2DvNyAADYdbYrRP/Od76Tt956633X19fXb3eHAACAbTMvBwCAXWe7QvRTTjllZ/UDAAB4n8zLAQBg17EmOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAU6NbRHQCAnWni/CXbVT/vguN3Uk8AgHfyOxoA6Cw8iQ4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUKBbR3cA2L1MnL+ko7sAAAAAALsNT6IDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAgd0+RP/oRz+aioqKd20NDQ1JkpEjR76r7cILL2x3jpUrV2bs2LHp2bNn+vXrl0svvTQbN27siOEAAAAAANCJdOvoDryXJUuWZNOmTeX9559/Pn/0R3+UP/uzPysf+8IXvpDZs2eX93v27Fn+etOmTRk7dmxqa2vzxBNPZNWqVTn//POzzz775Otf//quGQQAAAAAAJ3Sbh+if+QjH2m3f+WVV+bjH/94/vAP/7B8rGfPnqmtrd3q6++///688MILeeCBB1JTU5Ojjz46V1xxRaZNm5aZM2emsrJyp/YfAAAAAIDOa7dfzuWd1q9fn3/8x3/M5z73uVRUVJSPL1iwIAceeGCOPPLITJ8+Pb/5zW/KbY2NjRk6dGhqamrKx+rr69Pa2pply5bt0v4DAAAAANC57PZPor/TXXfdlTVr1uSCCy4oHzv33HMzaNCg9O/fP88++2ymTZuW5cuX5wc/+EGSpLm5uV2AnqS839zcvNX3aWtrS1tbW3m/tbV1B48EAAAAAIDOoFOF6PPmzcuYMWPSv3//8rFJkyaVvx46dGgOOuignHbaaXn55Zfz8Y9//AO9z5w5czJr1qwP3V8AAAAAADq3TrOcy7//+7/ngQceyOc///lt1o0YMSJJ8tJLLyVJamtr09LS0q5my37ROurTp0/P2rVry9srr7zyYbsPAAAAAEAn1GlC9FtvvTX9+vXL2LFjt1nX1NSUJDnooIOSJHV1dXnuueeyevXqcs2iRYtSXV2dIUOGbPUcVVVVqa6ubrcBAAAAALD36RTLuWzevDm33nprJkyYkG7d/l+XX3755dx2220544wz0rdv3zz77LOZMmVKTjnllAwbNixJMnr06AwZMiTnnXderrrqqjQ3N+fyyy9PQ0NDqqqqOmpIAAAAAAB0Ap0iRH/ggQeycuXKfO5zn2t3vLKyMg888ECuu+66vPnmmxkwYEDGjRuXyy+/vFzTtWvXLFy4MBdddFHq6uqy7777ZsKECZk9e/auHgYAAAAAAJ1MpwjRR48enVKp9K7jAwYMyCOPPPKerx80aFDuueeendE1AAAAAAD2YJ0iRAeAXWXi/CXbVT/vguN3Uk8AAACA3UGn+WBRAAAAAADY1YToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUECIDgAAe7k5c+bk+OOPz/77759+/frlM5/5TJYvX96u5u23305DQ0P69u2b/fbbL+PGjUtLS0u7mpUrV2bs2LHp2bNn+vXrl0svvTQbN25sV/Pwww/n2GOPTVVVVQ455JDMnz9/Zw8PAAA+FCE6AADs5R555JE0NDRk8eLFWbRoUTZs2JDRo0fnzTffLNdMmTIlP/nJT3LnnXfmkUceyauvvpqzzjqr3L5p06aMHTs269evzxNPPJHvfe97mT9/fmbMmFGuWbFiRcaOHZtTTz01TU1NueSSS/L5z38+99133y4dLwAAbI9uHd0BAACgY917773t9ufPn59+/fpl6dKlOeWUU7J27drMmzcvt912Wz71qU8lSW699dYcfvjhWbx4cU488cTcf//9eeGFF/LAAw+kpqYmRx99dK644opMmzYtM2fOTGVlZW666aYMHjw43/jGN5Ikhx9+eB5//PFce+21qa+v3+XjBgCA98OT6AAAQDtr165NkvTp0ydJsnTp0mzYsCGjRo0q1xx22GEZOHBgGhsbkySNjY0ZOnRoampqyjX19fVpbW3NsmXLyjXvPMeWmi3nAACA3ZEn0QEAgLLNmzfnkksuySc/+ckceeSRSZLm5uZUVlamd+/e7WpramrS3NxcrnlngL6lfUvbtmpaW1vz1ltvpUePHu/qT1tbW9ra2sr7ra2tH26AAACwnTyJDgAAlDU0NOT555/P7bff3tFdSfLbDz3t1atXeRswYEBHdwkAgL2MEB0AAEiSTJ48OQsXLsxPf/rTHHzwweXjtbW1Wb9+fdasWdOuvqWlJbW1teWalpaWd7VvadtWTXV19VafQk+S6dOnZ+3ateXtlVde+VBjBACA7SVEBwCAvVypVMrkyZPzwx/+MA899FAGDx7crn348OHZZ5998uCDD5aPLV++PCtXrkxdXV2SpK6uLs8991xWr15drlm0aFGqq6szZMiQcs07z7GlZss5tqaqqirV1dXtNgAA2JWsiQ4AAHu5hoaG3HbbbfnRj36U/fffv7yGea9evdKjR4/06tUrEydOzNSpU9OnT59UV1fn4osvTl1dXU488cQkyejRozNkyJCcd955ueqqq9Lc3JzLL788DQ0NqaqqSpJceOGF+fa3v53LLrssn/vc5/LQQw/ljjvuyN13391hYwcAgPciRAcAgL3cjTfemCQZOXJku+O33nprLrjggiTJtddemy5dumTcuHFpa2tLfX19brjhhnJt165ds3Dhwlx00UWpq6vLvvvumwkTJmT27NnlmsGDB+fuu+/OlClTcv311+fggw/Od7/73dTX1+/0MdL5TZy/ZLtfM++C43dCTwCAvY0QHQAA9nKlUuk9a7p37565c+dm7ty5hTWDBg3KPffcs83zjBw5Ms8888x29xEAADqKNdEBAAAAAKCAEB0AAAAAAAoI0QEAAAAAoIAQHQAAAAAACvhgUdjDTZy/pKO7AAAAAACdlifRAQAAAACggBAdAAAAAAAKCNEBAAAAAKCAEB0AAAAAAAoI0QEAAAAAoEC3ju4AsH0mzl/S0V0AAAAAgL2GEB0APoTt/R9b8y44fif1BAAAANgZLOcCAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQYLcO0WfOnJmKiop222GHHVZuf/vtt9PQ0JC+fftmv/32y7hx49LS0tLuHCtXrszYsWPTs2fP9OvXL5deemk2bty4q4cCAAAAAEAn1K2jO/BejjjiiDzwwAPl/W7d/l+Xp0yZkrvvvjt33nlnevXqlcmTJ+ess87Kv/zLvyRJNm3alLFjx6a2tjZPPPFEVq1alfPPPz/77LNPvv71r+/ysQAAAAAA0Lns9iF6t27dUltb+67ja9euzbx583LbbbflU5/6VJLk1ltvzeGHH57FixfnxBNPzP33358XXnghDzzwQGpqanL00UfniiuuyLRp0zJz5sxUVlbu6uEAAAAAANCJ7NbLuSTJiy++mP79++djH/tYxo8fn5UrVyZJli5dmg0bNmTUqFHl2sMOOywDBw5MY2NjkqSxsTFDhw5NTU1Nuaa+vj6tra1ZtmzZrh0IAAAAAACdzm79JPqIESMyf/78HHrooVm1alVmzZqVk08+Oc8//3yam5tTWVmZ3r17t3tNTU1NmpubkyTNzc3tAvQt7VvairS1taWtra2839rauoNGBAAAAABAZ7Jbh+hjxowpfz1s2LCMGDEigwYNyh133JEePXrstPedM2dOZs2atdPODwAAAABA57DbL+fyTr17984f/MEf5KWXXkptbW3Wr1+fNWvWtKtpaWkpr6FeW1ublpaWd7VvaSsyffr0rF27try98sorO3YgAAAAAAB0Cp0qRF+3bl1efvnlHHTQQRk+fHj22WefPPjgg+X25cuXZ+XKlamrq0uS1NXV5bnnnsvq1avLNYsWLUp1dXWGDBlS+D5VVVWprq5utwEAAAAAsPfZrZdz+Zu/+ZuceeaZGTRoUF599dX8r//1v9K1a9ecc8456dWrVyZOnJipU6emT58+qa6uzsUXX5y6urqceOKJSZLRo0dnyJAhOe+883LVVVelubk5l19+eRoaGlJVVdXBowMAAAAAYHe3W4fo//Ef/5Fzzjknv/71r/ORj3wkJ510UhYvXpyPfOQjSZJrr702Xbp0ybhx49LW1pb6+vrccMMN5dd37do1CxcuzEUXXZS6urrsu+++mTBhQmbPnt1RQwIAAAAAoBPZrUP022+/fZvt3bt3z9y5czN37tzCmkGDBuWee+7Z0V0DAAAAAGAv0KnWRAcAAAAAgF1JiA4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQoFtHdwAAAAB2honzl2xX/bwLjt9JPQEAOjNPogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAECBbh3dAQDYm0ycv2S76uddcPxO6gkAAADwfgjRoYNtb6AGAAAAAOw6lnMBAAAAAIACQnQAAAAAACggRAcAAAAAgAJCdAAAAAAAKCBEBwAAAACAAkJ0AAAAAAAoIEQHAAAAAIAC3Tq6AwAAALA7mDh/yXbVz7vg+J3UEwBgd+JJdAAAAAAAKCBEBwAAAACAAkJ0AAAAAAAoIEQHAAAAAIACPlgUdrDt/TAiAABIzCMBAHZXnkQHAAAAAIACQnQAAAAAACggRAcAAPLoo4/mzDPPTP/+/VNRUZG77rqrXXupVMqMGTNy0EEHpUePHhk1alRefPHFdjWvvfZaxo8fn+rq6vTu3TsTJ07MunXr2tU8++yzOfnkk9O9e/cMGDAgV1111c4eGgAAfChCdAAAIG+++WaOOuqozJ07d6vtV111Vb75zW/mpptuypNPPpl999039fX1efvtt8s148ePz7Jly7Jo0aIsXLgwjz76aCZNmlRub21tzejRozNo0KAsXbo0V199dWbOnJmbb755p48PAAA+KB8sCgAAZMyYMRkzZsxW20qlUq677rpcfvnl+fSnP50k+Yd/+IfU1NTkrrvuytlnn51f/OIXuffee7NkyZIcd9xxSZJvfetbOeOMM/J3f/d36d+/fxYsWJD169fnlltuSWVlZY444og0NTXlmmuuaRe2AwDA7sST6AAAwDatWLEizc3NGTVqVPlYr169MmLEiDQ2NiZJGhsb07t373KAniSjRo1Kly5d8uSTT5ZrTjnllFRWVpZr6uvrs3z58rz++utbfe+2tra0tra22wAAYFcSogMAANvU3NycJKmpqWl3vKamptzW3Nycfv36tWvv1q1b+vTp065ma+d453v8rjlz5qRXr17lbcCAAR9+QAAAsB2E6AAAwG5r+vTpWbt2bXl75ZVXOrpLAADsZYToAADANtXW1iZJWlpa2h1vaWkpt9XW1mb16tXt2jdu3JjXXnutXc3WzvHO9/hdVVVVqa6ubrcBAMCuJEQHAAC2afDgwamtrc2DDz5YPtba2ponn3wydXV1SZK6urqsWbMmS5cuLdc89NBD2bx5c0aMGFGuefTRR7Nhw4ZyzaJFi3LooYfmgAMO2EWjAQCA7SNEBwAAsm7dujQ1NaWpqSnJbz9MtKmpKStXrkxFRUUuueSS/O3f/m1+/OMf57nnnsv555+f/v375zOf+UyS5PDDD8/pp5+eL3zhC3nqqafyL//yL5k8eXLOPvvs9O/fP0ly7rnnprKyMhMnTsyyZcvy/e9/P9dff32mTp3aQaMGAID31q2jOwAAAHS8p59+Oqeeemp5f0uwPWHChMyfPz+XXXZZ3nzzzUyaNClr1qzJSSedlHvvvTfdu3cvv2bBggWZPHlyTjvttHTp0iXjxo3LN7/5zXJ7r169cv/996ehoSHDhw/PgQcemBkzZmTSpEm7bqCwA02cv2S76uddcPxO6gkAsDMJ0QEAgIwcOTKlUqmwvaKiIrNnz87s2bMLa/r06ZPbbrttm+8zbNiwPPbYYx+4nwAAsKsJ0QFgN+YJNwAAAOhY1kQHAAAAAIACQnQAAAAAACggRAcAAAAAgAJCdAAAAAAAKCBEBwAAAACAAkJ0AAAAAAAoIEQHAAAAAIACQnQAAAAAACiwW4foc+bMyfHHH5/9998//fr1y2c+85ksX768Xc3IkSNTUVHRbrvwwgvb1axcuTJjx45Nz549069fv1x66aXZuHHjrhwKAAAAAACdULeO7sC2PPLII2loaMjxxx+fjRs35stf/nJGjx6dF154Ifvuu2+57gtf+EJmz55d3u/Zs2f5602bNmXs2LGpra3NE088kVWrVuX888/PPvvsk69//eu7dDwAAAAAAHQuu3WIfu+997bbnz9/fvr165elS5fmlFNOKR/v2bNnamtrt3qO+++/Py+88EIeeOCB1NTU5Oijj84VV1yRadOmZebMmamsrNypYwAAAAAAoPParZdz+V1r165NkvTp06fd8QULFuTAAw/MkUcemenTp+c3v/lNua2xsTFDhw5NTU1N+Vh9fX1aW1uzbNmyXdNxAAAAAAA6pd36SfR32rx5cy655JJ88pOfzJFHHlk+fu6552bQoEHp379/nn322UybNi3Lly/PD37wgyRJc3NzuwA9SXm/ubl5q+/V1taWtra28n5ra+uOHg4AAAAAAJ1ApwnRGxoa8vzzz+fxxx9vd3zSpEnlr4cOHZqDDjoop512Wl5++eV8/OMf/0DvNWfOnMyaNetD9RcAAAAAgM6vUyznMnny5CxcuDA//elPc/DBB2+zdsSIEUmSl156KUlSW1ublpaWdjVb9ovWUZ8+fXrWrl1b3l555ZUPOwQAAAAAADqh3fpJ9FKplIsvvjg//OEP8/DDD2fw4MHv+ZqmpqYkyUEHHZQkqaury9e+9rWsXr06/fr1S5IsWrQo1dXVGTJkyFbPUVVVlaqqqh0zCDq9ifOXdHQXAAAAAIAOsluH6A0NDbntttvyox/9KPvvv395DfNevXqlR48eefnll3PbbbfljDPOSN++ffPss89mypQpOeWUUzJs2LAkyejRozNkyJCcd955ueqqq9Lc3JzLL788DQ0NgnIAAAAAALZpt17O5cYbb8zatWszcuTIHHTQQeXt+9//fpKksrIyDzzwQEaPHp3DDjssf/3Xf51x48blJz/5SfkcXbt2zcKFC9O1a9fU1dXls5/9bM4///zMnj27o4YFAAAAAEAnsVs/iV4qlbbZPmDAgDzyyCPveZ5Bgwblnnvu2VHdAgAAAABgL7FbP4kOAAAAAAAdSYgOAAAAAAAFhOgAAAAAAFBAiA4AAAAAAAWE6AAAAAAAUECIDgAAAAAABYToAAAAAABQQIgOAAAAAAAFhOgAAAAAAFCgW0d3AADYcSbOX7Jd9fMuOH4n9QQAAAD2DEJ0AAAA2AX8z24A6JyE6Ox1tnfiCgAAAADsvayJDgAAAAAABYToAAAAAABQwHIuALAX+yBLXFmfFQAAgL2JJ9EBAAAAAKCAEB0AAAAAAAoI0QEAAAAAoIAQHQAAAAAACgjRAQAAAACggBAdAAAAAAAKCNEBAAAAAKCAEB0AAAAAAAoI0QEAAAAAoIAQHQAAAAAACgjRAQAAAACgQLeO7gAA0LlMnL9ku+rnXXD8TuoJAAAA7HyeRAcAAAAAgAJCdAAAAAAAKCBEBwAAAACAAkJ0AAAAAAAoIEQHAAAAAIACQnQAAAAAACggRAcAAAAAgAJCdAAAAAAAKNCtozsAH9bE+Us6ugsAAAA73Pbe68y74Pid1BMA2Lt5Eh0AAAAAAAoI0QEAAAAAoIAQHQAAAAAAClgTHQDYqaznCgAAQGfmSXQAAAAAACggRAcAAAAAgAJCdAAAAAAAKCBEBwAAAACAAj5YlN3O9n4AHQAAAADAzuJJdAAAAAAAKOBJdAAAANgDbO9f9c674Pid1BMA2LMI0QGATk1gAAAAwM4kRAcAdis+GwMAAIDdiTXRAQAAAACggCfR2ek8UQgAALD7sSQaALw/QnQAAICdwMMkAAB7BiE6AAAA8J48uQ7A3kqIDgDsVXb2k6ECAwAAgD3LXhWiz507N1dffXWam5tz1FFH5Vvf+lZOOOGEju5Wp+PPUgEA+DDMy2Hv4Ml1APYUe02I/v3vfz9Tp07NTTfdlBEjRuS6665LfX19li9fnn79+nV09wAAYK9gXg4UEboDsLuqKJVKpY7uxK4wYsSIHH/88fn2t7+dJNm8eXMGDBiQiy++OF/60pe2+drW1tb06tUra9euTXV19a7o7i7lyXIA2HHc0PN+7Onzy235MPPypHP9tzPPhs7N73SAPd/7nVvuFU+ir1+/PkuXLs306dPLx7p06ZJRo0alsbGxA3sGAOxpdrfQbHsDAE8BsjOZlwOdic9RAWCLvSJE/+///u9s2rQpNTU17Y7X1NTkX//1X99V39bWlra2tvL+2rVrk/z2/0x0hIYFSzvkfQGAzu+8G3/aqc8/d/zw7arf3nnT9p5/R9kyr9xL/ii0bHvn5cnuNzffHuvfWtfRXQB2Yzv7d+iu0FG/RwF2lPc7L98rQvTtNWfOnMyaNetdxwcMGNABvQEA2Hv94//s3Od/L2+88UZ69erVsZ3YzZmbA+y+Ovr3KMCO8l7z8r0iRD/wwAPTtWvXtLS0tDve0tKS2trad9VPnz49U6dOLe9v3rw5r732Wvr27ZuKioqd3l8+nNbW1gwYMCCvvPLKbr9OJh3P9cL75Vphe7heeC+lUilvvPFG+vfv39Fd2aW2d16e7Ji5uZ/JPYPv457D93LP4Pu45/C93DP4Pn4w73devleE6JWVlRk+fHgefPDBfOYzn0ny28n3gw8+mMmTJ7+rvqqqKlVVVe2O9e7dexf0lB2purraPxq8b64X3i/XCtvD9cK27I1PoG/vvDzZsXNzP5N7Bt/HPYfv5Z7B93HP4Xu5Z/B93H7vZ16+V4ToSTJ16tRMmDAhxx13XE444YRcd911efPNN/MXf/EXHd01AADYa5iXAwDQ2ew1Ifqf//mf57/+678yY8aMNDc35+ijj8699977rg81AgAAdh7zcgAAOpu9JkRPksmTJxf+mSh7jqqqqvyv//W/3vVnv7A1rhfeL9cK28P1Atu2q+flfib3DL6Pew7fyz2D7+Oew/dyz+D7uHNVlEqlUkd3AgAAAAAAdkddOroDAAAAAACwuxKiAwAAAABAASE6AAAAAAAUEKLTKV155ZWpqKjIJZdcUj729ttvp6GhIX379s1+++2XcePGpaWlpd3rVq5cmbFjx6Znz57p169fLr300mzcuHEX955d4T//8z/z2c9+Nn379k2PHj0ydOjQPP300+X2UqmUGTNm5KCDDkqPHj0yatSovPjii+3O8dprr2X8+PGprq5O7969M3HixKxbt25XD4WdaNOmTfnqV7+awYMHp0ePHvn4xz+eK664Iu/8uBDXyt7r0UcfzZlnnpn+/funoqIid911V7v2HXVtPPvsszn55JPTvXv3DBgwIFddddXOHhrsVebOnZuPfvSj6d69e0aMGJGnnnqqo7vEO8yZMyfHH3989t9///Tr1y+f+cxnsnz58nY15vmdj/u1zs291J7BvU7n5B5kN1aCTuapp54qffSjHy0NGzas9MUvfrF8/MILLywNGDCg9OCDD5aefvrp0oknnlj6xCc+UW7fuHFj6cgjjyyNGjWq9Mwzz5Tuueee0oEHHliaPn16B4yCnem1114rDRo0qHTBBReUnnzyydIvf/nL0n333Vd66aWXyjVXXnllqVevXqW77rqr9POf/7z0x3/8x6XBgweX3nrrrXLN6aefXjrqqKNKixcvLj322GOlQw45pHTOOed0xJDYSb72ta+V+vbtW1q4cGFpxYoVpTvvvLO03377la6//vpyjWtl73XPPfeUvvKVr5R+8IMflJKUfvjDH7Zr3xHXxtq1a0s1NTWl8ePHl55//vnSP/3TP5V69OhR+s53vrOrhgl7tNtvv71UWVlZuuWWW0rLli0rfeELXyj17t271NLS0tFd4/9XX19fuvXWW0vPP/98qampqXTGGWeUBg4cWFq3bl25xjy/c3G/1rm5l9pzuNfpnNyD7L6E6HQqb7zxRun3f//3S4sWLSr94R/+YXlStmbNmtI+++xTuvPOO8u1v/jFL0pJSo2NjaVS6bf/EHXp0qXU3NxcrrnxxhtL1dXVpba2tl06DnauadOmlU466aTC9s2bN5dqa2tLV199dfnYmjVrSlVVVaV/+qd/KpVKpdILL7xQSlJasmRJueaf//mfSxUVFaX//M//3HmdZ5caO3Zs6XOf+1y7Y2eddVZp/PjxpVLJtcL/87sT2B11bdxwww2lAw44oN3voWnTppUOPfTQnTwi2DuccMIJpYaGhvL+pk2bSv379y/NmTOnA3vFtqxevbqUpPTII4+USiXz/M7G/Vrn515qz+Fep/NzD7J7sZwLnUpDQ0PGjh2bUaNGtTu+dOnSbNiwod3xww47LAMHDkxjY2OSpLGxMUOHDk1NTU25pr6+Pq2trVm2bNmuGQC7xI9//OMcd9xx+bM/+7P069cvxxxzTP7+7/++3L5ixYo0Nze3u1569eqVESNGtLteevfuneOOO65cM2rUqHTp0iVPPvnkrhsMO9UnPvGJPPjgg/m3f/u3JMnPf/7zPP744xkzZkwS1wrFdtS10djYmFNOOSWVlZXlmvr6+ixfvjyvv/76LhoN7JnWr1+fpUuXtvs57dKlS0aNGlX+OWX3s3bt2iRJnz59kpjndzbu1zo/91J7Dvc6ex73IB2rW0d3AN6v22+/PT/72c+yZMmSd7U1NzensrIyvXv3bne8pqYmzc3N5Zp3Tsi2tG9pY8/xy1/+MjfeeGOmTp2aL3/5y1myZEn+6q/+KpWVlZkwYUL5+7216+Gd10u/fv3atXfr1i19+vRxvexBvvSlL6W1tTWHHXZYunbtmk2bNuVrX/taxo8fnySuFQrtqGujubk5gwcPftc5trQdcMABO6X/sDf47//+72zatGmrP6f/+q//2kG9Yls2b96cSy65JJ/85Cdz5JFHJjHP70zcr+0Z3EvtOdzr7Hncg3QsITqdwiuvvJIvfvGLWbRoUbp3797R3WE3t3nz5hx33HH5+te/niQ55phj8vzzz+emm27KhAkTOrh37E7uuOOOLFiwILfddluOOOKINDU15ZJLLkn//v1dKwCwizU0NOT555/P448/3tFdYTu5X9tzuJfac7jXgR3Lci50CkuXLs3q1atz7LHHplu3bunWrVseeeSRfPOb30y3bt1SU1OT9evXZ82aNe1e19LSktra2iRJbW3tuz79fcv+lhr2DAcddFCGDBnS7tjhhx+elStXJvl/3++tXQ/vvF5Wr17drn3jxo157bXXXC97kEsvvTRf+tKXcvbZZ2fo0KE577zzMmXKlMyZMyeJa4ViO+ra8LsJdp4DDzwwXbt23ebPKbuPyZMnZ+HChfnpT3+agw8+uHy8trbWPL8TcL+253Avtedwr7PncQ/SsYTodAqnnXZannvuuTQ1NZW34447LuPHjy9/vc8+++TBBx8sv2b58uVZuXJl6urqkiR1dXV57rnn2v1jsmjRolRXV79rkkDn9slPfjLLly9vd+zf/u3fMmjQoCTJ4MGDU1tb2+56aW1tzZNPPtnuelmzZk2WLl1arnnooYeyefPmjBgxYheMgl3hN7/5Tbp0af+rsGvXrtm8eXMS1wrFdtS1UVdXl0cffTQbNmwo1yxatCiHHnqoP6OED6mysjLDhw9v93O6efPmPPjgg+WfUzpeqVTK5MmT88Mf/jAPPfTQu/68fPjw4eb5nYD7tT2He6k9h3udPY97kA7W0Z9sCh/UOz/tvVQqlS688MLSwIEDSw899FDp6aefLtXV1ZXq6urK7Rs3biwdeeSRpdGjR5eamppK9957b+kjH/lIafr06R3Qe3amp556qtStW7fS1772tdKLL75YWrBgQalnz56lf/zHfyzXXHnllaXevXuXfvSjH5WeffbZ0qc//enS4MGDS2+99Va55vTTTy8dc8wxpSeffLL0+OOPl37/93+/dM4553TEkNhJJkyYUPq93/u90sKFC0srVqwo/eAHPygdeOCBpcsuu6xc41rZe73xxhulZ555pvTMM8+UkpSuueaa0jPPPFP693//91KptGOujTVr1pRqampK5513Xun5558v3X777aWePXuWvvOd7+zy8cKe6Pbbby9VVVWV5s+fX3rhhRdKkyZNKvXu3bvU3Nzc0V3j/3fRRReVevXqVXr44YdLq1atKm+/+c1vyjXm+Z2T+7XOyb3UnsO9TufkHmT3JUSn0/rdSdlbb71V+p//83+WDjjggFLPnj1Lf/Inf1JatWpVu9f86le/Ko0ZM6bUo0eP0oEHHlj667/+69KGDRt2cc/ZFX7yk5+UjjzyyFJVVVXpsMMOK918883t2jdv3lz66le/WqqpqSlVVVWVTjvttNLy5cvb1fz6178unXPOOaX99tuvVF1dXfqLv/iL0htvvLErh8FO1traWvriF79YGjhwYKl79+6lj33sY6WvfOUrpba2tnKNa2Xv9dOf/rSU5F3bhAkTSqXSjrs2fv7zn5dOOumkUlVVVen3fu/3SldeeeWuGiLsFb71rW+VBg4cWKqsrCydcMIJpcWLF3d0l3iHrf07m6R06623lmvM8zsn92udl3upPYN7nc7JPcjuq6JUKpV29dPvAAAAAADQGVgTHQAAAAAACgjRAQAAAACggBAdAAAAAAAKCNEBAAAAAKCAEB0AAAAAAAoI0QEAAAAAoIAQHQAAAAAACgjRAQAAAACggBAdAAAAAAAKdOvoDgCwe3nkkUfyl3/5l+nevXu745s3b84f/uEf5qmnnkpbW9u7Xrdu3bosW7Ys1113Xf7P//k/6dat/a+Y9evX5ytf+UpOPPHEjBkzJj179nzXOQYPHpwf/vCHO3ZAAADQCZmXA+w+hOgAtPPWW2/l7LPPzsyZM9sd/9WvfpUvfelLqaioSFNT07teN3LkyJRKpbz++uv59re/nZEjR7Zrnz9/ft54441s2LAhn/jEJzJ//vx3nePEE0/ccQMBAIBOzLwcYPdhORcAAAAAACggRAcAAAAAgAJCdAAAAAAAKCBEBwAAAACAAkJ0AAAAAAAoIEQHAAAAAIACQnQAAAAAACggRAcAAAAAgAJCdAAAAAAAKCBEBwAAAACAAt06ugMA7F569eqVhQsXZuHChe9qq6+vz5o1a3Lcccdt9bVdunTJwQcfnL/5m7/ZavuXv/zl9OjRI88///xWzzF06NAP13kAANhDmJcD7D4qSqVSqaM7AQAAAAAAuyPLuQAAAAAAQAEhOgAAAAAAFBCiAwAAAABAASE6AAAAAAAUEKIDAAAAAEABIToAAAAAABQQogMAAAAAQAEhOgAAAAAAFBCiAwAAAABAgf8PVhKHY3CI0H4AAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 长度区间分布 ===\n",
      "输入长度区间分布:\n",
      "0-50: 2417 条 (8.47%)\n",
      "50-100: 796 条 (2.79%)\n",
      "100-200: 7845 条 (27.49%)\n",
      "200-500: 17435 条 (61.10%)\n",
      "500-1000: 40 条 (0.14%)\n",
      "1000-2000: 0 条 (0.00%)\n",
      "2000-∞: 0 条 (0.00%)\n",
      "\n",
      "输出长度区间分布:\n",
      "0-100: 0 条 (0.00%)\n",
      "100-200: 0 条 (0.00%)\n",
      "200-500: 4 条 (0.01%)\n",
      "500-1000: 25714 条 (90.12%)\n",
      "1000-2000: 2815 条 (9.87%)\n",
      "2000-3000: 0 条 (0.00%)\n",
      "3000-∞: 0 条 (0.00%)\n",
      "\n",
      "思维过程长度区间分布:\n",
      "0-100: 0 条 (0.00%)\n",
      "100-200: 0 条 (0.00%)\n",
      "200-500: 2097 条 (7.35%)\n",
      "500-1000: 26405 条 (92.54%)\n",
      "1000-2000: 31 条 (0.11%)\n",
      "2000-3000: 0 条 (0.00%)\n",
      "3000-∞: 0 条 (0.00%)\n",
      "\n",
      "=== 随机CoT样本示例 ===\n",
      "\n",
      "样本 1:\n",
      "输入 (231字符): **问题：**  \n",
      "2015年10月13日11时许，被告人何某在武汉市新洲区邾城街衡州大街金鹤宾馆8102房门口，以人民币500元的价格向陈某贩卖10颗甲基苯丙胺片剂（“麻果”）和1包甲基苯丙胺（冰毒），交易完成后被当场抓获。经鉴定，毒品净重1.01克，均为甲基苯丙胺。何某自愿认罪。根据《刑法》第347条，公诉机关建议判处有期徒刑并处罚金。本案中，何某的行为是否完全符合走私、贩卖、运输、制造毒品罪...\n",
      "思维过程 (695字符): **  \n",
      "1. **犯罪构成要件分析**  \n",
      "   - **客观要件**：  \n",
      "     - **行为**：何某实施了贩卖毒品的行为（以500元价格向陈某交付毒品）。  \n",
      "     - **结果**：毒品交易完成（1.01克甲基苯丙胺已实际转移）。  \n",
      "     - **因果关系**：何某的行为直接导致毒品流入社会，侵害了国家对毒品的管制秩序。  \n",
      "   - **主观要件**：  \n",
      "     - ...\n",
      "答案部分 (134字符): \n",
      "\n",
      "**\n",
      "  \n",
      "\n",
      "被告人何某的行为完全符合《刑法》第347条贩卖毒品罪的构成要件，其主观上具有贩卖毒品的故意，客观上实施了交易行为。鉴于毒品数量较小（1.01克）且其自愿认罪，法院判处8个月有期徒刑及2000元罚金量刑适当，符合法律规定和司法实践对类似情节的处理标准。...\n",
      "\n",
      "样本 2:\n",
      "输入 (279字符): 问题生成  \n",
      "被告人刘某在2015年8月26日至2016年1月期间，以帮助被害人杨某办理医院环境评估审批等事宜为由，骗取杨某人民币9800元。2016年8月29日，刘某被抓获归案后如实供述了主要事实，其家属在审理期间退赔全部违法所得9800元。根据《刑法》第266条，本案中：  \n",
      "1. 刘某虚构“办理审批”事实骗取钱财的行为是否完全符合诈骗罪的构成要件？  \n",
      "2. 涉案金额9800元属于“数额较大...\n",
      "思维过程 (688字符): #### 1. 犯罪构成要件分析  \n",
      "**客观要件**：  \n",
      "- **行为**：刘某虚构“帮助办理审批”的事实（虚假承诺），使被害人陷入错误认识而交付钱财（9800元），符合诈骗罪中“虚构事实、隐瞒真相”的行为特征。  \n",
      "- **结果**：被害人实际遭受财产损失（9800元），且该损失与刘某的欺骗行为直接相关（因果关系成立）。  \n",
      "- **金额**：9800元达到诈骗罪立案标准（根据司法解释，诈骗...\n",
      "答案部分 (171字符): \n",
      "\n",
      "---\n",
      "\n",
      "### 思考过程  \n",
      "\n",
      "  \n",
      "\n",
      "---\n",
      "\n",
      "### 解答  \n",
      "被告人刘某以虚构办理审批事项为由骗取9800元，其行为完全符合诈骗罪的构成要件（主观故意+客观欺骗行为+因果关系）。涉案金额属于“数额较大”，依法应处3年以下有期徒刑。考虑到其坦白、全额退赔等从轻情节，法院判处11个月有期徒刑并处罚金1000元符合法律规定，量刑适当。...\n",
      "\n",
      "样本 3:\n",
      "输入 (280字符): 问题生成：\n",
      "被告人赵××于2016年1月在天津市北辰区双街镇××小区底商××门脸房内，以营利为目的设置三组24台具备赌博功能的游戏机（财神爷8台、一箭双雕8台、无名捕鱼机8台），通过上分、下分兑换现金的方式供他人赌博。2016年1月27日被公安机关当场查获，涉案游戏机经鉴定均具备赌博功能。公诉机关指控其行为构成开设赌场罪，建议判处5至6个月有期徒刑。根据《刑法》第303条，本案中：1. 赵××的行...\n",
      "思维过程 (756字符): 1. **犯罪构成要件分析**  \n",
      "   - **客观要件**：  \n",
      "     - 行为：设置24台经鉴定的赌博机（财神爷、一箭双雕、捕鱼机），提供现金兑换服务（上分、下分）。  \n",
      "     - 结果：建立固定赌博场所供他人参赌，破坏社会管理秩序。  \n",
      "     - 因果关系：赵××的经营行为直接促成赌博活动的持续进行。  \n",
      "   - **主观要件**：明确以营利为目的（指控事实中明确提及），具有...\n",
      "答案部分 (220字符): \n",
      "\n",
      "思考过程：\n",
      "\n",
      "### 解答：\n",
      "赵××的行为完全符合《刑法》第303条开设赌场罪的构成要件：其以营利为目的，在固定场所设置24台经鉴定的赌博机并提供现金兑换服务，主观故意与客观行为均满足该罪要求。量刑上，虽然涉案赌博机数量达到\"情节严重\"标准（10台以上），但综合考虑经营时间较短（不足1个月）、无其他加重情节，判处5个月有期徒刑并处罚金10000元符合罪责刑相适应原则，判决适当。法律依据为《刑法...\n",
      "\n",
      "样本 4:\n",
      "输入 (267字符): 法律问题：\n",
      "2013年10月19日08时36分许，被告人田某驾驶冀D×××××号微型轿车在邯郸市南迎宾道由南向北行驶至小北堡村口时，因驶入道路西侧与横过马路的行人户某（怀抱孙女户某某）发生碰撞，导致户某经抢救无效死亡、户某某受伤及车辆损坏。田某肇事后逃逸，但于当日11时驾驶肇事车辆投案并如实供述。经交警部门认定，田某负事故全部责任，且存在酒后驾驶情节。田某已赔偿被害人亲属53万元。根据《中华人民共...\n",
      "思维过程 (796字符): 1. **犯罪构成要件分析**  \n",
      "   - **客观要件**：  \n",
      "     - **行为**：田某驾驶机动车违反交通规则（驶入对向车道）导致碰撞行人（明确问题中\"驶入道路西侧\"的行为描述）。  \n",
      "     - **结果**：造成1人死亡、1人受伤及财产损失（问题明确\"户某死亡、户某某受伤及车辆损坏\"）。  \n",
      "     - **因果关系**：交警责任认定田某负全责（问题中\"承担事故的全部责任\"）...\n",
      "答案部分 (145字符): \n",
      "\n",
      "被告人田某的行为构成《刑法》第133条交通肇事罪，其逃逸行为属于加重情节，但因自首及赔偿可从轻处罚。检察院建议的二年以上三年以下有期徒刑适当，理由包括：全责认定、逃逸与自首情节并存、已赔偿53万元取得谅解，符合罪刑相适应原则。最终判决24个月有期徒刑（在建议幅度内）且未处罚金合法合理。...\n",
      "\n",
      "样本 5:\n",
      "输入 (27字符): 根据《刑法》第133条，张某的行为是否构成交通肇事罪？...\n",
      "思维过程 (739字符): 1. **犯罪构成要件分析**  \n",
      "   - **客观要件**：  \n",
      "     - **行为**：张某酒后驾驶机动车（危险行为） + 肇事后逃逸（加重行为）。  \n",
      "     - **结果**：直接导致被害人重伤二级（法定危害结果）。  \n",
      "     - **因果关系**：交警认定张某负全责，证明其违法行为与损害结果存在直接因果关系。  \n",
      "   - **主观要件**：  \n",
      "     - 酒后驾驶属于过...\n",
      "答案部分 (108字符): \n",
      "\n",
      "被告人张某的行为构成交通肇事罪（肇事后逃逸），符合《刑法》第133条的加重情节。法院判处36个月有期徒刑处于法定刑下限，在无其他从轻情节的情况下，量刑适当。但需注意，若存在未披露的从轻情节（如赔偿），则可能偏重。...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def merge_cot_jsonl_files(input_files, output_file):\n",
    "    \"\"\"\n",
    "    合并多个JSONL文件，保留所有字段\n",
    "    \n",
    "    Args:\n",
    "        input_files: 输入JSONL文件路径列表\n",
    "        output_file: 输出文件路径\n",
    "    \n",
    "    Returns:\n",
    "        所有处理的数据列表，用于后续分析\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # 准备输出文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as outf:\n",
    "        # 处理每个输入文件\n",
    "        for input_file in input_files:\n",
    "            print(f\"处理文件: {input_file}\")\n",
    "            count = 0\n",
    "            \n",
    "            # 读取JSONL文件\n",
    "            with open(input_file, 'r', encoding='utf-8') as inf:\n",
    "                for line in tqdm(inf, desc=f\"读取 {os.path.basename(input_file)}\"):\n",
    "                    try:\n",
    "                        # 解析JSON\n",
    "                        item = json.loads(line.strip())\n",
    "                        \n",
    "                        # 检查必要字段是否存在\n",
    "                        if 'input' in item and 'output' in item:\n",
    "                            # 写入输出文件\n",
    "                            outf.write(json.dumps(item, ensure_ascii=False) + \"\\n\")\n",
    "                            all_data.append(item)\n",
    "                            count += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"处理行时出错: {str(e)}\")\n",
    "            \n",
    "            print(f\"从 {input_file} 中提取了 {count} 条数据\")\n",
    "    \n",
    "    print(f\"合并完成，总共 {len(all_data)} 条数据\")\n",
    "    print(f\"输出文件: {output_file}\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def analyze_cot_data_distribution(data):\n",
    "    \"\"\"\n",
    "    分析CoT数据长度分布\n",
    "    \n",
    "    Args:\n",
    "        data: 数据列表，每项包含input和output字段\n",
    "    \"\"\"\n",
    "    # 计算输入和输出的长度\n",
    "    input_lengths = [len(item['input']) for item in data]\n",
    "    output_lengths = [len(item['output']) for item in data]\n",
    "    \n",
    "    # 分析思维链特征\n",
    "    think_tag_count = sum(1 for item in data if '<think>' in item['output'])\n",
    "    \n",
    "    # 提取思维链部分和答案部分的长度\n",
    "    think_lengths = []\n",
    "    answer_lengths = []\n",
    "    \n",
    "    for item in data:\n",
    "        output = item['output']\n",
    "        if '<think>' in output and '</think>' in output:\n",
    "            think_part = output[output.find('<think>')+7:output.find('</think>')]\n",
    "            think_lengths.append(len(think_part))\n",
    "            \n",
    "            # 尝试提取答案部分\n",
    "            remaining = output[output.find('</think>')+8:]\n",
    "            answer_lengths.append(len(remaining))\n",
    "    \n",
    "    # 创建DataFrame便于分析\n",
    "    df = pd.DataFrame({\n",
    "        'input_length': input_lengths,\n",
    "        'output_length': output_lengths\n",
    "    })\n",
    "    \n",
    "    if think_lengths:\n",
    "        df_think = pd.DataFrame({\n",
    "            'think_length': think_lengths,\n",
    "            'answer_length': answer_lengths\n",
    "        })\n",
    "    \n",
    "    # 基本统计信息\n",
    "    print(\"\\n=== 数据长度统计 ===\")\n",
    "    print(\"输入长度统计:\")\n",
    "    print(df['input_length'].describe())\n",
    "    print(\"\\n输出长度统计:\")\n",
    "    print(df['output_length'].describe())\n",
    "    \n",
    "    print(f\"\\n包含<think>标签的数据: {think_tag_count}/{len(data)} ({think_tag_count/len(data)*100:.2f}%)\")\n",
    "    \n",
    "    if think_lengths:\n",
    "        print(\"\\n思维过程长度统计:\")\n",
    "        print(pd.Series(think_lengths).describe())\n",
    "        print(\"\\n答案部分长度统计:\")\n",
    "        print(pd.Series(answer_lengths).describe())\n",
    "    \n",
    "    # 绘制长度分布直方图\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(input_lengths, bins=50, alpha=0.7)\n",
    "    plt.title('输入长度分布')\n",
    "    plt.xlabel('字符长度')\n",
    "    plt.ylabel('频次')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(output_lengths, bins=50, alpha=0.7)\n",
    "    plt.title('输出长度分布')\n",
    "    plt.xlabel('字符长度')\n",
    "    plt.ylabel('频次')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 如果有思维链数据，绘制思维链和答案长度分布\n",
    "    if think_lengths:\n",
    "        plt.figure(figsize=(15, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.hist(think_lengths, bins=50, alpha=0.7)\n",
    "        plt.title('思维过程长度分布')\n",
    "        plt.xlabel('字符长度')\n",
    "        plt.ylabel('频次')\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.hist(answer_lengths, bins=50, alpha=0.7)\n",
    "        plt.title('答案部分长度分布')\n",
    "        plt.xlabel('字符长度')\n",
    "        plt.ylabel('频次')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    # 长度区间分布\n",
    "    print(\"\\n=== 长度区间分布 ===\")\n",
    "    \n",
    "    # 输入长度区间\n",
    "    input_ranges = [\n",
    "        (0, 50), (50, 100), (100, 200), (200, 500), \n",
    "        (500, 1000), (1000, 2000), (2000, float('inf'))\n",
    "    ]\n",
    "    \n",
    "    print(\"输入长度区间分布:\")\n",
    "    for start, end in input_ranges:\n",
    "        count = ((df['input_length'] >= start) & (df['input_length'] < end)).sum()\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"{start}-{end if end != float('inf') else '∞'}: {count} 条 ({percentage:.2f}%)\")\n",
    "    \n",
    "    # 输出长度区间\n",
    "    output_ranges = [\n",
    "        (0, 100), (100, 200), (200, 500), (500, 1000), \n",
    "        (1000, 2000), (2000, 3000), (3000, float('inf'))\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n输出长度区间分布:\")\n",
    "    for start, end in output_ranges:\n",
    "        count = ((df['output_length'] >= start) & (df['output_length'] < end)).sum()\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"{start}-{end if end != float('inf') else '∞'}: {count} 条 ({percentage:.2f}%)\")\n",
    "    \n",
    "    # 如果有思维链数据，分析思维链长度区间\n",
    "    if think_lengths:\n",
    "        think_ranges = [\n",
    "            (0, 100), (100, 200), (200, 500), (500, 1000), \n",
    "            (1000, 2000), (2000, 3000), (3000, float('inf'))\n",
    "        ]\n",
    "        \n",
    "        print(\"\\n思维过程长度区间分布:\")\n",
    "        for start, end in think_ranges:\n",
    "            count = sum(1 for length in think_lengths if start <= length < end)\n",
    "            percentage = count / len(think_lengths) * 100\n",
    "            print(f\"{start}-{end if end != float('inf') else '∞'}: {count} 条 ({percentage:.2f}%)\")\n",
    "    \n",
    "    # 分析样本数据类型\n",
    "    analyze_cot_sample_content(data)\n",
    "\n",
    "def analyze_cot_sample_content(data, sample_size=5):\n",
    "    \"\"\"\n",
    "    分析CoT样本内容\n",
    "    \"\"\"\n",
    "    # 随机选择样本\n",
    "    import random\n",
    "    samples = random.sample(data, min(sample_size, len(data)))\n",
    "    \n",
    "    print(\"\\n=== 随机CoT样本示例 ===\")\n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"\\n样本 {i}:\")\n",
    "        print(f\"输入 ({len(sample['input'])}字符): {sample['input'][:200]}...\")\n",
    "        \n",
    "        output = sample['output']\n",
    "        if '<think>' in output and '</think>' in output:\n",
    "            think_part = output[output.find('<think>')+7:output.find('</think>')]\n",
    "            answer_part = output[output.find('</think>')+8:]\n",
    "            print(f\"思维过程 ({len(think_part)}字符): {think_part[:200]}...\")\n",
    "            print(f\"答案部分 ({len(answer_part)}字符): {answer_part[:200]}...\")\n",
    "        else:\n",
    "            print(f\"输出 ({len(output)}字符): {output[:200]}...\")\n",
    "\n",
    "# 设置参数\n",
    "base_dir = \"/root/autodl-tmp/muyan/data/cot\"\n",
    "input_files = [\n",
    "    os.path.join(base_dir, \"rest_data_cot_1w.jsonl\"),\n",
    "    os.path.join(base_dir, \"rest_data_cot_2w.jsonl\"),\n",
    "    os.path.join(base_dir, \"kg_crime_all.jsonl\")\n",
    "]\n",
    "output_file = os.path.join(base_dir, \"merged_all_cot_data.jsonl\")\n",
    "\n",
    "# 执行合并和分析\n",
    "all_data = merge_cot_jsonl_files(input_files, output_file)\n",
    "analyze_cot_data_distribution(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa231f57",
   "metadata": {},
   "source": [
    "### 数据过滤与拆解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fafe1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取并处理文件: /root/autodl-tmp/muyan/data/cot/merged_all_cot_data.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2463f3bac30a4cfca70b2d25f3c89e72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "读取、过滤和清洗数据: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "总数据: 28533条\n",
      "过滤掉输入长度<50的数据: 2417条\n",
      "保留数据: 26116条\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30319b9d8f19467b8513f8c1eead5c25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "写入训练集:   0%|          | 0/23504 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a37118c988047d4bd76846ccb1c13e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "写入测试集:   0%|          | 0/2612 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据集拆分完成:\n",
      "训练集(90%): 23504条 -> /root/autodl-tmp/muyan/data/cot/filter_all_cot_train_data.jsonl\n",
      "测试集(10%): 2612条 -> /root/autodl-tmp/muyan/data/cot/filter_all_cot_test_data.jsonl\n",
      "\n",
      "文件大小统计:\n",
      "训练集: 59.91 MB\n",
      "测试集: 6.66 MB\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6b410c475624152b7be351f726fce16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "分析训练集: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9956bb044eb481babf9484a8617a9d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "分析测试集: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "数据长度统计:\n",
      "训练集输入长度: 平均 229.2 字符, 中位数 222.0 字符\n",
      "训练集输出长度: 平均 830.7 字符, 中位数 823.0 字符\n",
      "测试集输入长度: 平均 230.6 字符, 中位数 223.0 字符\n",
      "测试集输出长度: 平均 828.6 字符, 中位数 821.0 字符\n",
      "训练集思维过程长度: 平均 651.2 字符, 中位数 652.0 字符\n",
      "含思维过程的样本占比: 100.0%\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def filter_clean_split_cot(input_file, train_output, test_output, min_input_length=50, train_ratio=0.9):\n",
    "    \"\"\"\n",
    "    过滤短输入，清洗文本并拆分CoT数据集\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入JSONL文件路径\n",
    "        train_output: 训练集输出文件路径\n",
    "        test_output: 测试集输出文件路径\n",
    "        min_input_length: 输入文本最小长度限制\n",
    "        train_ratio: 训练集占比\n",
    "    \n",
    "    Returns:\n",
    "        train_count: 训练集数据量\n",
    "        test_count: 测试集数据量\n",
    "    \"\"\"\n",
    "    # 读取所有数据并过滤、清洗\n",
    "    all_data = []\n",
    "    short_input_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    print(f\"读取并处理文件: {input_file}\")\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"读取、过滤和清洗数据\"):\n",
    "            total_count += 1\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                \n",
    "                # 过滤掉输入长度小于指定值的数据\n",
    "                if len(item['input']) < min_input_length:\n",
    "                    short_input_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # 清洗input中的\"生成\"字样\n",
    "                item['input'] = re.sub(r'生成', '', item['input'])\n",
    "                \n",
    "                # 清洗output中的\"解答\"字样\n",
    "                item['output'] = re.sub(r'解答', '', item['output'])\n",
    "                \n",
    "                all_data.append(item)\n",
    "            except Exception as e:\n",
    "                print(f\"处理行时出错: {str(e)}\")\n",
    "    \n",
    "    print(f\"总数据: {total_count}条\")\n",
    "    print(f\"过滤掉输入长度<{min_input_length}的数据: {short_input_count}条\")\n",
    "    print(f\"保留数据: {len(all_data)}条\")\n",
    "    \n",
    "    # 随机打乱数据\n",
    "    random.seed(42)  # 设置随机种子，确保结果可复\n",
    "\n",
    "def filter_clean_split_cot(input_file, train_output, test_output, min_input_length=50, train_ratio=0.9):\n",
    "    \"\"\"\n",
    "    过滤短输入，清洗文本并拆分CoT数据集\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入JSONL文件路径\n",
    "        train_output: 训练集输出文件路径\n",
    "        test_output: 测试集输出文件路径\n",
    "        min_input_length: 输入文本最小长度限制\n",
    "        train_ratio: 训练集占比\n",
    "    \n",
    "    Returns:\n",
    "        train_count: 训练集数据量\n",
    "        test_count: 测试集数据量\n",
    "    \"\"\"\n",
    "    # 读取所有数据并过滤、清洗\n",
    "    all_data = []\n",
    "    short_input_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    print(f\"读取并处理文件: {input_file}\")\n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"读取、过滤和清洗数据\"):\n",
    "            total_count += 1\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                \n",
    "                # 过滤掉输入长度小于指定值的数据\n",
    "                if len(item['input']) < min_input_length:\n",
    "                    short_input_count += 1\n",
    "                    continue\n",
    "                \n",
    "                # 清洗input中的\"生成\"字样\n",
    "                item['input'] = re.sub(r'生成', '', item['input'])\n",
    "                \n",
    "                # 清洗output中的\"解答\"字样\n",
    "                item['output'] = re.sub(r'解答', '', item['output'])\n",
    "                \n",
    "                all_data.append(item)\n",
    "            except Exception as e:\n",
    "                print(f\"处理行时出错: {str(e)}\")\n",
    "    \n",
    "    print(f\"总数据: {total_count}条\")\n",
    "    print(f\"过滤掉输入长度<{min_input_length}的数据: {short_input_count}条\")\n",
    "    print(f\"保留数据: {len(all_data)}条\")\n",
    "    \n",
    "    # 随机打乱数据\n",
    "    random.seed(42)  # 设置随机种子，确保结果可复现\n",
    "    random.shuffle(all_data)\n",
    "    \n",
    "    # 计算分割点\n",
    "    split_index = int(len(all_data) * train_ratio)\n",
    "    \n",
    "    # 均匀抽样（而不是连续分割）\n",
    "    indices = np.arange(len(all_data))\n",
    "    train_indices = np.sort(np.random.choice(indices, size=split_index, replace=False))\n",
    "    test_indices = np.setdiff1d(indices, train_indices)\n",
    "    \n",
    "    train_data = [all_data[i] for i in train_indices]\n",
    "    test_data = [all_data[i] for i in test_indices]\n",
    "    \n",
    "    # 写入训练集\n",
    "    with open(train_output, 'w', encoding='utf-8') as f:\n",
    "        for item in tqdm(train_data, desc=\"写入训练集\"):\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    # 写入测试集\n",
    "    with open(test_output, 'w', encoding='utf-8') as f:\n",
    "        for item in tqdm(test_data, desc=\"写入测试集\"):\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"\\n数据集拆分完成:\")\n",
    "    print(f\"训练集({train_ratio*100:.0f}%): {len(train_data)}条 -> {train_output}\")\n",
    "    print(f\"测试集({(1-train_ratio)*100:.0f}%): {len(test_data)}条 -> {test_output}\")\n",
    "    \n",
    "    return len(train_data), len(test_data)\n",
    "\n",
    "def analyze_split_results(train_file, test_file):\n",
    "    \"\"\"\n",
    "    分析拆分后的数据文件\n",
    "    \"\"\"\n",
    "    # 统计文件大小\n",
    "    train_size = os.path.getsize(train_file) / (1024 * 1024)\n",
    "    test_size = os.path.getsize(test_file) / (1024 * 1024)\n",
    "    \n",
    "    print(f\"\\n文件大小统计:\")\n",
    "    print(f\"训练集: {train_size:.2f} MB\")\n",
    "    print(f\"测试集: {test_size:.2f} MB\")\n",
    "    \n",
    "    # 读取训练集样本分析\n",
    "    train_input_lens = []\n",
    "    train_output_lens = []\n",
    "    train_think_lens = []\n",
    "    \n",
    "    with open(train_file, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"分析训练集\"):\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                train_input_lens.append(len(item['input']))\n",
    "                train_output_lens.append(len(item['output']))\n",
    "                \n",
    "                output = item['output']\n",
    "                if '<think>' in output and '</think>' in output:\n",
    "                    think_part = output[output.find('<think>')+7:output.find('</think>')]\n",
    "                    train_think_lens.append(len(think_part))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    # 读取测试集样本分析\n",
    "    test_input_lens = []\n",
    "    test_output_lens = []\n",
    "    \n",
    "    with open(test_file, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"分析测试集\"):\n",
    "            try:\n",
    "                item = json.loads(line)\n",
    "                test_input_lens.append(len(item['input']))\n",
    "                test_output_lens.append(len(item['output']))\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "    print(f\"\\n数据长度统计:\")\n",
    "    print(f\"训练集输入长度: 平均 {np.mean(train_input_lens):.1f} 字符, 中位数 {np.median(train_input_lens):.1f} 字符\")\n",
    "    print(f\"训练集输出长度: 平均 {np.mean(train_output_lens):.1f} 字符, 中位数 {np.median(train_output_lens):.1f} 字符\")\n",
    "    print(f\"测试集输入长度: 平均 {np.mean(test_input_lens):.1f} 字符, 中位数 {np.median(test_input_lens):.1f} 字符\")\n",
    "    print(f\"测试集输出长度: 平均 {np.mean(test_output_lens):.1f} 字符, 中位数 {np.median(test_output_lens):.1f} 字符\")\n",
    "    \n",
    "    if train_think_lens:\n",
    "        print(f\"训练集思维过程长度: 平均 {np.mean(train_think_lens):.1f} 字符, 中位数 {np.median(train_think_lens):.1f} 字符\")\n",
    "        print(f\"含思维过程的样本占比: {len(train_think_lens)/len(train_input_lens)*100:.1f}%\")\n",
    "\n",
    "# 设置参数\n",
    "base_dir = \"/root/autodl-tmp/muyan/data/cot\"\n",
    "input_file = os.path.join(base_dir, \"merged_all_cot_data.jsonl\")\n",
    "train_output = os.path.join(base_dir, \"filter_all_cot_train_data.jsonl\")\n",
    "test_output = os.path.join(base_dir, \"filter_all_cot_test_data.jsonl\")\n",
    "min_input_length = 50\n",
    "train_ratio = 0.9\n",
    "\n",
    "# 执行过滤、清洗和拆分\n",
    "train_count, test_count = filter_clean_split_cot(\n",
    "    input_file, \n",
    "    train_output, \n",
    "    test_output, \n",
    "    min_input_length, \n",
    "    train_ratio\n",
    ")\n",
    "\n",
    "# 分析拆分结果\n",
    "analyze_split_results(train_output, test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca574e06",
   "metadata": {},
   "source": [
    "## 3.6 SFT数据准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e5ab2c",
   "metadata": {},
   "source": [
    "lawzhidao_filter.csv 进行数据处理，主要是数据过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95122b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "读取CSV文件: /root/autodl-tmp/muyan/data/sft/lawzhidao_filter.csv\n",
      "CSV文件包含 36368 行数据\n",
      "筛选出 18243 行 is_best=1 的数据\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff1e78c80f794cbd880ba93440a01f45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "处理数据:   0%|          | 0/18243 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，成功转换 18238 条数据\n",
      "输出文件: ./lawzhidao_sft.jsonl\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def process_csv_to_sft(input_csv, output_file):\n",
    "    \"\"\"\n",
    "    处理CSV文件，将符合条件的数据转换为SFT训练数据格式\n",
    "    \n",
    "    条件:\n",
    "    - is_best=1\n",
    "    - 优先使用question作为input，若为空则使用title\n",
    "    \n",
    "    Args:\n",
    "        input_csv: 输入CSV文件路径\n",
    "        output_file: 输出文件路径\n",
    "    \"\"\"\n",
    "    # 读取CSV文件\n",
    "    print(f\"读取CSV文件: {input_csv}\")\n",
    "    df = pd.read_csv(input_csv)\n",
    "    print(f\"CSV文件包含 {len(df)} 行数据\")\n",
    "    \n",
    "    # 筛选is_best=1的数据\n",
    "    filtered_df = df[df['is_best'] == 1]\n",
    "    print(f\"筛选出 {len(filtered_df)} 行 is_best=1 的数据\")\n",
    "    \n",
    "    # 准备输出文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as outf:\n",
    "        # 统计计数\n",
    "        processed = 0\n",
    "        \n",
    "        # 处理每一行\n",
    "        for _, row in tqdm(filtered_df.iterrows(), total=len(filtered_df), desc=\"处理数据\"):\n",
    "            try:\n",
    "                # 选择input字段(优先question，否则用title)\n",
    "                question = row.get('question', '')\n",
    "                title = row.get('title', '')\n",
    "                \n",
    "                input_text = question if question and not pd.isna(question) else title\n",
    "                \n",
    "                # 如果input为空，则跳过\n",
    "                if not input_text or pd.isna(input_text):\n",
    "                    continue\n",
    "                \n",
    "                # 获取reply作为输出\n",
    "                reply = row.get('reply', '')\n",
    "                if pd.isna(reply) or not reply:\n",
    "                    continue\n",
    "                \n",
    "                # 构建SFT训练格式\n",
    "                sft_item = {\n",
    "                    \"input\": input_text,\n",
    "                    \"output\": reply\n",
    "                }\n",
    "                \n",
    "                # 写入输出文件\n",
    "                outf.write(json.dumps(sft_item, ensure_ascii=False) + \"\\n\")\n",
    "                processed += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"处理数据时出错: {str(e)}\")\n",
    "    \n",
    "    print(f\"处理完成，成功转换 {processed} 条数据\")\n",
    "    print(f\"输出文件: {output_file}\")\n",
    "\n",
    "# 设置参数\n",
    "input_csv = \"/root/autodl-tmp/muyan/data/sft/lawzhidao_filter.csv\"\n",
    "output_file = \"./lawzhidao_sft.jsonl\"\n",
    "\n",
    "# 执行处理\n",
    "process_csv_to_sft(input_csv, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a7a804",
   "metadata": {},
   "source": [
    "```json\n",
    "{\"input\": \"你好我的银行卡昨天我一个以前的朋友叫我发给他，这个对我有伤害吗\", \"output\": \"您好，只提供银行卡号不提供实际信息不会有影响，建议您注重个人隐私和财务安全。\", \"meta\": {\"cause\": \"债权债务\"}}\n",
    "{\"input\": \"乡村道路摩托车相撞，双方都有责任，今年X月份满两年，一方提起诉讼，有效吗？\", \"output\": \"你好，有效的，根据根据《中华人民共和国民法典》第一百八十八条的规定，向人民法院请求保护民事权利的诉讼时效期间为三年，所以在两年内提起诉讼也是有效的。\", \"meta\": {\"cause\": \"交通事故\"}}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e933bc4",
   "metadata": {},
   "source": [
    "处理路径下单独json文件并汇总成问题集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723a1cac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "找到 16209 个JSON文件\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb7a715520264f14aee39a58fb594565",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "处理文件:   0%|          | 0/16209 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理完成，输出文件: /root/autodl-tmp/muyan/data/sft/sft_training_data.jsonl\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import glob\n",
    "from tqdm.notebook import tqdm  # 注意这里使用tqdm的notebook版本\n",
    "\n",
    "def process_json_files_to_sft(input_dir, output_file):\n",
    "    \"\"\"\n",
    "    处理指定目录下的所有JSON文件，转换为SFT训练数据格式\n",
    "    \n",
    "    Args:\n",
    "        input_dir: 输入目录路径，包含所有JSON文件\n",
    "        output_file: 输出文件路径\n",
    "    \"\"\"\n",
    "    # 获取目录下所有JSON文件\n",
    "    json_files = glob.glob(os.path.join(input_dir, \"*.json\"))\n",
    "    print(f\"找到 {len(json_files)} 个JSON文件\")\n",
    "    \n",
    "    # 准备输出文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as outf:\n",
    "        # 处理每个文件\n",
    "        for file_path in tqdm(json_files, desc=\"处理文件\"):\n",
    "            try:\n",
    "                # 读取JSON文件\n",
    "                with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                    data = json.load(f)\n",
    "                \n",
    "                # 提取关键字段\n",
    "                question = data.get(\"question\", \"\")\n",
    "                answer = data.get(\"answer\", \"\")\n",
    "                cause = data.get(\"cause\", \"\")\n",
    "                \n",
    "                # 构建SFT训练格式\n",
    "                sft_item = {\n",
    "                    \"input\": question,\n",
    "                    \"output\": answer\n",
    "                }\n",
    "                \n",
    "                # 可选：添加额外元数据\n",
    "                if cause:\n",
    "                    sft_item[\"meta\"] = {\"cause\": cause}\n",
    "                \n",
    "                # 写入输出文件\n",
    "                outf.write(json.dumps(sft_item, ensure_ascii=False) + \"\\n\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"处理文件 {file_path} 时出错: {str(e)}\")\n",
    "    \n",
    "    print(f\"处理完成，输出文件: {output_file}\")\n",
    "\n",
    "# 直接在Jupyter中设置参数并执行\n",
    "input_dir = \"/root/autodl-tmp/muyan/data/sft/train\"  # 输入目录\n",
    "output_file = \"/root/autodl-tmp/muyan/data/sft/sft_training_data.jsonl\"  # 输出文件\n",
    "\n",
    "# 执行处理函数\n",
    "process_json_files_to_sft(input_dir, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "054682ee",
   "metadata": {},
   "source": [
    "```json\n",
    "{\"input\": \"入室持刀行凶伤人能不能判刑\", \"output\": \"对于入室持刀伤人涉嫌故意伤害刑事犯罪，一经定罪，故意伤害他人身体的，处三年以下有期徒刑、拘役或者管制。犯前款罪，致人重伤的，处三年以上十年以下有期徒刑；致人死亡或者以特别残忍手段致人重伤造成严重残疾的，处十年以上有期徒刑、无期徒刑或者死刑。相关法律规定《中华人民共和国刑法》第二百三十四条故意伤害他人身体的，处三年以下有期徒刑、拘役或者管制。犯前款罪，致人重伤的，处三年以上十年以下有期徒刑；致人死亡或者以特别残忍手段致人重伤造成严重残疾的，处十年以上有期徒刑、无期徒刑或者死刑。本法另有规定的，依照规定。\"}\n",
    "{\"input\": \"对交通事故责任认定书不服怎么办，交通事故损\", \"output\": \"事故认定书下发后，如果你对认定不满意，可在接到认定书3日内到上一级公安机关复议。\"}\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860f5d3f",
   "metadata": {},
   "source": [
    "### 数据过滤合并"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e513b58e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "处理文件: /root/autodl-tmp/muyan/data/sft/sft_training_data.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe0a4ca7bb8e4e5590b1a3a8ab323748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "读取 sft_training_data.jsonl: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 /root/autodl-tmp/muyan/data/sft/sft_training_data.jsonl 中提取了 16209 条数据\n",
      "处理文件: /root/autodl-tmp/muyan/data/sft/lawzhidao_sft.jsonl\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91111a77bd234e2e92dc7f5b94e35317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "读取 lawzhidao_sft.jsonl: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "从 /root/autodl-tmp/muyan/data/sft/lawzhidao_sft.jsonl 中提取了 18238 条数据\n",
      "合并完成，总共 34447 条数据\n",
      "输出文件: /root/autodl-tmp/muyan/data/sft/all_sft.jsonl\n",
      "\n",
      "=== 数据长度统计 ===\n",
      "输入长度统计:\n",
      "count    34447.000000\n",
      "mean        35.186373\n",
      "std         35.474357\n",
      "min          1.000000\n",
      "25%         16.000000\n",
      "50%         22.000000\n",
      "75%         40.000000\n",
      "max        575.000000\n",
      "Name: input_length, dtype: float64\n",
      "\n",
      "输出长度统计:\n",
      "count    34447.000000\n",
      "mean       195.723953\n",
      "std        310.798000\n",
      "min          1.000000\n",
      "25%         34.000000\n",
      "50%         81.000000\n",
      "75%        250.000000\n",
      "max       7274.000000\n",
      "Name: output_length, dtype: float64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 23383 (\\N{CJK UNIFIED IDEOGRAPH-5B57}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 31526 (\\N{CJK UNIFIED IDEOGRAPH-7B26}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 38271 (\\N{CJK UNIFIED IDEOGRAPH-957F}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 39057 (\\N{CJK UNIFIED IDEOGRAPH-9891}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 36755 (\\N{CJK UNIFIED IDEOGRAPH-8F93}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 20837 (\\N{CJK UNIFIED IDEOGRAPH-5165}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/tmp/ipykernel_69400/1249659910.py:96: UserWarning: Glyph 20986 (\\N{CJK UNIFIED IDEOGRAPH-51FA}) missing from font(s) DejaVu Sans.\n",
      "  plt.tight_layout()\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 39057 (\\N{CJK UNIFIED IDEOGRAPH-9891}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 27425 (\\N{CJK UNIFIED IDEOGRAPH-6B21}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 36755 (\\N{CJK UNIFIED IDEOGRAPH-8F93}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20837 (\\N{CJK UNIFIED IDEOGRAPH-5165}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 38271 (\\N{CJK UNIFIED IDEOGRAPH-957F}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24230 (\\N{CJK UNIFIED IDEOGRAPH-5EA6}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20998 (\\N{CJK UNIFIED IDEOGRAPH-5206}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 24067 (\\N{CJK UNIFIED IDEOGRAPH-5E03}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 23383 (\\N{CJK UNIFIED IDEOGRAPH-5B57}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 31526 (\\N{CJK UNIFIED IDEOGRAPH-7B26}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n",
      "/root/miniconda3/envs/qingxi/lib/python3.11/site-packages/IPython/core/pylabtools.py:170: UserWarning: Glyph 20986 (\\N{CJK UNIFIED IDEOGRAPH-51FA}) missing from font(s) DejaVu Sans.\n",
      "  fig.canvas.print_figure(bytes_io, **kw)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 长度区间分布 ===\n",
      "输入长度区间分布:\n",
      "0-50: 27910 条 (81.02%)\n",
      "50-100: 4499 条 (13.06%)\n",
      "100-200: 1818 条 (5.28%)\n",
      "200-500: 218 条 (0.63%)\n",
      "500-1000: 2 条 (0.01%)\n",
      "1000-2000: 0 条 (0.00%)\n",
      "2000-∞: 0 条 (0.00%)\n",
      "\n",
      "输出长度区间分布:\n",
      "0-50: 12582 条 (36.53%)\n",
      "50-100: 6283 条 (18.24%)\n",
      "100-200: 4755 条 (13.80%)\n",
      "200-500: 7810 条 (22.67%)\n",
      "500-1000: 2260 条 (6.56%)\n",
      "1000-2000: 599 条 (1.74%)\n",
      "2000-∞: 158 条 (0.46%)\n",
      "\n",
      "输出/输入长度比例统计:\n",
      "count    34447.000000\n",
      "mean        11.815269\n",
      "std         22.385400\n",
      "min          0.013937\n",
      "25%          0.897436\n",
      "50%          3.208333\n",
      "75%         14.769231\n",
      "max        548.727273\n",
      "dtype: float64\n",
      "\n",
      "=== 随机样本示例 ===\n",
      "\n",
      "样本 1:\n",
      "输入 (56字符): 我家住X，我母亲是已故军人遗属，享受军人遗属补助金，于XXXX年X月XX日去世了，请问补助金应该是什么时候停发？...\n",
      "输出 (23字符): 您好！具体看当地政策如何规定，可咨询发放部门。...\n",
      "\n",
      "样本 2:\n",
      "输入 (53字符): 我借了二万高利贷，一个月XX分利，被出借人吃了五期，差不多一万利息，现在无力还贷，我要问一下律师们如何调解...\n",
      "输出 (125字符): 您好，您只需要归还合理范围内本金和利息，判断利息是否合理可根据《最高人民法院关于审理民间借贷案件适用法律若干问题的规定》，出借人请求借款人按照合同约定的利率支付利息的人民法院应予支持，但是双方约定的利...\n",
      "\n",
      "样本 3:\n",
      "输入 (225字符): 我车子XX年X月XX号付的定金五千，X月XX第二次订转定金共X万，X月XX付的全款，X月XX提车，现在临牌都过期了，一直上不到新能源牌照，提车的时候告知地标没过，说很快就能过的，也就信了Xs店，到现在...\n",
      "输出 (27字符): 您好，可以协商，协商不成的向消协投诉维权，也可以起诉。...\n",
      "\n",
      "样本 4:\n",
      "输入 (16字符): 十万元欠条不还，法院起诉份是多少...\n",
      "输出 (730字符): 受理费标准（一）财产案件根据诉讼请求的金额或者价额，按照下列比例分段累计交纳：1.不超过1万元的，每件交纳50元；2.超过1万元至10万元的部分，按照2.5%交纳；3.超过10万元至20万元的部分，按...\n",
      "\n",
      "样本 5:\n",
      "输入 (15字符): 车祸受害人没出院能上法院起诉吗...\n",
      "输出 (47字符): 对于纠纷，协商不成的，可以通过诉讼的方式解决，注意要有合理的诉讼请求，必要时还要有充足的证据。...\n"
     ]
    }
   ],
   "source": [
    "# pip install matplotlib\n",
    "import json \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def merge_jsonl_files(input_files, output_file, fields=['input', 'output']):\n",
    "    \"\"\"\n",
    "    合并多个JSONL文件，只保留指定字段\n",
    "    \n",
    "    Args:\n",
    "        input_files: 输入JSONL文件路径列表\n",
    "        output_file: 输出文件路径\n",
    "        fields: 要保留的字段列表\n",
    "    \n",
    "    Returns:\n",
    "        所有处理的数据列表，用于后续分析\n",
    "    \"\"\"\n",
    "    all_data = []\n",
    "    \n",
    "    # 准备输出文件\n",
    "    with open(output_file, 'w', encoding='utf-8') as outf:\n",
    "        # 处理每个输入文件\n",
    "        for input_file in input_files:\n",
    "            print(f\"处理文件: {input_file}\")\n",
    "            count = 0\n",
    "            \n",
    "            # 读取JSONL文件\n",
    "            with open(input_file, 'r', encoding='utf-8') as inf:\n",
    "                for line in tqdm(inf, desc=f\"读取 {os.path.basename(input_file)}\"):\n",
    "                    try:\n",
    "                        # 解析JSON\n",
    "                        item = json.loads(line.strip())\n",
    "                        \n",
    "                        # 只保留指定字段\n",
    "                        filtered_item = {field: item.get(field, \"\") for field in fields}\n",
    "                        \n",
    "                        # 确保字段非空\n",
    "                        if all(filtered_item.get(field, \"\") for field in fields):\n",
    "                            # 写入输出文件\n",
    "                            outf.write(json.dumps(filtered_item, ensure_ascii=False) + \"\\n\")\n",
    "                            all_data.append(filtered_item)\n",
    "                            count += 1\n",
    "                    \n",
    "                    except Exception as e:\n",
    "                        print(f\"处理行时出错: {str(e)}\")\n",
    "            \n",
    "            print(f\"从 {input_file} 中提取了 {count} 条数据\")\n",
    "    \n",
    "    print(f\"合并完成，总共 {len(all_data)} 条数据\")\n",
    "    print(f\"输出文件: {output_file}\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "def analyze_data_distribution(data):\n",
    "    \"\"\"\n",
    "    分析数据长度分布\n",
    "    \n",
    "    Args:\n",
    "        data: 数据列表，每项包含input和output字段\n",
    "    \"\"\"\n",
    "    # 计算输入和输出的长度\n",
    "    input_lengths = [len(item['input']) for item in data]\n",
    "    output_lengths = [len(item['output']) for item in data]\n",
    "    \n",
    "    # 创建DataFrame便于分析\n",
    "    df = pd.DataFrame({\n",
    "        'input_length': input_lengths,\n",
    "        'output_length': output_lengths\n",
    "    })\n",
    "    \n",
    "    # 基本统计信息\n",
    "    print(\"\\n=== 数据长度统计 ===\")\n",
    "    print(\"输入长度统计:\")\n",
    "    print(df['input_length'].describe())\n",
    "    print(\"\\n输出长度统计:\")\n",
    "    print(df['output_length'].describe())\n",
    "    \n",
    "    # 绘制长度分布直方图\n",
    "    plt.figure(figsize=(15, 6))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(input_lengths, bins=50, alpha=0.7)\n",
    "    plt.title('输入长度分布')\n",
    "    plt.xlabel('字符长度')\n",
    "    plt.ylabel('频次')\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(output_lengths, bins=50, alpha=0.7)\n",
    "    plt.title('输出长度分布')\n",
    "    plt.xlabel('字符长度')\n",
    "    plt.ylabel('频次')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 长度区间分布\n",
    "    print(\"\\n=== 长度区间分布 ===\")\n",
    "    \n",
    "    # 输入长度区间\n",
    "    input_ranges = [\n",
    "        (0, 50), (50, 100), (100, 200), (200, 500), \n",
    "        (500, 1000), (1000, 2000), (2000, float('inf'))\n",
    "    ]\n",
    "    \n",
    "    print(\"输入长度区间分布:\")\n",
    "    for start, end in input_ranges:\n",
    "        count = ((df['input_length'] >= start) & (df['input_length'] < end)).sum()\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"{start}-{end if end != float('inf') else '∞'}: {count} 条 ({percentage:.2f}%)\")\n",
    "    \n",
    "    # 输出长度区间\n",
    "    output_ranges = [\n",
    "        (0, 50), (50, 100), (100, 200), (200, 500), \n",
    "        (500, 1000), (1000, 2000), (2000, float('inf'))\n",
    "    ]\n",
    "    \n",
    "    print(\"\\n输出长度区间分布:\")\n",
    "    for start, end in output_ranges:\n",
    "        count = ((df['output_length'] >= start) & (df['output_length'] < end)).sum()\n",
    "        percentage = count / len(df) * 100\n",
    "        print(f\"{start}-{end if end != float('inf') else '∞'}: {count} 条 ({percentage:.2f}%)\")\n",
    "    \n",
    "    # 输入-输出长度比例\n",
    "    ratio = df['output_length'] / df['input_length']\n",
    "    print(\"\\n输出/输入长度比例统计:\")\n",
    "    print(ratio.describe())\n",
    "    \n",
    "    # 分析样本数据类型\n",
    "    analyze_sample_content(data)\n",
    "\n",
    "def analyze_sample_content(data, sample_size=5):\n",
    "    \"\"\"\n",
    "    分析样本内容类型\n",
    "    \"\"\"\n",
    "    # 随机选择样本\n",
    "    import random\n",
    "    samples = random.sample(data, min(sample_size, len(data)))\n",
    "    \n",
    "    print(\"\\n=== 随机样本示例 ===\")\n",
    "    for i, sample in enumerate(samples, 1):\n",
    "        print(f\"\\n样本 {i}:\")\n",
    "        print(f\"输入 ({len(sample['input'])}字符): {sample['input'][:100]}...\")\n",
    "        print(f\"输出 ({len(sample['output'])}字符): {sample['output'][:100]}...\")\n",
    "\n",
    "# 设置参数\n",
    "base_dir = \"/root/autodl-tmp/muyan/data/sft\"\n",
    "input_files = [\n",
    "    os.path.join(base_dir, \"sft_training_data.jsonl\"),\n",
    "    os.path.join(base_dir, \"lawzhidao_sft.jsonl\")\n",
    "]\n",
    "output_file = os.path.join(base_dir, \"all_sft.jsonl\")\n",
    "\n",
    "# 执行合并和分析\n",
    "all_data = merge_jsonl_files(input_files, output_file)\n",
    "analyze_data_distribution(all_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d84640e8",
   "metadata": {},
   "source": [
    "### 数据拆分"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6df62da",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def filter_and_split_data(input_file, train_output, test_output, max_output_length=500, train_ratio=0.5):\n",
    "    \"\"\"\n",
    "    过滤长度过长的数据并均匀拆分为训练集和测试集\n",
    "    \n",
    "    Args:\n",
    "        input_file: 输入JSONL文件\n",
    "        train_output: 训练集输出文件\n",
    "        test_output: 测试集输出文件\n",
    "        max_output_length: 最大输出长度\n",
    "        train_ratio: 训练集比例\n",
    "    \"\"\"\n",
    "    # 读取全部数据\n",
    "    all_data = []\n",
    "    print(f\"读取文件: {input_file}\")\n",
    "    \n",
    "    with open(input_file, 'r', encoding='utf-8') as f:\n",
    "        for line in tqdm(f, desc=\"读取数据\"):\n",
    "            try:\n",
    "                item = json.loads(line.strip())\n",
    "                all_data.append(item)\n",
    "            except Exception as e:\n",
    "                print(f\"解析JSON时出错: {str(e)}\")\n",
    "    \n",
    "    print(f\"读取完成，共 {len(all_data)} 条数据\")\n",
    "    \n",
    "    # 过滤输出长度过长的数据\n",
    "    filtered_data = [item for item in all_data if len(item.get('output', '')) <= max_output_length]\n",
    "    \n",
    "    filtered_count = len(filtered_data)\n",
    "    removed_count = len(all_data) - filtered_count\n",
    "    \n",
    "    print(f\"过滤后剩余 {filtered_count} 条数据\")\n",
    "    print(f\"移除了 {removed_count} 条输出长度 > {max_output_length} 的数据\")\n",
    "    \n",
    "    # 打乱数据顺序\n",
    "    random.seed(42)  # 设定随机种子，确保结果可复现\n",
    "    random.shuffle(filtered_data)\n",
    "    \n",
    "    # 均匀拆分训练集和测试集\n",
    "    # 使用步长方式均匀选择，而不是简单的前一半后一半\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    for i, item in enumerate(filtered_data):\n",
    "        if i % 2 == 0:  # 偶数索引分到训练集\n",
    "            train_data.append(item)\n",
    "        else:  # 奇数索引分到测试集\n",
    "            test_data.append(item)\n",
    "    \n",
    "    print(f\"训练集: {len(train_data)} 条数据\")\n",
    "    print(f\"测试集: {len(test_data)} 条数据\")\n",
    "    \n",
    "    # 保存训练集\n",
    "    with open(train_output, 'w', encoding='utf-8') as f:\n",
    "        for item in tqdm(train_data, desc=\"保存训练集\"):\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    # 保存测试集\n",
    "    with open(test_output, 'w', encoding='utf-8') as f:\n",
    "        for item in tqdm(test_data, desc=\"保存测试集\"):\n",
    "            f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "    \n",
    "    print(f\"处理完成！\")\n",
    "    print(f\"训练集已保存至: {train_output}\")\n",
    "    print(f\"测试集已保存至: {test_output}\")\n",
    "    \n",
    "    # 输出两个集合长度分布的基本信息\n",
    "    analyze_split_sets(train_data, test_data)\n",
    "    \n",
    "    return len(train_data), len(test_data)\n",
    "\n",
    "def analyze_split_sets(train_data, test_data):\n",
    "    \"\"\"分析训练集和测试集的长度分布\"\"\"\n",
    "    train_input_lengths = [len(item['input']) for item in train_data]\n",
    "    train_output_lengths = [len(item['output']) for item in train_data]\n",
    "    \n",
    "    test_input_lengths = [len(item['input']) for item in test_data]\n",
    "    test_output_lengths = [len(item['output']) for item in test_data]\n",
    "    \n",
    "    # 创建DataFrame\n",
    "    train_df = pd.DataFrame({\n",
    "        'input_length': train_input_lengths,\n",
    "        'output_length': train_output_lengths\n",
    "    })\n",
    "    \n",
    "    test_df = pd.DataFrame({\n",
    "        'input_length': test_input_lengths,\n",
    "        'output_length': test_output_lengths\n",
    "    })\n",
    "    \n",
    "    print(\"\\n=== 训练集长度统计 ===\")\n",
    "    print(\"输入长度: \", train_df['input_length'].describe())\n",
    "    print(\"输出长度: \", train_df['output_length'].describe())\n",
    "    \n",
    "    print(\"\\n=== 测试集长度统计 ===\")\n",
    "    print(\"输入长度: \", test_df['input_length'].describe())\n",
    "    print(\"输出长度: \", test_df['output_length'].describe())\n",
    "\n",
    "# 设置参数\n",
    "base_dir = \"/root/autodl-tmp/muyan/data/sft\"\n",
    "input_file = os.path.join(base_dir, \"all_sft.jsonl\")\n",
    "train_output = os.path.join(base_dir, \"filter_all_train_sft.jsonl\")\n",
    "test_output = os.path.join(base_dir, \"filter_all_test_sft.jsonl\")\n",
    "\n",
    "# 执行过滤和拆分\n",
    "train_count, test_count = filter_and_split_data(\n",
    "    input_file, \n",
    "    train_output, \n",
    "    test_output, \n",
    "    max_output_length=500, \n",
    "    train_ratio=0.5\n",
    ")\n",
    "\n",
    "print(f\"\\n最终结果:\")\n",
    "print(f\"训练集: {train_count} 条数据\")\n",
    "print(f\"测试集: {test_count} 条数据\")\n",
    "print(f\"总数据: {train_count + test_count} 条数据\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ee0404",
   "metadata": {},
   "source": [
    "## 混合数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39763ea",
   "metadata": {},
   "source": [
    "```python\n",
    "import json\n",
    "import random\n",
    "from pathlib import Path\n",
    "# 用于混合sft与cot数据集\n",
    "# 路径定义\n",
    "cot_file = Path('/root/autodl-tmp/filter_all_cot_train_data23k.jsonl')\n",
    "sft_file = Path('/root/autodl-tmp/filter_all_train_sft18k.jsonl')\n",
    "output_file = Path('/root/autodl-tmp/train_cot_sft_2w.jsonl')\n",
    "\n",
    "# 读取 COT 数据\n",
    "cot_data = []\n",
    "with open(cot_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():  # 确保不是空行\n",
    "            cot_data.append(json.loads(line.strip()))\n",
    "\n",
    "# 读取 SFT 数据\n",
    "sft_data = []\n",
    "with open(sft_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        if line.strip():  # 确保不是空行\n",
    "            sft_data.append(json.loads(line.strip()))\n",
    "\n",
    "# 采样数据\n",
    "cot_samples = cot_data[:12000] if len(cot_data) >= 12000 else cot_data\n",
    "sft_samples = sft_data[:8000] if len(sft_data) >= 8000 else sft_data\n",
    "\n",
    "# 计算交叉比例（每个SFT样本后跟随多少个COT样本）\n",
    "ratio = len(cot_samples) / len(sft_samples)\n",
    "\n",
    "# 合并并随机打乱数据\n",
    "merged_data = []\n",
    "cot_index = 0\n",
    "\n",
    "# 均匀交叉合并数据\n",
    "for sft_index in range(len(sft_samples)):\n",
    "    # 添加一个SFT样本\n",
    "    merged_data.append(sft_samples[sft_index])\n",
    "    \n",
    "    # 计算应该添加的COT样本数量\n",
    "    cot_to_add = int((sft_index + 1) * ratio) - int(sft_index * ratio)\n",
    "    \n",
    "    # 添加对应数量的COT样本\n",
    "    for _ in range(cot_to_add):\n",
    "        if cot_index < len(cot_samples):\n",
    "            merged_data.append(cot_samples[cot_index])\n",
    "            cot_index += 1\n",
    "\n",
    "# 确保所有COT样本都被添加\n",
    "while cot_index < len(cot_samples):\n",
    "    merged_data.append(cot_samples[cot_index])\n",
    "    cot_index += 1\n",
    "\n",
    "# 随机打乱最终数据（可选，取决于是否需要严格交替）\n",
    "random.shuffle(merged_data)\n",
    "\n",
    "# 写入输出文件\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    for item in merged_data:\n",
    "        f.write(json.dumps(item, ensure_ascii=False) + '\\n')\n",
    "\n",
    "print(f\"完成合并！共写入 {len(merged_data)} 条数据到 {output_file}\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17970ae4",
   "metadata": {},
   "source": [
    "# 4. 模型准备"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6e7e9df",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250514155907938.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c470a7",
   "metadata": {},
   "source": [
    "## 模型下载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d30b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/autodl-tmp/Qwen/Qwen2.5-0.5B-Instruct\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:20:57,781 - modelscope - INFO - Got 10 files, start to download ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35a44e10a4344254aa0cd2119c44ebdd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 10 items:   0%|          | 0.00/10.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94eab91f5d824bb392f31eb7334035d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [config.json]:   0%|          | 0.00/659 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f073b9f1cd7544c7b21b0d3c569c56bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [LICENSE]:   0%|          | 0.00/11.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a34a854f780d4a4cb701c788c5c96932",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [configuration.json]:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba6085b3223640b699f92f1ac3ebe7b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/4.80k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e1e739d759a54c389c76fa03b3a049d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [generation_config.json]:   0%|          | 0.00/242 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5cbda87d9994c5f9f2b10425df1e155",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [merges.txt]:   0%|          | 0.00/1.59M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50df08fad2d047478f759678e11b83a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model.safetensors]:   0%|          | 0.00/942M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d1c09d2a5d24d509a89413f77ba032f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer.json]:   0%|          | 0.00/6.71M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e93c322e744d47a6a7952f90ac8d027c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer_config.json]:   0%|          | 0.00/7.13k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79744f27302d41919457e7af4c74e48e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [vocab.json]:   0%|          | 0.00/2.65M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:22:01,878 - modelscope - INFO - Download model 'Qwen/Qwen2.5-0.5B-Instruct' successfully.\n",
      "2025-05-06 17:22:01,878 - modelscope - INFO - Creating symbolic link [/root/autodl-tmp/Qwen/Qwen2.5-0.5B-Instruct].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已下载到: /root/autodl-tmp/Qwen/Qwen2___5-0___5B-Instruct\n"
     ]
    }
   ],
   "source": [
    "from modelscope import snapshot_download\n",
    "\n",
    "# 指定你想要的下载路径\n",
    "custom_path = '/root/autodl-tmp/'\n",
    "\n",
    "# 使用 cache_dir 参数下载模型到指定路径\n",
    "model_dir = snapshot_download('Qwen/Qwen2.5-0.5B-Instruct', cache_dir=custom_path)\n",
    "\n",
    "# 打印模型保存的路径\n",
    "print(f\"模型已下载到: {model_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcddac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Model from https://www.modelscope.cn to directory: /root/autodl-tmp/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:32:45,399 - modelscope - INFO - Got 11 files, start to download ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6bfbd241c91146308db80cbacbc27a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing 11 items:   0%|          | 0.00/11.0 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0be36ed641f34891a0c9def37e408aa4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [figures/benchmark.jpg]:   0%|          | 0.00/759k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da684e2b6dee46a0a2a48d786dd54b72",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [configuration.json]:   0%|          | 0.00/73.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c575207f7374425e987addb99d107923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [generation_config.json]:   0%|          | 0.00/181 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6337cae2077f49c0a297711c396d4e4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [config.json]:   0%|          | 0.00/826 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3e738d939ff4941a366960ea9a27d28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00002-of-000002.safetensors]:   0%|          | 0.00/6.89G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4258d00609d549bd9bdc49209e8f11a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [LICENSE]:   0%|          | 0.00/1.04k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f36d3d389a53474885bc3f6a37133135",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model-00001-of-000002.safetensors]:   0%|          | 0.00/8.07G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3284f914e94b4f06a8e1bd0bee5c5860",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [model.safetensors.index.json]:   0%|          | 0.00/23.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "614b345ba6d54b4d9c9caef9a3b3e9bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [README.md]:   0%|          | 0.00/15.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbd5f76c9475467ea2a80bcb2bb90c07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer.json]:   0%|          | 0.00/8.66M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8f93a9a45ba41a2bee58d5201a75fd8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading [tokenizer_config.json]:   0%|          | 0.00/3.00k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-06 17:42:10,868 - modelscope - INFO - Download model 'deepseek-ai/DeepSeek-R1-Distill-Llama-8B' successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "模型已下载到: /root/autodl-tmp/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\n"
     ]
    }
   ],
   "source": [
    "#模型下载\n",
    "from modelscope import snapshot_download\n",
    "\n",
    "# 指定你想要的下载路径\n",
    "custom_path = '/root/autodl-tmp/'\n",
    "\n",
    "# 使用 cache_dir 参数下载模型到指定路径\n",
    "model_dir = snapshot_download('deepseek-ai/DeepSeek-R1-Distill-Llama-8B', cache_dir=custom_path)\n",
    "\n",
    "# 打印模型保存的路径\n",
    "print(f\"模型已下载到: {model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323a77b3",
   "metadata": {},
   "source": [
    "# 5.蒸馏实践"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c35f4d",
   "metadata": {},
   "source": [
    "本次采用混合蒸馏方式分布级蒸馏+特征级蒸馏。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4126007",
   "metadata": {},
   "source": [
    "!pip install transformers accelerate sentencepiece    \n",
    "!pip install torch>=2.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dc2f936",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "检测到GPU总内存: 79.14GB\n",
      "统一设备配置: cuda\n",
      "开始渐进式蒸馏过程...\n",
      "加载分词器...\n",
      "准备4000个样本...\n",
      "训练样本: 7200, 验证样本: 800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "预处理数据: 100%|██████████| 7200/7200 [00:15<00:00, 460.89it/s]\n",
      "预处理数据: 100%|██████████| 800/800 [00:01<00:00, 406.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载学生模型...\n",
      "[2025-05-09 00:12:31,652] [INFO] [real_accelerator.py:239:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/compiler_compat/ld: cannot find -laio: No such file or directory\n",
      "collect2: error: ld returned 1 exit status\n",
      "/root/miniconda3/compiler_compat/ld: warning: libpthread.so.0, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/root/miniconda3/compiler_compat/ld: warning: libstdc++.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/root/miniconda3/compiler_compat/ld: warning: libm.so.6, needed by /usr/local/cuda/lib64/libcufile.so, not found (try using -rpath or -rpath-link)\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::runtime_error::~runtime_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__gxx_personality_v0@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::tellp()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::steady_clock::now()@GLIBCXX_3.4.19'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_replace_aux(unsigned long, unsigned long, unsigned long, char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for bool@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_logic_error(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::logic_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::~locale()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_end_catch@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::logic_error::~logic_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__si_class_type_info@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new[](unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak_hard()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::basic_streambuf(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::string const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned short@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::resize(unsigned long, char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char const*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ctype<char>::_M_widen_init() const@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_invalid_argument(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::operator=(std::locale const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::_M_cache_locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_free_exception@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::notify_one()@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::~Init()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::~basic_string()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_pure_virtual@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::flush()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for __cxxabiv1::__class_type_info@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_rethrow@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_fstream<char, std::char_traits<char> >::~basic_fstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::compare(char const*) const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::chrono::_V2::system_clock::now()@GLIBCXX_3.4.19'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_ifstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Hash_bytes(void const*, unsigned long, unsigned long)@CXXABI_1.3.5'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long long>(long long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for char*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_Prime_rehash_policy::_M_need_rehash(unsigned long, unsigned long, unsigned long) const@GLIBCXX_3.4.18'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::out_of_range@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long>(unsigned long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::~ios_base()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::range_error::~range_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::~__basic_file()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_acquire@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<bool>(bool)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::overflow_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::range_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_filebuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete[](void*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(unsigned long, char, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_transfer(std::__detail::_List_node_base*, std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::replace(unsigned long, unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::exception@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_M_destroy(std::allocator<wchar_t> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream& std::istream::_M_extract<double>(double&)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_fstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::basic_ifstream(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(std::string const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator new(unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned int@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::append(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::domain_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char, unsigned long) const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::put(char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_alloc()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_thread_atexit@CXXABI_1.3.7'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_increment(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::~basic_ifstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::Init::Init()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::condition_variable()@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::basic_filebuf()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::domain_error::~domain_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cerr@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::find(char const*, unsigned long, unsigned long) const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::str() const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::invalid_argument@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(std::string const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_ostringstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_rebalance_for_erase(std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_hook(std::__detail::_List_node_base*)@GLIBCXX_3.4.15'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__detail::_List_node_base::_M_unhook()@GLIBCXX_3.4.15'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<char, std::char_traits<char>, std::allocator<char> >::_M_sync(char*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<char, std::char_traits<char> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::locale::locale(std::locale const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_istringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `log2f@GLIBC_2.2.5'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::exception::~exception()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_create(unsigned long, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__basic_file<char>::is_open() const@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_istringstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::swap(std::string&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ostringstream<char, std::char_traits<char>, std::allocator<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::basic_streambuf(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::init(std::basic_streambuf<char, std::char_traits<char> >*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_bad_cast()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<char, std::char_traits<char> >::clear(std::_Ios_Iostate)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >::operator=(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> > const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `operator delete(void*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream::operator<<(int)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_Rep::_M_destroy(std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_iostream<wchar_t, std::char_traits<wchar_t> >::~basic_iostream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::runtime_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ofstream<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_insert_and_rebalance(bool, std::_Rb_tree_node_base*, std::_Rb_tree_node_base*, std::_Rb_tree_node_base&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringstream<char, std::char_traits<char>, std::allocator<char> >::~basic_stringstream()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `VTT for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<long>(long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::get()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned long long@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::operator<< <std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::out_of_range::~out_of_range()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::length_error::~length_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ostream<char, std::char_traits<char> >& std::__ostream_insert<char, std::char_traits<char> >(std::basic_ostream<char, std::char_traits<char> >&, char const*, long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::invalid_argument::~invalid_argument()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::swap(std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::cout@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<unsigned long long>(unsigned long long)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for int*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<void const*>(void const*)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::underflow_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_streambuf<char, std::char_traits<char> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for std::out_of_range@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_allocate_exception@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_ios<wchar_t, std::char_traits<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for void const*@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ios<wchar_t, std::char_traits<wchar_t> >::init(std::basic_streambuf<wchar_t, std::char_traits<wchar_t> >*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::reserve(unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_begin_catch@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_Rep::_S_empty_rep_storage@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::_M_leak()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::open(char const*, std::_Ios_Openmode)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >::_M_sync(wchar_t*, unsigned long, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::istream::getline(char*, long, char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_istream<char, std::char_traits<char> >& std::getline<char, std::char_traits<char>, std::allocator<char> >(std::basic_istream<char, std::char_traits<char> >&, std::basic_string<char, std::char_traits<char>, std::allocator<char> >&, char)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringstream<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::condition_variable::~condition_variable()@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::basic_stringbuf<wchar_t, std::char_traits<wchar_t>, std::allocator<wchar_t> >@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::insert(unsigned long, char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::string::assign(char const*, unsigned long)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for unsigned char@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ios_base::ios_base()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_out_of_range(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::overflow_error::~overflow_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_length_error(char const*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::__throw_system_error(int)@GLIBCXX_3.4.11'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ofstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::ostream& std::ostream::_M_insert<double>(double)@GLIBCXX_3.4.9'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_streambuf<char, std::char_traits<char> >::operator=(std::basic_streambuf<char, std::char_traits<char> > const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `typeinfo for long long@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_string<char, std::char_traits<char>, std::allocator<char> >::basic_string(char const*, unsigned long, std::allocator<char> const&)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_ifstream<char, std::char_traits<char> >::close()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_guard_release@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `__cxa_throw@CXXABI_1.3'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::underflow_error::~underflow_error()@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::_Rb_tree_decrement(std::_Rb_tree_node_base*)@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `vtable for std::length_error@GLIBCXX_3.4'\n",
      "/root/miniconda3/compiler_compat/ld: /usr/local/cuda/lib64/libcufile.so: undefined reference to `std::basic_filebuf<char, std::char_traits<char> >::~basic_filebuf()@GLIBCXX_3.4'\n",
      "collect2: error: ld returned 1 exit status\n",
      "/root/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n",
      "Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "成功启用梯度检查点\n",
      "检查学生模型维度...\n",
      "学生模型层数: 25\n",
      "  层 0: 维度 896\n",
      "  层 1: 维度 896\n",
      "  层 2: 维度 896\n",
      "  层 3: 维度 896\n",
      "  层 4: 维度 896\n",
      "  层 5: 维度 896\n",
      "  层 6: 维度 896\n",
      "  层 7: 维度 896\n",
      "  层 8: 维度 896\n",
      "  层 9: 维度 896\n",
      "  层 10: 维度 896\n",
      "  层 11: 维度 896\n",
      "  层 12: 维度 896\n",
      "  层 13: 维度 896\n",
      "  层 14: 维度 896\n",
      "  层 15: 维度 896\n",
      "  层 16: 维度 896\n",
      "  层 17: 维度 896\n",
      "  层 18: 维度 896\n",
      "  层 19: 维度 896\n",
      "  层 20: 维度 896\n",
      "  层 21: 维度 896\n",
      "  层 22: 维度 896\n",
      "  层 23: 维度 896\n",
      "  层 24: 维度 896\n",
      "准备训练...\n",
      "解冻: model.layers.23.self_attn.q_proj.weight\n",
      "解冻: model.layers.23.self_attn.q_proj.bias\n",
      "解冻: model.layers.23.self_attn.k_proj.weight\n",
      "解冻: model.layers.23.self_attn.k_proj.bias\n",
      "解冻: model.layers.23.self_attn.v_proj.weight\n",
      "解冻: model.layers.23.self_attn.v_proj.bias\n",
      "解冻: model.layers.23.self_attn.o_proj.weight\n",
      "解冻: model.layers.23.mlp.gate_proj.weight\n",
      "解冻: model.layers.23.mlp.up_proj.weight\n",
      "解冻: model.layers.23.mlp.down_proj.weight\n",
      "解冻: model.layers.23.input_layernorm.weight\n",
      "解冻: model.layers.23.post_attention_layernorm.weight\n",
      "解冻: model.layers.22.self_attn.q_proj.weight\n",
      "解冻: model.layers.22.self_attn.q_proj.bias\n",
      "解冻: model.layers.22.self_attn.k_proj.weight\n",
      "解冻: model.layers.22.self_attn.k_proj.bias\n",
      "解冻: model.layers.22.self_attn.v_proj.weight\n",
      "解冻: model.layers.22.self_attn.v_proj.bias\n",
      "解冻: model.layers.22.self_attn.o_proj.weight\n",
      "解冻: model.layers.22.mlp.gate_proj.weight\n",
      "解冻: model.layers.22.mlp.up_proj.weight\n",
      "解冻: model.layers.22.mlp.down_proj.weight\n",
      "解冻: model.layers.22.input_layernorm.weight\n",
      "解冻: model.layers.22.post_attention_layernorm.weight\n",
      "解冻: model.layers.21.self_attn.q_proj.weight\n",
      "解冻: model.layers.21.self_attn.q_proj.bias\n",
      "解冻: model.layers.21.self_attn.k_proj.weight\n",
      "解冻: model.layers.21.self_attn.k_proj.bias\n",
      "解冻: model.layers.21.self_attn.v_proj.weight\n",
      "解冻: model.layers.21.self_attn.v_proj.bias\n",
      "解冻: model.layers.21.self_attn.o_proj.weight\n",
      "解冻: model.layers.21.mlp.gate_proj.weight\n",
      "解冻: model.layers.21.mlp.up_proj.weight\n",
      "解冻: model.layers.21.mlp.down_proj.weight\n",
      "解冻: model.layers.21.input_layernorm.weight\n",
      "解冻: model.layers.21.post_attention_layernorm.weight\n",
      "解冻: model.layers.20.self_attn.q_proj.weight\n",
      "解冻: model.layers.20.self_attn.q_proj.bias\n",
      "解冻: model.layers.20.self_attn.k_proj.weight\n",
      "解冻: model.layers.20.self_attn.k_proj.bias\n",
      "解冻: model.layers.20.self_attn.v_proj.weight\n",
      "解冻: model.layers.20.self_attn.v_proj.bias\n",
      "解冻: model.layers.20.self_attn.o_proj.weight\n",
      "解冻: model.layers.20.mlp.gate_proj.weight\n",
      "解冻: model.layers.20.mlp.up_proj.weight\n",
      "解冻: model.layers.20.mlp.down_proj.weight\n",
      "解冻: model.layers.20.input_layernorm.weight\n",
      "解冻: model.layers.20.post_attention_layernorm.weight\n",
      "解冻: model.embed_tokens.weight\n",
      "已解冻 49 个参数\n",
      "临时加载教师模型检查维度...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/lib/python3.12/site-packages/transformers/generation/configuration_utils.py:820: UserWarning: `return_dict_in_generate` is NOT set to `True`, but `output_hidden_states` is. When `return_dict_in_generate` is not `True`, `output_hidden_states` is ignored.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c6824033a8a4477ba98b2038a244e82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "教师模型层数: 33\n",
      "教师模型层数: 33\n",
      "  层 0: 维度 4096\n",
      "  层 1: 维度 4096\n",
      "  层 2: 维度 4096\n",
      "  层 3: 维度 4096\n",
      "  层 4: 维度 4096\n",
      "  层 5: 维度 4096\n",
      "  层 6: 维度 4096\n",
      "  层 7: 维度 4096\n",
      "  层 8: 维度 4096\n",
      "  层 9: 维度 4096\n",
      "  层 10: 维度 4096\n",
      "  层 11: 维度 4096\n",
      "  层 12: 维度 4096\n",
      "  层 13: 维度 4096\n",
      "  层 14: 维度 4096\n",
      "  层 15: 维度 4096\n",
      "  层 16: 维度 4096\n",
      "  层 17: 维度 4096\n",
      "  层 18: 维度 4096\n",
      "  层 19: 维度 4096\n",
      "  层 20: 维度 4096\n",
      "  层 21: 维度 4096\n",
      "  层 22: 维度 4096\n",
      "  层 23: 维度 4096\n",
      "  层 24: 维度 4096\n",
      "  层 25: 维度 4096\n",
      "  层 26: 维度 4096\n",
      "  层 27: 维度 4096\n",
      "  层 28: 维度 4096\n",
      "  层 29: 维度 4096\n",
      "  层 30: 维度 4096\n",
      "  层 31: 维度 4096\n",
      "  层 32: 维度 4096\n",
      "注意: 教师模型不支持输出注意力权重，将禁用注意力蒸馏\n",
      "创建单层特征映射器...\n",
      "执行热身推理...\n",
      "Epoch 1/3\n",
      "本轮权重: 响应级 1.000, 特征级 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1:  22%|██▏       | 199/900 [44:35<2:09:43, 11.10s/it, loss=13.269773, resp_loss=2.653955, feat_loss=0.000000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 200, 验证损失: 13.330167, 当前最佳: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1:  22%|██▏       | 200/900 [57:54<48:46:39, 250.86s/it, loss=13.269773, resp_loss=2.653955, feat_loss=0.000000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1:  44%|████▍     | 399/900 [1:35:16<1:33:23, 11.18s/it, loss=13.108273, resp_loss=2.621655, feat_loss=0.000000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 400, 验证损失: 13.222851, 当前最佳: 13.330167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1:  44%|████▍     | 400/900 [1:48:36<34:52:28, 251.10s/it, loss=13.108273, resp_loss=2.621655, feat_loss=0.000000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1:  67%|██████▋   | 599/900 [2:25:50<55:52, 11.14s/it, loss=12.878502, resp_loss=2.575700, feat_loss=0.000000]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 600, 验证损失: 13.056371, 当前最佳: 13.222851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1:  67%|██████▋   | 600/900 [2:39:05<20:48:52, 249.78s/it, loss=12.878502, resp_loss=2.575700, feat_loss=0.000000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1:  89%|████████▉ | 799/900 [3:16:17<18:46, 11.15s/it, loss=13.073080, resp_loss=2.614616, feat_loss=0.000000]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 800, 验证损失: 12.792996, 当前最佳: 13.056371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1:  89%|████████▉ | 800/900 [3:29:36<6:57:45, 250.65s/it, loss=13.073080, resp_loss=2.614616, feat_loss=0.000000]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 1: 100%|██████████| 900/900 [3:48:13<00:00, 15.22s/it, loss=12.509165, resp_loss=2.501833, feat_loss=0.000000]   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 完成, 平均训练损失: 13.086791\n",
      "GPU内存: 已分配 0.00GB, 已保留 0.00GB\n",
      "梯度范数: 30.1714\n",
      "警告: 梯度范数过大 (30.1714)，调整优化步骤\n",
      "Epoch 2/3\n",
      "本轮权重: 响应级 0.800, 特征级 0.200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2:  11%|█         | 100/900 [31:51<55:11:36, 248.37s/it, loss=13.320787, resp_loss=2.564216, feat_loss=0.099941]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1000, 验证损失: 13.016069, 当前最佳: 12.792996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2:  33%|███▎      | 299/900 [1:09:02<1:51:30, 11.13s/it, loss=12.733960, resp_loss=2.448139, feat_loss=0.098653]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1200, 验证损失: 12.668683, 当前最佳: 12.792996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2:  33%|███▎      | 300/900 [1:22:19<41:40:15, 250.03s/it, loss=12.733960, resp_loss=2.448139, feat_loss=0.098653]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2:  55%|█████▌    | 499/900 [1:59:26<1:13:55, 11.06s/it, loss=12.092804, resp_loss=2.320378, feat_loss=0.098182]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1400, 验证损失: 12.281133, 当前最佳: 12.668683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2:  56%|█████▌    | 500/900 [2:12:43<27:48:31, 250.28s/it, loss=12.092804, resp_loss=2.320378, feat_loss=0.098182]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2:  78%|███████▊  | 699/900 [2:49:57<38:08, 11.38s/it, loss=12.310715, resp_loss=2.362765, feat_loss=0.099378]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1600, 验证损失: 11.867267, 当前最佳: 12.281133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2:  78%|███████▊  | 700/900 [3:03:13<13:53:39, 250.10s/it, loss=12.310715, resp_loss=2.362765, feat_loss=0.099378]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2: 100%|█████████▉| 899/900 [3:40:27<00:11, 11.17s/it, loss=10.926286, resp_loss=2.089235, feat_loss=0.096022]    "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1800, 验证损失: 11.382619, 当前最佳: 11.867267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 2: 100%|██████████| 900/900 [3:53:45<00:00, 15.58s/it, loss=10.926286, resp_loss=2.089235, feat_loss=0.096022] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n",
      "Epoch 2 完成, 平均训练损失: 12.285311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU内存: 已分配 0.00GB, 已保留 0.00GB\n",
      "梯度范数: 27.4517\n",
      "警告: 梯度范数过大 (27.4517)，调整优化步骤\n",
      "Epoch 3/3\n",
      "本轮权重: 响应级 0.600, 特征级 0.400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 3:  22%|██▏       | 199/900 [37:14<2:09:40, 11.10s/it, loss=11.184345, resp_loss=2.140039, feat_loss=0.096830]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2000, 验证损失: 10.989277, 当前最佳: 11.382619\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 3:  22%|██▏       | 200/900 [53:17<58:20:22, 300.03s/it, loss=11.184345, resp_loss=2.140039, feat_loss=0.096830]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 3:  44%|████▍     | 399/900 [1:42:10<2:01:24, 14.54s/it, loss=10.176765, resp_loss=1.941528, feat_loss=0.093825]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2200, 验证损失: 10.584100, 当前最佳: 10.989277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 3:  44%|████▍     | 400/900 [1:59:59<46:33:43, 335.25s/it, loss=10.176765, resp_loss=1.941528, feat_loss=0.093825]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "保存当前最佳模型到 /root/autodl-tmp/distilled_model_best\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "训练 Epoch 3:  67%|██████▋   | 599/900 [2:50:01<1:43:20, 20.60s/it, loss=10.147943, resp_loss=1.934293, feat_loss=0.095296]  "
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import json\n",
    "import os\n",
    "import gc\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "# 定义模型路径：指定教师模型、学生模型、训练数据和输出路径\n",
    "teacher_model_path = \"/root/autodl-tmp/deepseek-ai/DeepSeek-R1-Distill-Llama-8B\"\n",
    "student_model_path = \"/root/autodl-tmp/Qwen/Qwen2___5-0___5B-Instruct\"\n",
    "# 训练数据：包含2万个样本的JSONL文件，每行是一个训练样本\n",
    "data_path = \"/root/autodl-tmp/train_cot_sft_2w.jsonl\"\n",
    "# 输出目录：存放蒸馏后的模型\n",
    "output_dir = \"/root/autodl-tmp/distilled_model\"\n",
    "\n",
    "# 定义简单线性特征映射器类\n",
    "# 作用：将教师模型的隐藏状态向量映射到学生模型的隐藏状态维度\n",
    "# 这是最基础的特征映射方法，通过一个线性层实现特征空间转换\n",
    "class SimpleMapper(nn.Module):\n",
    "    def __init__(self, teacher_dim, student_dim):\n",
    "        \"\"\"\n",
    "        初始化简单特征映射器\n",
    "        参数:\n",
    "            teacher_dim: 教师模型隐藏状态的维度\n",
    "            student_dim: 学生模型隐藏状态的维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 创建一个线性变换层，将teacher_dim维的向量映射为student_dim维\n",
    "        self.linear = nn.Linear(teacher_dim, student_dim)\n",
    "        # 使用正态分布初始化权重，均值为0，标准差为0.02\n",
    "        # 这是Transformer模型常用的初始化方法，有助于训练稳定\n",
    "        nn.init.normal_(self.linear.weight, mean=0.0, std=0.02)\n",
    "        # 将偏置初始化为0\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "        \n",
    "    def forward(self, teacher_feature):\n",
    "        \"\"\"\n",
    "        前向传播：应用线性变换\n",
    "        参数:\n",
    "            teacher_feature: 教师模型的隐藏状态 [batch_size, seq_len, teacher_dim]\n",
    "        返回:\n",
    "            映射后的特征 [batch_size, seq_len, student_dim]\n",
    "        \"\"\"\n",
    "        return self.linear(teacher_feature)\n",
    "\n",
    "# 多层特征映射器 - 主体代码没有用到的模块\n",
    "# 如果要使用此映射器，需要将ProgressiveDistiller中的self.use_multi_layer设置为True\n",
    "# 此映射器可以同时处理多个层的特征映射，实现更细粒度的知识迁移\n",
    "class MultiLayerFeatureMapper(nn.Module):\n",
    "    def __init__(self, teacher_dims, student_dims):\n",
    "        \"\"\"\n",
    "        初始化多层特征映射器\n",
    "        参数:\n",
    "            teacher_dims: 教师模型各层隐藏状态的维度列表\n",
    "            student_dims: 学生模型各层隐藏状态的维度列表\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 为每对教师-学生层维度创建一个高级特征映射器\n",
    "        self.mappers = nn.ModuleList()\n",
    "        for teacher_dim, student_dim in zip(teacher_dims, student_dims):\n",
    "            self.mappers.append(AdvancedFeatureMapper(teacher_dim, student_dim))\n",
    "            \n",
    "    def forward(self, teacher_features, layer_indices):\n",
    "        \"\"\"\n",
    "        前向传播：映射多层特征\n",
    "        参数:\n",
    "            teacher_features: 教师模型的所有层隐藏状态列表\n",
    "            layer_indices: 需要映射的层索引列表\n",
    "        返回:\n",
    "            映射后的特征列表，与学生模型的对应层匹配\n",
    "        \"\"\"\n",
    "        mapped_features = []\n",
    "        for i, idx in enumerate(layer_indices):\n",
    "            # 检查索引是否有效\n",
    "            if idx < len(teacher_features) and i < len(self.mappers):\n",
    "                mapped_features.append(self.mappers[i](teacher_features[idx]))\n",
    "        return mapped_features\n",
    "\n",
    "# 高级特征映射器 - 主体代码没有用到的模块\n",
    "# 这是一个更复杂的单层特征映射器，使用了层归一化和非线性激活\n",
    "# 相比SimpleMapper，可以捕获更复杂的特征关系\n",
    "class AdvancedFeatureMapper(nn.Module):\n",
    "    def __init__(self, teacher_dim, student_dim):\n",
    "        \"\"\"\n",
    "        初始化高级特征映射器\n",
    "        参数:\n",
    "            teacher_dim: 教师模型隐藏状态的维度\n",
    "            student_dim: 学生模型隐藏状态的维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 为教师特征添加层归一化，这有助于稳定训练\n",
    "        self.teacher_norm = nn.LayerNorm(teacher_dim)\n",
    "        # 为学生特征添加层归一化\n",
    "        self.student_norm = nn.LayerNorm(student_dim)\n",
    "        \n",
    "        # 计算中间隐藏层维度，取两个维度的平均值\n",
    "        hidden_dim = (teacher_dim + student_dim) // 2\n",
    "        # 降维投影层：从教师维度到隐藏维度\n",
    "        self.down_proj = nn.Linear(teacher_dim, hidden_dim)\n",
    "        # 非线性激活函数：GELU比ReLU在NLP任务中通常效果更好\n",
    "        self.activation = nn.GELU()\n",
    "        # 升维投影层：从隐藏维度到学生维度\n",
    "        self.up_proj = nn.Linear(hidden_dim, student_dim)\n",
    "        \n",
    "    def forward(self, teacher_feature):\n",
    "        \"\"\"\n",
    "        前向传播：应用归一化、降维、非线性激活和升维\n",
    "        参数:\n",
    "            teacher_feature: 教师模型的隐藏状态\n",
    "        返回:\n",
    "            映射后的特征，维度与学生模型匹配\n",
    "        \"\"\"\n",
    "        # 首先对输入应用层归一化\n",
    "        x = self.teacher_norm(teacher_feature)\n",
    "        # 降维\n",
    "        x = self.down_proj(x)\n",
    "        # 应用非线性激活\n",
    "        x = self.activation(x)\n",
    "        # 升维，映射到学生维度\n",
    "        x = self.up_proj(x)\n",
    "        return x\n",
    "\n",
    "# 增强特征映射器 - 主体代码没有用到部分\n",
    "# 这是一个更复杂的特征映射器，增加了中间层和dropout\n",
    "# 如果想使用，需要修改MultiLayerFeatureMapper代码，将AdvancedFeatureMapper替换为EnhancedFeatureMapper\n",
    "# 此映射器通过多层映射和dropout可以更好地泛化，对于复杂特征迁移可能效果更好\n",
    "class EnhancedFeatureMapper(nn.Module):\n",
    "    def __init__(self, teacher_dim, student_dim):\n",
    "        \"\"\"\n",
    "        初始化增强特征映射器\n",
    "        参数:\n",
    "            teacher_dim: 教师模型隐藏状态的维度\n",
    "            student_dim: 学生模型隐藏状态的维度\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # 为教师和学生特征添加层归一化\n",
    "        self.teacher_norm = nn.LayerNorm(teacher_dim)\n",
    "        self.student_norm = nn.LayerNorm(student_dim)\n",
    "        \n",
    "        # 使用多个隐藏层的映射网络，实现更复杂的非线性变换\n",
    "        # 第一个隐藏层维度：教师和学生维度的平均值\n",
    "        hidden_dim1 = (teacher_dim + student_dim) // 2\n",
    "        # 第二个隐藏层维度：第一隐藏层和学生维度的平均值\n",
    "        hidden_dim2 = (hidden_dim1 + student_dim) // 2\n",
    "        \n",
    "        # 三层映射网络：教师维度 -> 隐藏层1 -> 隐藏层2 -> 学生维度\n",
    "        self.down_proj = nn.Linear(teacher_dim, hidden_dim1)\n",
    "        self.mid_proj = nn.Linear(hidden_dim1, hidden_dim2)\n",
    "        self.up_proj = nn.Linear(hidden_dim2, student_dim)\n",
    "        \n",
    "        # 添加dropout层，减少过拟合\n",
    "        self.dropout = nn.Dropout(0.1)  # 10%的dropout率\n",
    "        # 非线性激活函数\n",
    "        self.activation = nn.GELU()\n",
    "        \n",
    "    def forward(self, teacher_feature):\n",
    "        \"\"\"\n",
    "        前向传播：应用多层非线性变换和dropout\n",
    "        参数:\n",
    "            teacher_feature: 教师模型的隐藏状态\n",
    "        返回:\n",
    "            映射后的特征，维度与学生模型匹配\n",
    "        \"\"\"\n",
    "        # 首先对输入应用层归一化\n",
    "        x = self.teacher_norm(teacher_feature)\n",
    "        # 第一层投影\n",
    "        x = self.down_proj(x)\n",
    "        # 应用非线性激活\n",
    "        x = self.activation(x)\n",
    "        # 应用dropout，增强泛化能力\n",
    "        x = self.dropout(x)\n",
    "        # 第二层投影\n",
    "        x = self.mid_proj(x)\n",
    "        # 再次应用非线性激活\n",
    "        x = self.activation(x)\n",
    "        # 再次应用dropout\n",
    "        x = self.dropout(x)\n",
    "        # 最后一层投影，映射到学生维度\n",
    "        x = self.up_proj(x)\n",
    "        return x\n",
    "\n",
    "# 自定义文本数据集类，处理和准备蒸馏训练数据\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, examples, max_length, teacher_tokenizer, student_tokenizer):\n",
    "        \"\"\"\n",
    "        初始化文本数据集\n",
    "        参数:\n",
    "            examples: 文本样本列表，每个样本包含text和is_full字段\n",
    "            max_length: 序列最大长度\n",
    "            teacher_tokenizer: 教师模型的分词器\n",
    "            student_tokenizer: 学生模型的分词器\n",
    "        \"\"\"\n",
    "        self.examples = examples\n",
    "        self.max_length = max_length\n",
    "        self.teacher_tokenizer = teacher_tokenizer\n",
    "        self.student_tokenizer = student_tokenizer\n",
    "        \n",
    "        # 预处理所有样本以加速训练（避免每次迭代时重复分词）\n",
    "        self.preprocessed_data = []\n",
    "        # 使用tqdm显示预处理进度\n",
    "        for example in tqdm(examples, desc=\"预处理数据\"):\n",
    "            text = example[\"text\"]\n",
    "            \n",
    "            # 使用教师模型的分词器处理文本\n",
    "            # max_length: 截断或填充到指定长度\n",
    "            # padding: 填充到max_length\n",
    "            # truncation: 如果超出max_length则截断\n",
    "            # return_tensors: 返回PyTorch张量\n",
    "            teacher_inputs = self.teacher_tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # 使用学生模型的分词器处理相同文本\n",
    "            # 注意：不同模型的分词器可能会产生不同的标记序列\n",
    "            student_inputs = self.student_tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_tensors=\"pt\"\n",
    "            )\n",
    "            \n",
    "            # 存储预处理后的数据\n",
    "            # squeeze(0)去除批次维度，使张量形状为[seq_len]或[seq_len, dim]\n",
    "            self.preprocessed_data.append({\n",
    "                \"teacher_inputs\": {\n",
    "                    \"input_ids\": teacher_inputs.input_ids.squeeze(0),  # [seq_len]\n",
    "                    \"attention_mask\": teacher_inputs.attention_mask.squeeze(0)  # [seq_len]\n",
    "                },\n",
    "                \"student_inputs\": {\n",
    "                    \"input_ids\": student_inputs.input_ids.squeeze(0),  # [seq_len]\n",
    "                    \"attention_mask\": student_inputs.attention_mask.squeeze(0)  # [seq_len]\n",
    "                }\n",
    "            })\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"返回数据集中样本数量\"\"\"\n",
    "        return len(self.preprocessed_data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"获取指定索引的样本\"\"\"\n",
    "        return self.preprocessed_data[idx]\n",
    "\n",
    "# 渐进式蒸馏器主类，实现整个模型蒸馏过程\n",
    "# 该类负责加载模型、准备数据、训练配置及执行训练循环\n",
    "class ProgressiveDistiller:\n",
    "    def __init__(self, low_resource_mode=False):\n",
    "        \"\"\"\n",
    "        初始化渐进式蒸馏器\n",
    "        参数:\n",
    "            low_resource_mode: 是否在低资源环境下运行(GPU内存较小时)\n",
    "        \"\"\"\n",
    "        # ===== 序列和批处理配置 =====\n",
    "        # 设置最大序列长度为512个token\n",
    "        self.max_length = 512        \n",
    "        # 每批次处理8个样本\n",
    "        self.batch_size = 8          \n",
    "        # 梯度累积步数：每32批次才更新一次参数\n",
    "        # 这样效果相当于使用了8*32=256的批量大小，但显存占用只有8个样本的水平\n",
    "        self.gradient_accumulation_steps = 32  \n",
    "        \n",
    "        # ===== 优化器配置 影响模型的学习行为和泛化能力。 =====\n",
    "        # 基础学习率设为1e-5，相对保守的值越小越稳定，但是学的慢\n",
    "        self.base_lr = 1e-5          \n",
    "        # 权重衰减系数，用于L2正则化，减轻过拟合\n",
    "        self.weight_decay = 0.05     \n",
    "        \n",
    "        # ===== 梯度裁剪配置 =====\n",
    "        # 梯度裁剪阈值：限制梯度范数不超过0.5，防止梯度爆炸\n",
    "        self.max_grad_norm = 0.5     \n",
    "                \n",
    "        # ===== 训练基本配置 =====\n",
    "        # 使用的样本数量：从数据集中取前4000个样本\n",
    "        self.num_samples = 4000      \n",
    "        # 训练轮次：对所有数据训练3轮\n",
    "        self.epochs = 3              \n",
    "        # 每200步验证一次模型性能\n",
    "        self.eval_steps = 200        \n",
    "        # 是否使用特征蒸馏：使用隐藏状态蒸馏\n",
    "        self.use_feature_distill = True  \n",
    "        # 特征蒸馏损失的权重：占总损失的50%\n",
    "        self.feature_weight = 0.5    \n",
    "        # 早停耐心值：如果连续3次验证都没有改善，则停止训练\n",
    "        self.patience = 3            \n",
    "        \n",
    "        # ===== 分层蒸馏策略 =====\n",
    "        # 是否使用多层映射：默认为False，只使用最后一层映射\n",
    "        self.use_multi_layer = False    \n",
    "        # 选择的教师模型层索引：第0层(嵌入层)、第12层、第24层(最后层)\n",
    "        self.teacher_layers = [0, 12, 24]  \n",
    "        # 选择的学生模型层索引：第0层(嵌入层)、第8层、第16层(最后层)\n",
    "        # 注意：学生模型层数可能少于教师模型\n",
    "        self.student_layers = [0, 8, 16]   \n",
    "        \n",
    "        # ===== 混合精度训练配置 =====\n",
    "        # 是否使用混合精度训练：默认不使用，以保证数值稳定性\n",
    "        self.mixed_precision = False  \n",
    "        # 设置运行设备：优先使用CUDA，否则使用CPU\n",
    "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")  \n",
    "        \n",
    "        # 如果使用混合精度训练，初始化梯度缩放器\n",
    "        # 梯度缩放器用于防止FP16计算中的梯度下溢\n",
    "        if self.mixed_precision:\n",
    "            self.scaler = GradScaler()     \n",
    "      \n",
    "        # ===== 资源配置 =====\n",
    "        # 是否使用低资源模式：根据传入参数决定\n",
    "        self.low_resource_mode = low_resource_mode\n",
    "        \n",
    "        # ===== 损失函数配置(可以后续作为开关使用) =====\n",
    "        # 对logits使用的损失类型：均方误差(MSE)\n",
    "        self.logits_loss_type = \"mse\"     \n",
    "        # 对特征使用的损失类型：余弦相似度\n",
    "        self.features_loss_type = \"cosine\" \n",
    "        # 损失缩放因子：将损失值放大10倍，避免过小的损失值（可以选择使用）\n",
    "        self.loss_scale = 10.0            \n",
    "        \n",
    "        # ===== 设备配置 =====\n",
    "        self.teacher_device = torch.device(\"cuda:0\")  # 教师模型在GPU 0\n",
    "        self.student_device = torch.device(\"cuda:1\")  # 学生模型在GPU 1\n",
    "        self.mapper_device = torch.device(\"cuda:1\")   # 映射器在GPU 1\n",
    "        \n",
    "        # 打印设备配置信息\n",
    "        print(f\"统一设备配置: {self.device}\")\n",
    "    \n",
    "    # 运行蒸馏过程的主方法\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        执行完整的渐进式蒸馏过程，包括模型加载、数据准备、训练循环和模型保存\n",
    "        返回:\n",
    "            bool: 蒸馏是否成功完成\n",
    "        \"\"\"\n",
    "        print(\"开始渐进式蒸馏过程...\")\n",
    "        try:\n",
    "            # 1. 加载分词器：用于将文本转换为模型可处理的标记序列\n",
    "            print(\"加载分词器...\")\n",
    "            # 加载教师模型的分词器\n",
    "            teacher_tokenizer = AutoTokenizer.from_pretrained(teacher_model_path)\n",
    "            # 加载学生模型的分词器\n",
    "            student_tokenizer = AutoTokenizer.from_pretrained(student_model_path)\n",
    "            \n",
    "            # 2. 准备样本数据：从JSONL文件加载训练数据\n",
    "            print(f\"准备{self.num_samples}个样本...\")\n",
    "            examples = []\n",
    "            count = 0\n",
    "            \n",
    "            # 打开并读取JSONL格式的训练数据\n",
    "            # JSONL格式：每行是一个独立的JSON对象\n",
    "            with open(data_path, 'r') as f:\n",
    "                for line in f:\n",
    "                    # 达到指定样本数后停止读取\n",
    "                    if count >= self.num_samples:\n",
    "                        break\n",
    "                    # 解析JSON行\n",
    "                    data = json.loads(line)\n",
    "                    \n",
    "                    # 分离输入和输出部分\n",
    "                    # \"input\": 模型的提示/上下文部分\n",
    "                    # \"output\": 模型应生成的输出部分\n",
    "                    input_text = data[\"input\"]\n",
    "                    output_text = data[\"output\"]\n",
    "                    \n",
    "                    # 添加两种样本以增强训练效果：\n",
    "                    # 1. 完整样本(输入+输出)：训练模型理解完整上下文\n",
    "                    examples.append({\n",
    "                        \"text\": input_text + output_text,\n",
    "                        \"is_full\": True\n",
    "                    })\n",
    "                    \n",
    "                    # 2. 仅输出样本：专注于输出部分的蒸馏\n",
    "                    examples.append({\n",
    "                        \"text\": output_text,\n",
    "                        \"is_full\": False\n",
    "                    })\n",
    "                    \n",
    "                    count += 1\n",
    "            \n",
    "            # 分割训练集和验证集：90%用于训练，10%用于验证\n",
    "            split_idx = int(len(examples) * 0.9)\n",
    "            train_examples = examples[:split_idx]\n",
    "            val_examples = examples[split_idx:]\n",
    "            print(f\"训练样本: {len(train_examples)}, 验证样本: {len(val_examples)}\")\n",
    "            \n",
    "            # 3. 创建数据集和数据加载器\n",
    "            # 创建训练集和验证集对象\n",
    "            train_dataset = TextDataset(train_examples, self.max_length, teacher_tokenizer, student_tokenizer)\n",
    "            val_dataset = TextDataset(val_examples, self.max_length, teacher_tokenizer, student_tokenizer)\n",
    "            \n",
    "            # 在创建DataLoader之前设置环境变量，避免分词器并行警告\n",
    "            os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "            # 配置训练数据加载器，优化加载效率\n",
    "            train_loader = DataLoader(\n",
    "                train_dataset, \n",
    "                batch_size=self.batch_size, \n",
    "                shuffle=True,  # 随机打乱数据顺序\n",
    "                num_workers=2,  # 使用2个子进程加载数据\n",
    "                pin_memory=True,  # 将数据固定在内存中加速GPU访问\n",
    "                prefetch_factor=2,  # 每个worker预取2个批次\n",
    "                persistent_workers=True  # 在迭代结束后保持worker进程，避免频繁创建销毁\n",
    "            )\n",
    "            # 验证数据加载器\n",
    "            val_loader = DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False)\n",
    "            \n",
    "            # 4. 加载学生模型：将被优化的模型\n",
    "            print(\"加载学生模型...\")\n",
    "            # 手动清理内存，减少内存碎片\n",
    "            gc.collect()\n",
    "            \n",
    "            # 使用AutoModelForCausalLM加载学生模型，设置多个关键参数\n",
    "            student_model = AutoModelForCausalLM.from_pretrained(\n",
    "                student_model_path,\n",
    "                torch_dtype=torch.float32,  # 使用32位浮点精度，提高训练稳定性\n",
    "                device_map=\"auto\",  # 自动决定模型如何分布在可用设备上\n",
    "                trust_remote_code=True,  # 允许运行模型仓库中的自定义代码\n",
    "                output_hidden_states=True,  # 输出所有层的隐藏状态，用于特征蒸馏\n",
    "                use_cache=False  # 禁用KV缓存以节省内存，这在训练中不需要\n",
    "            )\n",
    "            \n",
    "            # 尝试启用梯度检查点来节省内存\n",
    "            # 梯度检查点会在前向传播时释放中间激活值，在反向传播时重新计算\n",
    "            # 这会增加计算量但大幅减少内存使用\n",
    "            try:\n",
    "                # 直接尝试调用模型的梯度检查点启用方法\n",
    "                if hasattr(student_model, 'gradient_checkpointing_enable'):\n",
    "                    student_model.gradient_checkpointing_enable()\n",
    "                    print(\"成功启用梯度检查点\")\n",
    "                # 有些模型将方法封装在.model属性中\n",
    "                elif hasattr(student_model, 'model') and hasattr(student_model.model, 'gradient_checkpointing_enable'):\n",
    "                    student_model.model.gradient_checkpointing_enable()\n",
    "                    print(\"成功启用梯度检查点 (通过model属性)\")\n",
    "                else:\n",
    "                    print(\"警告: 此模型不支持梯度检查点，将继续执行但可能占用更多内存\")\n",
    "            except Exception as e:\n",
    "                print(f\"启用梯度检查点失败: {e}\")\n",
    "            \n",
    "            # 5. 检查学生模型的隐藏状态维度\n",
    "            # 这一步是为了确定特征映射器的输入/输出维度\n",
    "            print(\"检查学生模型维度...\")\n",
    "            with torch.no_grad():  # 不计算梯度，节省内存\n",
    "                # 获取一个批次的数据\n",
    "                batch = next(iter(train_loader))\n",
    "                # 只使用第一个样本进行测试\n",
    "                student_inputs = {\n",
    "                    \"input_ids\": batch[\"student_inputs\"][\"input_ids\"][:1],  # [1, seq_len]\n",
    "                    \"attention_mask\": batch[\"student_inputs\"][\"attention_mask\"][:1]  # [1, seq_len]\n",
    "                }\n",
    "                \n",
    "                # 前向传播获取隐藏状态\n",
    "                student_outputs = student_model(**student_inputs, output_hidden_states=True)\n",
    "                # 提取所有层的隐藏状态\n",
    "                student_hidden_states = student_outputs.hidden_states  # list of [1, seq_len, hidden_dim]\n",
    "                # 计算模型总层数\n",
    "                num_layers = len(student_hidden_states)\n",
    "                # 获取每层的隐藏维度\n",
    "                student_dims = [h.size(-1) for h in student_hidden_states]\n",
    "                \n",
    "                # 打印学生模型层信息\n",
    "                print(f\"学生模型层数: {num_layers}\")\n",
    "                for i, dim in enumerate(student_dims):\n",
    "                    print(f\"  层 {i}: 维度 {dim}\")\n",
    "            \n",
    "            # 6. 设置训练参数：配置模型参数的冻结/解冻状态\n",
    "            print(\"准备训练...\")\n",
    "            # 首先冻结所有参数，默认不训练\n",
    "            for param in student_model.parameters():\n",
    "                param.requires_grad = False\n",
    "            \n",
    "            # 解冻指定层以提高学习效果\n",
    "            # 这里选择解冻最后4层，这些层通常对模型输出影响最大\n",
    "            trainable_layers = [-1, -2, -3, -4]  # 使用负索引表示从后向前数\n",
    "            trainable_params = []  # 存储需要训练的参数\n",
    "            \n",
    "            # 计算实际层索引并解冻指定层\n",
    "            for layer_idx in trainable_layers:\n",
    "                # 计算实际层索引：负索引转换为正索引\n",
    "                actual_idx = num_layers + layer_idx if layer_idx < 0 else layer_idx\n",
    "                # 构建层名称，注意-1是因为hidden_states包含嵌入层\n",
    "                layer_name = f\"model.layers.{actual_idx-1}\"\n",
    "                \n",
    "                # 标记是否找到匹配的层\n",
    "                layers_found = False\n",
    "                # 遍历所有命名参数\n",
    "                for name, param in student_model.named_parameters():\n",
    "                    # 如果参数名包含目标层名称，则解冻该参数\n",
    "                    if layer_name in name:\n",
    "                        param.requires_grad = True\n",
    "                        trainable_params.append(param)\n",
    "                        layers_found = True\n",
    "                        print(f\"解冻: {name}\")\n",
    "                \n",
    "                # 如果未找到目标层，打印警告\n",
    "                if not layers_found:\n",
    "                    print(f\"警告: 未找到层 {layer_name}\")\n",
    "            \n",
    "            # 额外解冻LM头(输出层)和嵌入层，这些层对模型输出和输入表示很重要\n",
    "            lm_head_found = False\n",
    "            for name, param in student_model.named_parameters():\n",
    "                # 如果参数名包含\"lm_head\"或\"embed\"，则解冻\n",
    "                if \"lm_head\" in name or \"embed\" in name:\n",
    "                    param.requires_grad = True\n",
    "                    trainable_params.append(param)\n",
    "                    lm_head_found = True\n",
    "                    print(f\"解冻: {name}\")\n",
    "            \n",
    "            # 如果未找到LM头，打印警告\n",
    "            if not lm_head_found:\n",
    "                print(\"警告: 未找到LM头或嵌入层\")\n",
    "            \n",
    "            # 验证是否有可训练参数\n",
    "            if len(trainable_params) == 0:\n",
    "                raise ValueError(\"没有可训练参数！检查模型结构和解冻逻辑\")\n",
    "            else:\n",
    "                print(f\"已解冻 {len(trainable_params)} 个参数\")\n",
    "            \n",
    "            # 7. 加载教师模型并检查维度\n",
    "            print(\"临时加载教师模型检查维度...\")\n",
    "            # 加载教师模型\n",
    "            teacher_model = AutoModelForCausalLM.from_pretrained(\n",
    "                teacher_model_path,\n",
    "                torch_dtype=torch.float32,  # 使用32位浮点精度\n",
    "                device_map=self.teacher_device,  # 指定设备\n",
    "                trust_remote_code=True,  # 允许运行自定义代码\n",
    "                output_hidden_states=True  # 输出隐藏状态\n",
    "            )\n",
    "            # 设置为评估模式，不计算梯度\n",
    "            teacher_model.eval()\n",
    "\n",
    "            # 检查教师模型的隐藏状态维度\n",
    "            with torch.no_grad():\n",
    "                # 将数据移到教师模型所在设备\n",
    "                teacher_inputs = {\n",
    "                    \"input_ids\": batch[\"teacher_inputs\"][\"input_ids\"].to(self.teacher_device),\n",
    "                    \"attention_mask\": batch[\"teacher_inputs\"][\"attention_mask\"].to(self.teacher_device)\n",
    "                }\n",
    "                # 前向传播获取隐藏状态\n",
    "                teacher_outputs = teacher_model(**teacher_inputs, output_hidden_states=True)\n",
    "                teacher_hidden_states = teacher_outputs.hidden_states\n",
    "                \n",
    "                # 打印教师模型层数\n",
    "                print(f\"教师模型层数: {len(teacher_hidden_states)}\")\n",
    "                teacher_num_layers = len(teacher_hidden_states)\n",
    "                print(f\"教师模型层数: {teacher_num_layers}\")\n",
    "\n",
    "                # 打印每层维度信息\n",
    "                for i in range(teacher_num_layers):\n",
    "                    hidden_dim = teacher_hidden_states[i].size(-1)\n",
    "                    print(f\"  层 {i}: 维度 {hidden_dim}\")\n",
    "                \n",
    "                # 检测模型是否支持注意力输出\n",
    "                has_attention = hasattr(teacher_model.config, \"output_attentions\") and teacher_model.config.output_attentions\n",
    "                if not has_attention:\n",
    "                    print(\"注意: 教师模型不支持输出注意力权重，将禁用注意力蒸馏\")\n",
    "                    # 禁用注意力蒸馏\n",
    "                    self.use_attn_distill = False\n",
    "            \n",
    "            # 提取有效的层索引：确保不超出模型层数上限\n",
    "            # 过滤teacher_layers列表，保留索引小于实际层数的值\n",
    "            valid_teacher_layers = [i for i in self.teacher_layers if i < teacher_num_layers]\n",
    "            # 过滤student_layers列表，保留索引小于实际层数的值\n",
    "            valid_student_layers = [i for i in self.student_layers if i < num_layers]\n",
    "\n",
    "            # 获取选中层的维度\n",
    "            teacher_selected_dims = [teacher_hidden_states[i].size(-1) for i in valid_teacher_layers]\n",
    "            student_selected_dims = [student_hidden_states[i].size(-1) for i in valid_student_layers]\n",
    "            \n",
    "            # 8. 创建特征映射器：用于将教师特征映射到学生特征空间\n",
    "            if self.use_multi_layer:\n",
    "                # 如果启用多层映射，创建映射多个层的映射器\n",
    "                print(\"创建多层特征映射器...\")\n",
    "                feature_mapper = MultiLayerFeatureMapper(teacher_selected_dims, student_selected_dims).to(self.device)\n",
    "            else:\n",
    "                # 否则创建单层映射器，只映射最后一层\n",
    "                print(\"创建单层特征映射器...\")\n",
    "                # 使用最后一层的维度创建映射器\n",
    "                feature_mapper = SimpleMapper(teacher_selected_dims[-1], student_selected_dims[-1]).to(self.device)\n",
    "            \n",
    "            # 将特征映射器参数添加到需要训练的参数列表\n",
    "            trainable_params.extend(list(feature_mapper.parameters()))\n",
    "            \n",
    "            # 9. 创建优化器：使用AdamW，适合Transformer模型\n",
    "            optimizer = torch.optim.AdamW(\n",
    "                trainable_params,  # 只优化解冻的参数\n",
    "                lr=self.base_lr,  # 学习率\n",
    "                weight_decay=0.05,  # 权重衰减系数，用于正则化\n",
    "                eps=1e-8,  # 增加epsilon值提高数值稳定性\n",
    "                betas=(0.9, 0.999)  # 动量参数，标准设置\n",
    "            )\n",
    "            \n",
    "            # 10. 创建学习率调度器：实现学习率预热和衰减\n",
    "            # 计算总训练步数：批次数 * 轮次数\n",
    "            total_steps = len(train_loader) * self.epochs\n",
    "            # 计算预热步数：通常占总步数的6%\n",
    "            warmup_steps = int(0.06 * total_steps)  \n",
    "\n",
    "            # 创建线性预热后线性衰减的学习率调度器\n",
    "            # 这种调度器在开始时逐渐增加学习率(预热)，然后线性降低到接近0\n",
    "            scheduler = get_linear_schedule_with_warmup(\n",
    "                optimizer,\n",
    "                num_warmup_steps=warmup_steps,  # 预热步数\n",
    "                num_training_steps=total_steps  # 总训练步数\n",
    "            )\n",
    "            \n",
    "            # 11. 初始化训练状态变量和计数器\n",
    "            # 初始化最佳验证损失为无穷大，用于后续比较\n",
    "            best_val_loss = float('inf')  \n",
    "            # 早停计数器：记录连续未改善的验证次数\n",
    "            patience_counter = 0  \n",
    "            # 全局步数计数器：记录总训练步数\n",
    "            global_step = 0  \n",
    "            \n",
    "            # 12. 模型热身：在正式训练前进行几次推理，预热模型缓存\n",
    "            print(\"执行热身推理...\")\n",
    "            with torch.no_grad():  # 不计算梯度\n",
    "                for _ in range(3):  # 执行3次热身推理\n",
    "                    # 获取一个批次样本\n",
    "                    sample_batch = next(iter(train_loader))\n",
    "                    # 为学生模型准备输入（仅使用第一个样本）\n",
    "                    student_inputs = {\n",
    "                        \"input_ids\": sample_batch[\"student_inputs\"][\"input_ids\"][:1].to(self.student_device),\n",
    "                        \"attention_mask\": sample_batch[\"student_inputs\"][\"attention_mask\"][:1].to(self.student_device)\n",
    "                    }\n",
    "                    \n",
    "                    # 为教师模型准备输入（同样仅使用第一个样本）\n",
    "                    teacher_inputs = {\n",
    "                        \"input_ids\": sample_batch[\"teacher_inputs\"][\"input_ids\"][:1].to(self.teacher_device),\n",
    "                        \"attention_mask\": sample_batch[\"teacher_inputs\"][\"attention_mask\"][:1].to(self.teacher_device)\n",
    "                    }\n",
    "                    \n",
    "                    # 执行学生和教师模型的前向传播，预热模型\n",
    "                    _ = student_model(**student_inputs)\n",
    "                    _ = teacher_model(**teacher_inputs)\n",
    "\n",
    "            # 13. 开始训练循环：迭代多个epoch\n",
    "            for epoch in range(self.epochs):\n",
    "                print(f\"Epoch {epoch+1}/{self.epochs}\")\n",
    "                \n",
    "                # 渐进式调整特征蒸馏权重：随着训练进行，增加特征蒸馏的比重\n",
    "                # 第一轮：仅进行分布级蒸馏(logits蒸馏)\n",
    "                if epoch == 0:\n",
    "                    epoch_response_weight, epoch_feature_weight = 1.0, 0.0  \n",
    "                # 第二轮：主要是分布级蒸馏，加入少量特征蒸馏\n",
    "                elif epoch == 1:\n",
    "                    epoch_response_weight, epoch_feature_weight = 0.8, 0.2  \n",
    "                # 第三轮及以后：增加特征蒸馏比重\n",
    "                else:\n",
    "                    epoch_response_weight, epoch_feature_weight = 0.6, 0.4  \n",
    "                \n",
    "                # 打印当前轮次的权重配置\n",
    "                print(f\"本轮权重: 分布级 {epoch_response_weight:.3f}, 特征级 {epoch_feature_weight:.3f}\")\n",
    "                \n",
    "                # 14. 设置训练模式并初始化统计变量\n",
    "                student_model.train()  # 设置学生模型为训练模式(启用dropout等)\n",
    "                train_loss = 0.0  # 累计训练损失\n",
    "                train_step = 0   # 当前epoch的步数计数器\n",
    "                \n",
    "                # 15. 批次训练循环：使用tqdm显示进度条\n",
    "                with tqdm(train_loader, desc=f\"训练 Epoch {epoch+1}\") as pbar:\n",
    "                    for batch in pbar:\n",
    "                        # 将教师输入数据移到指定设备\n",
    "                        teacher_inputs = {\n",
    "                            \"input_ids\": batch[\"teacher_inputs\"][\"input_ids\"].to(self.device),\n",
    "                            \"attention_mask\": batch[\"teacher_inputs\"][\"attention_mask\"].to(self.device)\n",
    "                        }\n",
    "                        \n",
    "                        # 将学生输入数据移到指定设备\n",
    "                        student_inputs = {\n",
    "                            \"input_ids\": batch[\"student_inputs\"][\"input_ids\"].to(self.device),\n",
    "                            \"attention_mask\": batch[\"student_inputs\"][\"attention_mask\"].to(self.device)\n",
    "                        }\n",
    "                        \n",
    "                        # 16. 教师模型前向传播：不计算梯度，节省内存\n",
    "                        with torch.no_grad():\n",
    "                            # 获取教师模型的输出和隐藏状态\n",
    "                            teacher_outputs = teacher_model(**teacher_inputs, output_hidden_states=True)\n",
    "                            teacher_logits = teacher_outputs.logits  # [batch_size, seq_len, vocab_size]\n",
    "                            teacher_hidden_states = teacher_outputs.hidden_states  # list of [batch_size, seq_len, hidden_dim]\n",
    "                        \n",
    "                        # 17. 学生模型前向传播准备：清空之前的梯度\n",
    "                        optimizer.zero_grad()  \n",
    "                        \n",
    "                        # 18. 根据精度模式选择不同的前向传播和反向传播策略\n",
    "                        if self.mixed_precision:  # 混合精度训练模式(实际未启用)\n",
    "                            # 在自动混合精度上下文中运行前向传播\n",
    "                            with autocast():\n",
    "                                # 学生模型前向传播\n",
    "                                student_outputs = student_model(**student_inputs, output_hidden_states=True)\n",
    "                                # 计算蒸馏损失：包括响应损失和特征损失\n",
    "                                loss, response_loss, feature_loss = self.compute_distill_loss(\n",
    "                                    student_outputs.logits, teacher_logits,\n",
    "                                    student_outputs.hidden_states, teacher_hidden_states,\n",
    "                                    feature_mapper, epoch_feature_weight\n",
    "                                )\n",
    "                            \n",
    "                            # 混合精度模式下的反向传播\n",
    "                            loss.backward()\n",
    "                            \n",
    "                            # 每accumulation_steps步更新一次参数(梯度累积)\n",
    "                            if (train_step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                                # 检查是否有NaN或Inf梯度\n",
    "                                has_bad_grad = False\n",
    "                                for name, param in student_model.named_parameters():\n",
    "                                    if param.requires_grad and param.grad is not None:\n",
    "                                        if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():\n",
    "                                            print(f\"警告: 参数 {name} 的梯度含有NaN或Inf\")\n",
    "                                            param.grad = None  # 清除有问题的梯度\n",
    "                                            has_bad_grad = True\n",
    "                                \n",
    "                                if has_bad_grad:\n",
    "                                    print(\"跳过此步梯度更新，由于检测到NaN梯度\")\n",
    "                                    optimizer.zero_grad()  # 清空梯度，放弃此次更新\n",
    "                                else:\n",
    "                                    # 梯度裁剪：防止梯度爆炸\n",
    "                                    torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=0.5)\n",
    "                                    # 更新模型参数\n",
    "                                    optimizer.step()\n",
    "                                    # 更新学习率\n",
    "                                    scheduler.step()\n",
    "                                \n",
    "                                # 定期保存模型检查点，即使训练不稳定也能恢复\n",
    "                                if global_step % 100 == 0:\n",
    "                                    checkpoint_dir = f\"{output_dir}_step{global_step}\"\n",
    "                                    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "                                    student_model.save_pretrained(checkpoint_dir)\n",
    "                                    print(f\"保存中间检查点: {checkpoint_dir}\")\n",
    "                        else:  # 标准精度训练模式(实际使用的分支)\n",
    "                            # 学生模型前向传播\n",
    "                            student_outputs = student_model(**student_inputs, output_hidden_states=True)\n",
    "                            # 计算蒸馏损失\n",
    "                            loss, response_loss, feature_loss = self.compute_distill_loss(\n",
    "                                student_outputs.logits, teacher_logits,\n",
    "                                student_outputs.hidden_states, teacher_hidden_states,\n",
    "                                feature_mapper, epoch_feature_weight\n",
    "                            )\n",
    "                            \n",
    "                            # 标准精度模式下的反向传播\n",
    "                            loss.backward()\n",
    "                            \n",
    "                            # 每accumulation_steps步更新一次参数(梯度累积)\n",
    "                            if (train_step + 1) % self.gradient_accumulation_steps == 0:\n",
    "                                # 检查是否有NaN或Inf梯度\n",
    "                                has_bad_grad = False\n",
    "                                for name, param in student_model.named_parameters():\n",
    "                                    if param.requires_grad and param.grad is not None:\n",
    "                                        if torch.isnan(param.grad).any() or torch.isinf(param.grad).any():\n",
    "                                            print(f\"警告: 参数 {name} 的梯度含有NaN或Inf\")\n",
    "                                            param.grad = None  # 清除有问题的梯度\n",
    "                                            has_bad_grad = True\n",
    "                                \n",
    "                                if has_bad_grad:\n",
    "                                    print(\"跳过此步梯度更新，由于检测到NaN梯度\")\n",
    "                                    optimizer.zero_grad()  # 清空梯度，放弃此次更新\n",
    "                                else:\n",
    "                                    # 梯度裁剪：限制梯度范数不超过0.5，防止梯度爆炸\n",
    "                                    torch.nn.utils.clip_grad_norm_(trainable_params, max_norm=0.5)\n",
    "                                    # 更新模型参数\n",
    "                                    optimizer.step()\n",
    "                                    # 更新学习率\n",
    "                                    scheduler.step()\n",
    "                                \n",
    "                                # 定期保存模型检查点\n",
    "                                if global_step % 100 == 0:\n",
    "                                    checkpoint_dir = f\"{output_dir}_step{global_step}\"\n",
    "                                    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "                                    student_model.save_pretrained(checkpoint_dir)\n",
    "                                    print(f\"保存中间检查点: {checkpoint_dir}\")\n",
    "                        \n",
    "                        # 19. 检查损失值是否有效(非NaN/Inf)\n",
    "                        if torch.isnan(loss) or torch.isinf(loss):\n",
    "                            print(f\"警告: 检测到无效损失值 {loss.item()}, 跳过此批次更新\")\n",
    "                            continue  # 跳过此批次的后续处理\n",
    "                        \n",
    "                        # 20. 更新训练统计信息\n",
    "                        train_loss += loss.item()  # 累加损失值\n",
    "                        train_step += 1  # 步数+1\n",
    "                        global_step += 1  # 全局步数+1\n",
    "                        \n",
    "                        # 21. 更新进度条显示的信息\n",
    "                        pbar.set_postfix({\n",
    "                            'loss': f\"{loss.item():.6f}\",  # 总损失\n",
    "                            'resp_loss': f\"{response_loss.item():.6f}\",  # 响应损失\n",
    "                            'feat_loss': f\"{feature_loss.item():.6f}\"  # 特征损失\n",
    "                        })\n",
    "                        \n",
    "                        # 22. 定期评估模型(每eval_steps步)\n",
    "                        if global_step % self.eval_steps == 0:\n",
    "                            # 在验证集上评估当前模型性能\n",
    "                            val_loss = self.evaluate(\n",
    "                                student_model, \n",
    "                                teacher_model, \n",
    "                                val_loader, \n",
    "                                feature_mapper, \n",
    "                                epoch_response_weight, \n",
    "                                epoch_feature_weight\n",
    "                            )\n",
    "                            # 评估后将模型重新设为训练模式\n",
    "                            student_model.train()\n",
    "                            \n",
    "                            # 打印验证结果\n",
    "                            print(f\"Step {global_step}, 验证损失: {val_loss:.6f}, 当前最佳: {best_val_loss:.6f}\")\n",
    "                            \n",
    "                            # 23. 检查是否达到新的最佳性能\n",
    "                            if val_loss < best_val_loss:\n",
    "                                best_val_loss = val_loss  # 更新最佳验证损失\n",
    "                                patience_counter = 0  # 重置早停计数器\n",
    "                                \n",
    "                                # 保存当前最佳模型检查点\n",
    "                                checkpoint_dir = f\"{output_dir}_best\"\n",
    "                                os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "                                # 保存学生模型\n",
    "                                student_model.save_pretrained(checkpoint_dir)\n",
    "                                # 保存分词器\n",
    "                                student_tokenizer.save_pretrained(checkpoint_dir)\n",
    "                                # 保存特征映射器状态\n",
    "                                torch.save(feature_mapper.state_dict(), os.path.join(checkpoint_dir, \"feature_mapper.pt\"))\n",
    "                                print(f\"保存当前最佳模型到 {checkpoint_dir}\")\n",
    "                            else:\n",
    "                                # 未改善则增加早停计数\n",
    "                                patience_counter += 1\n",
    "                                # 检查是否达到早停条件\n",
    "                                if patience_counter >= self.patience:\n",
    "                                    print(f\"早停: {self.patience} 次评估内验证损失未改善\")\n",
    "                                    break  # 跳出批次循环\n",
    "                \n",
    "                # 24. 每轮结束后计算平均训练损失\n",
    "                avg_train_loss = train_loss / train_step if train_step > 0 else 0\n",
    "                print(f\"Epoch {epoch+1} 完成, 平均训练损失: {avg_train_loss:.6f}\")\n",
    "                \n",
    "                # 25. 保存每个epoch的检查点\n",
    "                checkpoint_dir = f\"{output_dir}_epoch{epoch+1}\"\n",
    "                os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "                student_model.save_pretrained(checkpoint_dir)\n",
    "                student_tokenizer.save_pretrained(checkpoint_dir)\n",
    "                torch.save(feature_mapper.state_dict(), os.path.join(checkpoint_dir, \"feature_mapper.pt\"))\n",
    "                \n",
    "                # 26. 检查是否达到早停条件\n",
    "                if patience_counter >= self.patience:\n",
    "                    print(\"早停条件满足，停止训练\")\n",
    "                    break  # 跳出epoch循环\n",
    "                \n",
    "                # 27. 定期内存清理，防止内存泄漏和碎片化\n",
    "                if global_step % 20 == 0:  # 每20步清理一次\n",
    "                    gc.collect()  # 触发垃圾回收\n",
    "                    torch.cuda.empty_cache()  # 清空CUDA缓存\n",
    "\n",
    "                # 28. 监控GPU内存使用情况\n",
    "                if train_step % 10 == 0 and torch.cuda.is_available():\n",
    "                    # 计算已分配内存(GB)\n",
    "                    memory_allocated = torch.cuda.memory_allocated() / 1024**3\n",
    "                    # 计算已保留内存(GB)\n",
    "                    memory_reserved = torch.cuda.memory_reserved() / 1024**3\n",
    "                    print(f\"GPU内存: 已分配 {memory_allocated:.2f}GB, 已保留 {memory_reserved:.2f}GB\")\n",
    "\n",
    "                # 29. 再次检查损失值是否有效(冗余检查，以防万一)\n",
    "                if torch.isnan(loss) or torch.isinf(loss):\n",
    "                    print(f\"警告: 检测到无效损失值 {loss.item()}, 跳过此批次更新\")\n",
    "                    optimizer.zero_grad()  # 清除梯度\n",
    "                    continue\n",
    "\n",
    "                # 30. 监控梯度范数，判断训练是否稳定\n",
    "                if train_step % 10 == 0:  # 每10步检查一次\n",
    "                    total_grad = 0\n",
    "                    # 计算所有梯度的L2范数\n",
    "                    for p in [p for p in trainable_params if p.grad is not None]:\n",
    "                        param_norm = p.grad.detach().data.norm(2)  # L2范数\n",
    "                        total_grad += param_norm.item() ** 2\n",
    "                    total_grad = total_grad ** 0.5  # 开方得到总范数\n",
    "                    print(f\"梯度范数: {total_grad:.4f}\")\n",
    "                    \n",
    "                    # 当梯度过大时动态调整学习率\n",
    "                    if total_grad > 10:  # 梯度范数超过阈值\n",
    "                        print(f\"警告: 梯度范数过大 ({total_grad:.4f})，调整优化步骤\")\n",
    "                        # 将所有参数组的学习率乘以0.8，降低学习率\n",
    "                        for param_group in optimizer.param_groups:\n",
    "                            param_group['lr'] = param_group['lr'] * 0.8\n",
    "\n",
    "                # 31. 检查并修复模型参数中的NaN和Inf值\n",
    "                has_nan = False\n",
    "                for name, param in student_model.named_parameters():\n",
    "                    if param.requires_grad and (torch.isnan(param).any() or torch.isinf(param).any()):\n",
    "                        print(f\"警告: 参数 {name} 含有NaN或Inf值，尝试修复\")\n",
    "                        # 将NaN或Inf值替换为0\n",
    "                        with torch.no_grad():\n",
    "                            param.data = torch.where(torch.isnan(param) | torch.isinf(param),\n",
    "                                                     torch.zeros_like(param), param.data)\n",
    "                        has_nan = True\n",
    "\n",
    "                if has_nan:\n",
    "                    print(\"检测到并修复了模型参数中的NaN值\")\n",
    "\n",
    "            # 32. 训练结束后释放教师模型以节省内存\n",
    "            del teacher_model\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "            \n",
    "            # 33. 保存最终模型\n",
    "            print(\"保存最终模型...\")\n",
    "            os.makedirs(output_dir, exist_ok=True)  # 创建输出目录\n",
    "            # 保存学生模型\n",
    "            student_model.save_pretrained(output_dir)\n",
    "            # 保存分词器\n",
    "            student_tokenizer.save_pretrained(output_dir)\n",
    "            # 保存特征映射器\n",
    "            torch.save(feature_mapper.state_dict(), os.path.join(output_dir, \"feature_mapper.pt\"))\n",
    "            \n",
    "            print(\"蒸馏完成!\")\n",
    "            return True  # 表示蒸馏成功完成\n",
    "            \n",
    "        except Exception as e:  # 捕获任何异常\n",
    "            print(f\"蒸馏过程中发生错误: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()  # 打印完整错误堆栈\n",
    "            return False  # 表示蒸馏失败\n",
    "    \n",
    "    # 模型评估方法：在验证集上计算平均损失\n",
    "    def evaluate(self, student_model, teacher_model, val_loader, feature_mapper, response_weight, feature_weight):\n",
    "        \"\"\"\n",
    "        在验证集上评估当前模型性能\n",
    "        参数:\n",
    "            student_model: 学生模型\n",
    "            teacher_model: 教师模型\n",
    "            val_loader: 验证数据加载器\n",
    "            feature_mapper: 特征映射器\n",
    "            response_weight: 分布级损失权重\n",
    "            feature_weight: 特征级损失权重\n",
    "        返回:\n",
    "            avg_loss: 平均验证损失\n",
    "        \"\"\"\n",
    "        student_model.eval()  # 设置为评估模式，禁用dropout等\n",
    "        total_loss = 0.0  # 累计损失\n",
    "        num_batches = 0  # 批次计数\n",
    "        \n",
    "        with torch.no_grad():  # 不计算梯度，节省内存\n",
    "            for batch in val_loader:  # 遍历验证集\n",
    "                # 准备教师模型输入\n",
    "                teacher_inputs = {\n",
    "                    \"input_ids\": batch[\"teacher_inputs\"][\"input_ids\"].to(self.teacher_device),\n",
    "                    \"attention_mask\": batch[\"teacher_inputs\"][\"attention_mask\"].to(self.teacher_device)\n",
    "                }\n",
    "                \n",
    "                # 准备学生模型输入\n",
    "                student_inputs = {\n",
    "                    \"input_ids\": batch[\"student_inputs\"][\"input_ids\"].to(self.student_device),\n",
    "                    \"attention_mask\": batch[\"student_inputs\"][\"attention_mask\"].to(self.student_device)\n",
    "                }\n",
    "                \n",
    "                # 教师模型前向传播\n",
    "                teacher_outputs = teacher_model(**teacher_inputs, output_hidden_states=True)\n",
    "                teacher_logits = teacher_outputs.logits\n",
    "                teacher_hidden_states = teacher_outputs.hidden_states\n",
    "                \n",
    "                # 学生模型前向传播\n",
    "                student_outputs = student_model(**student_inputs, output_hidden_states=True)\n",
    "                student_logits = student_outputs.logits\n",
    "                student_hidden_states = student_outputs.hidden_states\n",
    "                \n",
    "                # 计算蒸馏损失\n",
    "                loss, _, _ = self.compute_distill_loss(\n",
    "                    student_logits, teacher_logits,\n",
    "                    student_hidden_states, teacher_hidden_states,\n",
    "                    feature_mapper, feature_weight\n",
    "                )\n",
    "                \n",
    "                # 累加损失和批次计数\n",
    "                total_loss += loss.item()\n",
    "                num_batches += 1\n",
    "                \n",
    "                # 主动释放内存\n",
    "                del teacher_outputs, student_outputs\n",
    "                torch.cuda.empty_cache()\n",
    "        \n",
    "        # 计算平均损失，若无批次则返回无穷大\n",
    "        avg_loss = total_loss / num_batches if num_batches > 0 else float('inf')\n",
    "        return avg_loss\n",
    "\n",
    "    # 计算蒸馏损失：综合考虑分布级(logits)和特征级损失\n",
    "    def compute_distill_loss(self, student_logits, teacher_logits, student_hidden_states, teacher_hidden_states, feature_mapper, epoch_feature_weight=0):\n",
    "        \"\"\"\n",
    "        计算蒸馏损失，同时处理logits级别和特征级别的知识蒸馏\n",
    "        参数:\n",
    "            student_logits: 学生模型的输出logits\n",
    "            teacher_logits: 教师模型的输出logits\n",
    "            student_hidden_states: 学生模型的所有层隐藏状态\n",
    "            teacher_hidden_states: 教师模型的所有层隐藏状态\n",
    "            feature_mapper: 特征映射器\n",
    "            epoch_feature_weight: 当前epoch的特征损失权重\n",
    "        返回:\n",
    "            loss: 总损失\n",
    "            response_loss: 分布级损失\n",
    "            feature_loss: 特征级损失\n",
    "        \"\"\"\n",
    "        # 取两个模型词汇表大小的最小值，避免维度不匹配\n",
    "        min_vocab_size = min(teacher_logits.size(-1), student_logits.size(-1))\n",
    "        \n",
    "        # 截断logits值避免极值，提高训练稳定性\n",
    "        # 将值限制在[-10, 10]范围内\n",
    "        student_logits_trimmed = torch.clamp(student_logits[..., :min_vocab_size], -10, 10)\n",
    "        teacher_logits_trimmed = torch.clamp(teacher_logits[..., :min_vocab_size], -10, 10)\n",
    "        \n",
    "        # 使用平滑L1损失(Huber损失)计算分布级损失\n",
    "        # beta=0.1表示在差异小于0.1时使用平方损失，否则使用L1损失\n",
    "        response_loss = compute_smooth_l1_loss(\n",
    "            student_logits_trimmed, \n",
    "            teacher_logits_trimmed,\n",
    "            beta=0.1\n",
    "        )\n",
    "        \n",
    "        # 默认特征损失为0\n",
    "        feature_loss = torch.tensor(0.0, device=self.device, requires_grad=True)\n",
    "        \n",
    "        # 如果启用特征蒸馏且当前epoch的特征权重大于0\n",
    "        if self.use_feature_distill and epoch_feature_weight > 0:\n",
    "            # 简化特征蒸馏 - 仅使用最后一层隐藏状态\n",
    "            teacher_last = teacher_hidden_states[-1]  # 教师最后一层 [batch_size, seq_len, hidden_dim]\n",
    "            student_last = student_hidden_states[-1]  # 学生最后一层 [batch_size, seq_len, hidden_dim]\n",
    "            \n",
    "            # 使用特征映射器将教师特征映射到学生特征空间\n",
    "            mapped_teacher = feature_mapper(teacher_last)  # [batch_size, seq_len, student_hidden_dim]\n",
    "            \n",
    "            # 应用余弦相似度损失，计算特征匹配程度\n",
    "            # 乘以0.1是为了平衡特征损失的量级\n",
    "            feature_loss = 0.1 * compute_cosine_loss(student_last, mapped_teacher)\n",
    "        \n",
    "        # 加权组合不同类型的损失\n",
    "        # 1.0 - self.feature_weight: 分布级损失权重\n",
    "        # self.feature_weight: 特征级损失权重\n",
    "        loss = (1.0 - self.feature_weight) * response_loss + self.feature_weight * feature_loss\n",
    "        # 将损失乘以10.0，避免损失值过小导致优化困难\n",
    "        loss = loss * 10.0\n",
    "        \n",
    "        return loss, response_loss, feature_loss\n",
    "\n",
    "# 平滑L1损失函数(Huber损失)\n",
    "# 相比普通L1损失，对大误差不那么敏感，提高训练稳定性\n",
    "def compute_smooth_l1_loss(student_features, teacher_features, beta=1.0):\n",
    "    \"\"\"\n",
    "    计算平滑L1损失(Huber损失)\n",
    "    参数:\n",
    "        student_features: 学生模型特征\n",
    "        teacher_features: 教师模型特征\n",
    "        beta: 平滑参数，控制从L2损失过渡到L1损失的阈值\n",
    "    返回:\n",
    "        平均损失值\n",
    "    \"\"\"\n",
    "    # 计算绝对差异\n",
    "    diff = torch.abs(student_features - teacher_features)\n",
    "    # 创建条件掩码：差异小于beta的位置为True\n",
    "    cond = diff < beta\n",
    "    # 根据条件应用不同的损失计算：\n",
    "    # 当差异小于beta时: 0.5 * x^2 / beta (类似L2损失)\n",
    "    # 当差异大于等于beta时: x - 0.5 * beta (类似L1损失)\n",
    "    loss = torch.where(cond, 0.5 * diff**2 / beta, diff - 0.5 * beta)\n",
    "    # 返回所有元素的平均损失\n",
    "    return loss.mean()\n",
    "\n",
    "# 余弦相似度损失函数\n",
    "# 用于度量两个向量方向的相似性，值域为[0,2]，越小表示越相似\n",
    "def compute_cosine_loss(student_features, teacher_features):\n",
    "    \"\"\"\n",
    "    使用余弦相似度计算特征匹配损失\n",
    "    参数:\n",
    "        student_features: 学生模型特征 [batch_size, seq_len, hidden_dim]\n",
    "        teacher_features: 教师模型特征 [batch_size, seq_len, hidden_dim]\n",
    "    返回:\n",
    "        平均余弦损失值\n",
    "    \"\"\"\n",
    "    # 创建余弦相似度计算器，在最后一维(hidden_dim)上计算\n",
    "    cos = nn.CosineSimilarity(dim=-1)\n",
    "    # 计算1-余弦相似度作为损失\n",
    "    # 余弦相似度范围是[-1,1]，相似度越高值越接近1\n",
    "    # 1-余弦相似度范围是[0,2]，相似度越高值越接近0\n",
    "    return (1 - cos(student_features, teacher_features)).mean()\n",
    "\n",
    "# 主函数，程序入口\n",
    "def safe_main():\n",
    "    \"\"\"\n",
    "    主函数：进行环境设置、检测系统资源并启动蒸馏过程\n",
    "    \"\"\"\n",
    "    # 设置环境变量提高训练稳定性\n",
    "    # CUDA_LAUNCH_BLOCKING=1使CUDA操作同步执行，便于调试和错误定位\n",
    "    os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "    # PYTORCH_NO_CUDA_MEMORY_CACHING=1禁用CUDA内存缓存，减少内存碎片\n",
    "    os.environ[\"PYTORCH_NO_CUDA_MEMORY_CACHING\"] = \"1\"\n",
    "    \n",
    "    # 创建渐进式蒸馏器并运行\n",
    "    distiller = ProgressiveDistiller()\n",
    "    success = distiller.run()\n",
    "    \n",
    "    # 根据运行结果打印信息\n",
    "    if success:\n",
    "        print(\"🎉 渐进式特征蒸馏成功完成!\")\n",
    "    else:\n",
    "        print(\"❌ 蒸馏过程失败.\")\n",
    "\n",
    "# 脚本入口点\n",
    "if __name__ == \"__main__\":\n",
    "    safe_main() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe32533",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250509180722171.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96595801",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250509180741619.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a14dbd",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250509180804596.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844bb8d1",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250509180826194.png\" width=100%></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e30637a1",
   "metadata": {},
   "source": [
    "# 6.蒸馏效果验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eff6f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== 开始最简单的模型比较 ===\n",
      "\n",
      "加载Student模型: /root/autodl-tmp/Qwen/Qwen2___5-0___5B-Instruct\n",
      "Student模型加载成功\n",
      "\n",
      "加载Distilled模型: /root/autodl-tmp/distilled_model\n",
      "Distilled模型加载成功\n",
      "\n",
      "测试提示 1: 被告人陈1某在2014年10月至2015年1月期间，先后三次向吸毒人员李某某贩卖甲基苯丙胺（冰毒），其中前两次交易成功（每次价值400元），第三次在莆田市涵江区\"皇冠大酒店\"交易时被当场抓获并查获0....\n",
      "\n",
      "Student模型 (生成时间: 7.19秒):\n",
      "回答: 请说明理由。\n",
      "答案：不构成贩卖毒品罪；因为本案中，陈1某没有贩卖毒品的故意和行为，只是将毒品交给他人，并未实施实际的贩卖行为。\n",
      "\n",
      "理由如下：\n",
      "\n",
      "1. **主观方面**：根据《刑法》第347条的规定，贩卖毒品罪是指明知是毒品而非法销售给他人，或者明知是制毒物品而提供给他人使用，情节严重的行为。陈1某在贩卖毒品的过程中并没有表现出明显的故意或意图，即他并未认识到自己所出售的毒品是毒品，也没有意识到自己可能违反了法律规定的买卖毒品的规则。因此，他的行为不符合贩卖毒品罪的构成要件。\n",
      "\n",
      "2. **客观方面**：虽然陈1某在贩卖毒品过程中存在一定的过错，但这种过错并不足以使他构成贩卖毒品罪。首先，他没有直接参与具体的毒品交易过程，而是通过其他方式帮助他人购买毒品。其次，即使有贩卖毒品的故意，但由于他在交易过程中没有实际参与，所以不能认定为犯罪。最后，从司法实践来看，对于此类案件，通常会考虑被告人的悔罪表现、认错态度等因素来判断其是否构成犯罪。\n",
      "\n",
      "综上所述，根据《刑法》第347条的规定，陈1某的行为不属于贩卖毒品罪。如果需要进一步处理，建议由公安机关进行调查取证，以确定具体的情节和后果，然后依法作出相应的判决。同时，考虑到陈1某的悔罪表现，可以酌情减轻或免除处罚。 \n",
      "\n",
      "请注意，以上分析基于一般情况下的法律规定，具体情况可能会有所不同，建议咨询专业律师获取更准确的法律意见。\n",
      "\n",
      "Distilled模型 (生成时间: 5.61秒):\n",
      "回答: 请说明理由。\n",
      "\n",
      "本案中，陈1某多次贩卖毒品且被查获，但法院判处45个月有期徒刑并处罚金6000元，这显然是对陈1某的刑罚过重。根据《刑法》第347条的规定，贩卖毒品罪是指贩卖毒品的行为。根据《最高人民法院、最高人民检察院关于办理毒品犯罪案件适用法律若干问题的意见》第18条的规定，毒品犯罪的量刑标准为：一次贩毒的，处三年以上十年以下有期徒刑；两次以上的，处七年以上有期徒刑或者无期徒刑；三次以上的，处死刑，并处没收财产。因此，陈1某多次贩卖毒品且被查获，应当依法判处有期徒刑，并处罚金。\n",
      "\n",
      "此外，根据《中华人民共和国刑事诉讼法》第一百六十一条的规定，对于毒品犯罪案件，人民法院审理后，如果认定犯罪事实清楚，证据确实、充分，依照刑法及有关司法解释的规定，依法作出判决，即生效判决。所以，法院判处45个月有期徒刑并处罚金6000元是适当的。 \n",
      "\n",
      "综上所述，陈1某多次贩卖毒品且被查获，应当依法判处有期徒刑，并处罚金。法院判处45个月有期徒刑并处罚金6000元是适当的。\n",
      "\n",
      "测试提示 2: 被告人龙某某于2010年3月在中国农业银行益阳市大通湖支行办理惠农信用卡（卡号622820138024656），登记手机号为1354977428。2013年2月27日透支本金29997.67元后，于2...\n",
      "\n",
      "Student模型 (生成时间: 6.17秒):\n",
      "回答: 请说明理由。\n",
      "答案：（1）不构成犯罪。（2）酌情从轻处罚。\n",
      "\n",
      "（1）不构成犯罪。根据《刑法》第196条规定，信用卡诈骗罪是指以非法占有为目的，使用伪造、变造的信用卡，或者使用虚假的身份证明骗领信用卡的，或者冒用他人信用卡，进行诈骗活动的行为。本案中，龙某某在申请信用卡时，虽然提供了真实的身份信息和联系方式，但由于其没有及时更换手机号码，并且在多次催收后仍未履行还款义务，最终导致银行无法追回款项，因此不符合信用卡诈骗罪的构成要件。此外，龙某某的行为还涉及逃废债务，属于恶意透支，应当按照刑法第196条的规定定罪处罚。\n",
      "\n",
      "（2）酌情从轻处罚。根据《刑法》第196条的规定，对于信用卡诈骗罪的处罚，一般情况下是单罚制，即只处以罚金，而不能适用死刑。但是，在某些特殊情况下，如明知对方有重大疾病或长期卧病在床等特殊情况，可以考虑减轻处罚或者免除处罚。本案中，龙某某的行为已经构成了信用卡诈骗罪，且数额较大，应依法从重处罚。同时，考虑到其具有逃避催收的情节，可以从轻处罚。因此，法院判处6个月有期徒刑并未处罚金，符合法律规定。\n",
      "\n",
      "Distilled模型 (生成时间: 14.28秒):\n",
      "回答: 请说明理由。\n",
      "\n",
      "### 一、关于信用卡诈骗罪的认定\n",
      "\n",
      "根据《中华人民共和国刑法》第一百九十六条的规定，犯信用卡诈骗罪，数额巨大或者有其他严重情节的，处三年以上十年以下有期徒刑，并处罚金；数额巨大或者有其他严重情节的，处五年以上十年以下有期徒刑，并处罚金；数额特别巨大或者有其他特别严重情节的，处十年以上有期徒刑或者无期徒刑，并处罚金或者没收财产。本案中，龙某某在2013年3月擅自变更手机号并未通知银行，且逾期未还款，已构成信用卡诈骗罪。此外，由于其逃匿，法院依法判处6个月有期徒刑，但未处罚金，这符合《刑法》第一百九十六条中的“情节较轻”的规定。\n",
      "\n",
      "### 二、关于涉案金额及逃避催收情节\n",
      "\n",
      "1. **涉案金额**：根据法院判决，龙某某涉嫌信用卡诈骗罪，案值为29997.67元。因此，该案件涉及的金额确实较大。\n",
      "   \n",
      "2. **逃避催收情节**：法院判令龙某某偿还全部本息，但并未处罚金。这表明法院对逃债者采取了严厉的惩罚措施，即判处6个月有期徒刑。然而，对于逃债者的逃匿行为，法院并没有给予相应的处罚。因此，法院判处6个月有期徒刑并不完全符合《刑法》第一百九十六条中的“情节较轻”规定。\n",
      "\n",
      "### 三、关于法院判处6个月有期徒刑的合理性\n",
      "\n",
      "1. **法律适用**：《刑法》第一百九十六条是针对信用卡诈骗罪的法定刑，而《刑法》第一百九十七条则针对妨害信用卡管理罪。这两项罪名之间存在区别，且《刑法》第一百九十六条的刑罚幅度高于《刑法》第一百九十七条的刑罚幅度。因此，法院判处6个月有期徒刑并非对信用卡诈骗罪的加重处罚，而是对妨害信用卡管理罪的加重处罚。\n",
      "\n",
      "2. **司法实践**：法院判处6个月有期徒刑并不是对所有信用卡诈骗罪的惩罚，而是对特定犯罪行为的惩罚。例如，对于妨害信用卡管理罪，法院可能判处更重的刑罚，如有期徒刑或死刑。\n",
      "\n",
      "综上所述，法院判处6个月有期徒刑并不完全符合《刑法》第一百九十六条中的“情节较轻”规定。法院判处6个月有期徒刑虽然对本案有一定影响，但并不能完全适用于所有信用卡诈骗罪的处罚。 \n",
      "\n",
      "### 四、建议\n",
      "\n",
      "1. **律师建议**：建议龙某某及其家人寻求专业律师的帮助，了解具体的刑事法律规定和司法解释，以便更好地理解和遵守相关法律法规。\n",
      "  \n",
      "2. **法律咨询**：如果需要进一步的帮助，建议咨询专业的律师，他们可以提供更为详细的法律意见和辩护策略。\n",
      "\n",
      "3. **执行**：如果法院判决结果不服，可以在一定期限内申请再审，但通常情况下，法院的判决是最终的。\n",
      "\n",
      "总之，法院判处6个月有期徒刑并不完全符合《刑法》第一百九十六条中的“情节较轻”规定，但仍然对本案有一定的影响。建议龙某某及其家人寻求专业的法律帮助。\n",
      "\n",
      "测试提示 3: 被告人张某甲在2013年1月至3月7日期间，明知李某无药品经营资格且药品来源不明，仍以明显低价购入3700盒假药（包括复方丹参滴丸、脑心通胶囊、金水宝胶囊），并通过医药公司股东周某及自家药店销售。经检...\n",
      "\n",
      "Student模型 (生成时间: 6.79秒):\n",
      "回答: 请说明理由。\n",
      "答案：正确。\n",
      "\n",
      "**判断：**\n",
      "\n",
      "首先，需要明确的是，根据我国刑法的规定，销售假药的定义是“明知是假药而提供或者出售的”，而不是指明知药品来源不明。因此，张某甲的行为不完全符合销售假药罪的构成要件。\n",
      "\n",
      "其次，关于量刑问题，根据《中华人民共和国刑法》的相关规定，销售假药罪的法定最高刑为十年以上有期徒刑，并处五万元以上五十万元以下罚金。本案中，张某甲的行为已经达到了情节严重，属于犯罪的中等程度，但仍然可能面临较重的刑事处罚，如10年以上有期徒刑或无期徒刑，并处巨额罚款。\n",
      "\n",
      "**结论：**\n",
      "\n",
      "综上所述，张某甲的行为不符合销售假药罪的构成要件，不应被认定为销售假药罪。然而，鉴于其行为已达到中等程度，法院判处10个月有期徒刑并未处罚金，这在法律上并不违法，也不应被视为不当处罚。如果需要进一步处理，建议考虑其他法律途径，例如民事赔偿或其他形式的惩罚措施。 \n",
      "\n",
      "请注意，上述分析基于一般情况下的法律规定和案例讨论，具体情况可能会因个案的不同而有所差异。在实际案件处理中，律师会根据具体情况进行详细的法律咨询和辩护。如果您有具体的法律问题，建议咨询专业的法律顾问或法务人员。同时，对于任何涉及非法活动的违法行为，都应当依法进行，避免造成不必要的社会影响。\n",
      "\n",
      "Distilled模型 (生成时间: 8.73秒):\n",
      "回答: 请说明理由。\n",
      "\n",
      "### 问题分析\n",
      "\n",
      "#### 1. 假药的定义\n",
      "假药是指依照国家规定应当取得批准文号而未经批准生产、进口，或者擅自生产的药品。根据《中华人民共和国药品管理法》的规定，假药是指依照本法规定应当取得批准文号而未取得批准文号而生产的药品。\n",
      "\n",
      "#### 2. 案例分析\n",
      "本案中，张某甲通过非法途径购入并销售假药，属于非法购买和销售假药的行为。根据《刑法》第141条，出售假药或假药情节严重者，将面临刑事处罚。\n",
      "\n",
      "#### 3. 是否构成犯罪\n",
      "根据上述分析，张某甲的行为确实符合刑法第141条关于“销售假药”的定义，并且情节严重。因此，法院判决张某甲10个月有期徒刑并未处罚金，是合理的。\n",
      "\n",
      "#### 4. 法院判决的理由\n",
      "法院判决张某甲10个月有期徒刑并未处罚金，理由如下：\n",
      "\n",
      "- **事实认定**：法院依据证据（如查获的假药）以及相关司法解释，认定张某甲的行为符合刑法第141条关于“销售假药”之规定的“情节严重”。 \n",
      "  \n",
      "- **量刑考量**：法院考虑到张某甲的主观恶性、犯罪目的、犯罪手段、危害程度等因素，依法作出了一定的量刑。 \n",
      "\n",
      "- **罚金数额**：法院判处张某甲10个月有期徒刑，但并未处罚金。这体现了对张某甲犯罪行为的严厉惩罚，同时也考虑了其社会危害性和悔罪表现。\n",
      "\n",
      "综上所述，法院判决张某甲10个月有期徒刑并未处罚金，符合法律规定，体现了对犯罪行为的严肃惩处。 \n",
      "\n",
      "### 结论\n",
      "\n",
      "综上所述，张某甲的行为符合刑法第141条关于“销售假药”的定义，并且情节严重。法院判决张某甲10个月有期徒刑并未处罚金，是合理的。\n",
      "\n",
      "比较完成\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import time\n",
    "import os\n",
    "import gc\n",
    "import warnings\n",
    "\n",
    "# 忽略transformers的警告信息\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "\n",
    "# 清理内存\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# 定义测试提示\n",
    "test_prompts = [\n",
    "    \"被告人陈1某在2014年10月至2015年1月期间，先后三次向吸毒人员李某某贩卖甲基苯丙胺（冰毒），其中前两次交易成功（每次价值400元），第三次在莆田市涵江区\\\"皇冠大酒店\\\"交易时被当场抓获并查获0.73克毒品。根据《刑法》第347条规定，其多次贩卖毒品且被查获待售毒品的行为是否构成贩卖毒品罪？法院判处45个月有期徒刑并处罚金6000元是否适当？\",\n",
    "    \"被告人龙某某于2010年3月在中国农业银行益阳市大通湖支行办理惠农信用卡（卡号622820138024656），登记手机号为1354977428。2013年2月27日透支本金29997.67元后，于2013年3月擅自变更手机号为1309355305且未通知银行。银行于2013年4月26日、5月27日两次上门催收未果，同年6月龙某某通过其兄知悉催收信息后仍拒不还款，直至2013年9月30日被立案侦查后才偿还全部本息。根据《刑法》第196条，其行为是否构成信用卡诈骗罪？涉案金额达29997.67元且存在逃避催收情节，法院判处6个月有期徒刑但未处罚金是否适当？\",\n",
    "    \"被告人张某甲在2013年1月至3月7日期间，明知李某无药品经营资格且药品来源不明，仍以明显低价购入3700盒假药（包括复方丹参滴丸、脑心通胶囊、金水宝胶囊），并通过医药公司股东周某及自家药店销售。经检验均为假药，公诉机关指控其行为触犯刑法第141条。根据涉案金额、销售渠道及药品危害性，张某甲的行为是否构成销售假药罪？法院判处10个月有期徒刑且未处罚金是否适当？\"\n",
    "]\n",
    "\n",
    "def minimal_compare(student_path, distilled_path, prompts):\n",
    "    \"\"\"\n",
    "    最小化比较函数，仅比较生成输出和时间\n",
    "    \n",
    "    参数:\n",
    "        student_path: 学生模型路径\n",
    "        distilled_path: 蒸馏后模型路径\n",
    "        prompts: 测试提示列表\n",
    "    \"\"\"\n",
    "    print(\"=== 开始最简单的模型比较 ===\")\n",
    "    \n",
    "    models = {}\n",
    "    tokenizers = {}\n",
    "    \n",
    "    # 逐个加载和评估模型\n",
    "    for name, path in [(\"Student\", student_path), (\"Distilled\", distilled_path)]:\n",
    "        print(f\"\\n加载{name}模型: {path}\")\n",
    "        \n",
    "        try:\n",
    "            # 加载模型和分词器\n",
    "            tokenizer = AutoTokenizer.from_pretrained(path)\n",
    "            model = AutoModelForCausalLM.from_pretrained(\n",
    "                path,\n",
    "                torch_dtype=torch.float32,\n",
    "                device_map=\"auto\",\n",
    "                trust_remote_code=True\n",
    "            )\n",
    "            \n",
    "            tokenizers[name] = tokenizer\n",
    "            models[name] = model\n",
    "            \n",
    "            print(f\"{name}模型加载成功\")\n",
    "        except Exception as e:\n",
    "            print(f\"加载{name}模型失败: {e}\")\n",
    "            continue\n",
    "    \n",
    "    # 如果任一模型加载失败，退出\n",
    "    if len(models) < 2:\n",
    "        print(\"无法加载所有模型，比较终止\")\n",
    "        return\n",
    "    \n",
    "    # 比较每个提示的输出\n",
    "    for i, prompt in enumerate(prompts):\n",
    "        print(f\"\\n测试提示 {i+1}: {prompt[:100]}...\")\n",
    "        \n",
    "        for name in list(models.keys()):  # 使用list()创建副本进行迭代\n",
    "            model = models[name]\n",
    "            tokenizer = tokenizers[name]\n",
    "            \n",
    "            try:\n",
    "                # 编码输入\n",
    "                inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "                \n",
    "                # 测量生成时间\n",
    "                start_time = time.time()\n",
    "                \n",
    "                # 生成输出 - 设置return_dict_in_generate=True以消除警告\n",
    "                with torch.no_grad():\n",
    "                    outputs = model.generate(\n",
    "                        inputs.input_ids,\n",
    "                        max_new_tokens=1000,\n",
    "                        do_sample=False,\n",
    "                        return_dict_in_generate=True  # 添加此参数消除警告\n",
    "                    )\n",
    "                \n",
    "                end_time = time.time()\n",
    "                generation_time = end_time - start_time\n",
    "                \n",
    "                # 解码输出并去除原始提示\n",
    "                # 修改为适应return_dict_in_generate=True的输出格式\n",
    "                generated_text = tokenizer.decode(outputs.sequences[0], skip_special_tokens=True)\n",
    "                # 找到原始提示在生成文本中的位置并只保留后面的内容\n",
    "                answer = generated_text[len(prompt):].strip()\n",
    "                \n",
    "                print(f\"\\n{name}模型 (生成时间: {generation_time:.2f}秒):\")\n",
    "                print(f\"回答: {answer}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"{name}模型生成失败: {e}\")\n",
    "                continue\n",
    "            \n",
    "            # 清理内存\n",
    "            del inputs, outputs\n",
    "            gc.collect()\n",
    "            torch.cuda.empty_cache()\n",
    "    \n",
    "    # 清理模型 - 修复字典迭代错误\n",
    "    model_names = list(models.keys())  # 创建键的副本\n",
    "    for name in model_names:\n",
    "        del models[name], tokenizers[name]\n",
    "    \n",
    "    # 清空字典\n",
    "    models.clear()\n",
    "    tokenizers.clear()\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    print(\"\\n比较完成\")\n",
    "\n",
    "# 运行最简化比较\n",
    "student_model_path = \"/root/autodl-tmp/Qwen/Qwen2___5-0___5B-Instruct\"\n",
    "distilled_model_path = \"/root/autodl-tmp/distilled_model\"  # 或特定epoch的检查点\n",
    "minimal_compare(student_model_path, distilled_model_path, test_prompts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245dd3e2",
   "metadata": {},
   "source": [
    "# 7. 总结"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8554def7",
   "metadata": {},
   "source": [
    "<div align=center><img src=\"https://typora-photo1220.oss-cn-beijing.aliyuncs.com/DataAnalysis/muyan/image-20250514163602962.png\" width=100%></div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
